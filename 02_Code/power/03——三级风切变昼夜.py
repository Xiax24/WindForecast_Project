#!/usr/bin/env python3
"""
åŸºäºä¸‰çº§é£åˆ‡å˜åˆ†ç»„ä¸æ˜¼å¤œç»“åˆçš„é£ç”µé¢„æµ‹ä¸SHAPé‡è¦æ€§åˆ†æ
åˆ†ç±»ç­–ç•¥ï¼šå¼±åˆ‡å˜(Î±<0.2) / ä¸­ç­‰åˆ‡å˜(0.2â‰¤Î±<0.3) / å¼ºåˆ‡å˜(Î±â‰¥0.3) Ã— æ˜¼å¤œ
Author: Research Team
Date: 2025-06-09
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import lightgbm as lgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import shap
from datetime import datetime, time
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class ThreeGroupWindShearAnalyzer:
    def __init__(self, data_path, save_path):
        self.data_path = data_path
        self.save_path = save_path
        self.data = None
        self.groups = {}
        self.feature_names = None
        self.models = {}
        self.shap_explainers = {}
        self.results = {}
        
        # ä¸‰çº§é£åˆ‡å˜é˜ˆå€¼ï¼ˆåŸºäºå¤§æ°”è¾¹ç•Œå±‚ç‰©ç†ç‰¹å¾ï¼‰
        self.shear_thresholds = {
            'weak_upper': 0.1,      # Î± < 0.2: å¼±åˆ‡å˜
            'moderate_upper': 0.3,  # 0.2 â‰¤ Î± < 0.3: ä¸­ç­‰åˆ‡å˜
            # Î± â‰¥ 0.3: å¼ºåˆ‡å˜
        }
        
        # ç‰©ç†æœºåˆ¶å¯¹åº”å…³ç³»
        self.shear_physics = {
            'weak': {
                'description': 'å¼±åˆ‡å˜/é£é€Ÿå˜åŒ–å°',
                'day_cause': 'å¼ºæ··åˆã€ä¸ç¨³å®šå±‚ç»“',
                'night_cause': 'é«˜æ¹æµï¼ˆå¦‚é£é€Ÿå¤§ã€æ— é€†æ¸©ï¼‰'
            },
            'moderate': {
                'description': 'ä¸­ç­‰åˆ‡å˜',
                'day_cause': 'å¸¸è§æ—¥é—´èƒŒæ™¯çŠ¶æ€ï¼Œåä¸­æ€§',
                'night_cause': 'æ¶ˆå¼±ç¨³å®šï¼Œæˆ–é€†æ¸©æœªå®Œå…¨å»ºç«‹'
            },
            'strong': {
                'description': 'å¼ºåˆ‡å˜/å±‚ç»“æŠ‘åˆ¶',
                'day_cause': 'éå¸¸ç¨³å®šå¤§æ°”ï¼ˆå°‘è§ï¼‰',
                'night_cause': 'å¤œé—´é€†æ¸©æ˜¾è‘—ã€æ‘©æ“¦å±‚å¼ºå±‚ç»“'
            }
        }
        
    def load_and_prepare_data(self):
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
        print("ğŸ“Š åŠ è½½å’Œé¢„å¤„ç†æ•°æ®...")
        
        # åŠ è½½æ•°æ®
        self.data = pd.read_csv(self.data_path)
        print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {self.data.shape}")
        
        # è½¬æ¢datetimeåˆ—
        self.data['datetime'] = pd.to_datetime(self.data['datetime'])
        
        # é€‰æ‹©è§‚æµ‹æ•°æ®åˆ—
        obs_columns = [col for col in self.data.columns if col.startswith('obs_')]
        obs_columns += ['datetime', 'power']
        
        # ç§»é™¤å¯†åº¦å’Œæ¹¿åº¦
        obs_columns = [col for col in obs_columns if 'density' not in col and 'humidity' not in col]
        
        self.data = self.data[obs_columns].copy()
        print(f"é€‰æ‹©åˆ—æ•°: {len(obs_columns)-2}")
        
        # ç§»é™¤ç¼ºå¤±å€¼å’Œè´ŸåŠŸç‡
        initial_shape = self.data.shape[0]
        self.data = self.data.dropna()
        self.data = self.data[self.data['power'] >= 0]
        final_shape = self.data.shape[0]
        print(f"æ¸…ç†åæ•°æ®: {final_shape} è¡Œ (ç§»é™¤äº† {initial_shape - final_shape} è¡Œ)")
        
        return self.data
    
    def calculate_wind_shear(self):
        """è®¡ç®—é£åˆ‡å˜ç³»æ•°"""
        print("ğŸŒªï¸ è®¡ç®—é£åˆ‡å˜ç³»æ•°...")
        
        # æ‰¾åˆ°ä¸åŒé«˜åº¦çš„é£é€Ÿåˆ—
        wind_speed_cols = [col for col in self.data.columns if 'wind_speed' in col and col.startswith('obs_')]
        wind_speed_cols.sort()
        
        print(f"å‘ç°é£é€Ÿåˆ—: {wind_speed_cols}")
        
        if len(wind_speed_cols) < 2:
            raise ValueError("éœ€è¦è‡³å°‘2ä¸ªé«˜åº¦çš„é£é€Ÿæ•°æ®æ¥è®¡ç®—é£åˆ‡å˜")
        
        # æå–é«˜åº¦ä¿¡æ¯
        heights = []
        wind_speeds = {}
        
        for col in wind_speed_cols:
            try:
                height_str = col.split('_')[-1].replace('m', '')
                height = float(height_str)
                heights.append(height)
                wind_speeds[height] = self.data[col]
                print(f"  {col} -> {height}m")
            except:
                print(f"  è­¦å‘Š: æ— æ³•ä» {col} æå–é«˜åº¦ä¿¡æ¯")
        
        if len(heights) < 2:
            raise ValueError("æ— æ³•æå–è¶³å¤Ÿçš„é«˜åº¦ä¿¡æ¯")
        
        heights.sort()
        print(f"âœ“ å¯ç”¨é«˜åº¦: {heights} m")
        
        # è®¡ç®—é£åˆ‡å˜ç³»æ•°ï¼ˆä½¿ç”¨æœ€ä½å’Œæœ€é«˜ä¸¤ä¸ªé«˜åº¦ï¼‰
        h1, h2 = heights[0], heights[-1]
        v1, v2 = wind_speeds[h1], wind_speeds[h2]
        
        # é¿å…é™¤é›¶å’Œå¯¹æ•°é”™è¯¯
        valid_mask = (v1 > 0.5) & (v2 > 0.5)
        
        self.data = self.data[valid_mask].copy()
        v1, v2 = v1[valid_mask], v2[valid_mask]
        
        # è®¡ç®—é£åˆ‡å˜ç³»æ•°
        self.data['wind_shear_alpha'] = np.log(v2 / v1) / np.log(h2 / h1)
        
        print(f"âœ“ é£åˆ‡å˜è®¡ç®—å®Œæˆï¼Œä½¿ç”¨ {h1}m å’Œ {h2}m é«˜åº¦")
        print(f"  æœ‰æ•ˆæ•°æ®: {len(self.data)} æ¡")
        print(f"  é£åˆ‡å˜èŒƒå›´: {self.data['wind_shear_alpha'].min():.3f} ~ {self.data['wind_shear_alpha'].max():.3f}")
        print(f"  é£åˆ‡å˜å‡å€¼: {self.data['wind_shear_alpha'].mean():.3f}")
        print(f"  é£åˆ‡å˜ä¸­ä½æ•°: {self.data['wind_shear_alpha'].median():.3f}")
        
        return h1, h2
    
    def classify_three_group_shear(self):
        """åŸºäºä¸‰çº§é˜ˆå€¼åˆ†ç±»é£åˆ‡å˜"""
        print("ğŸ”„ åŸºäºä¸‰çº§é˜ˆå€¼åˆ†ç±»é£åˆ‡å˜...")
        
        alpha = self.data['wind_shear_alpha']
        
        # å®šä¹‰ä¸‰çº§åˆ†ç±»æ¡ä»¶
        conditions = [
            alpha < self.shear_thresholds['weak_upper'],                           # Î± < 0.2: å¼±åˆ‡å˜
            (alpha >= self.shear_thresholds['weak_upper']) & 
            (alpha < self.shear_thresholds['moderate_upper']),                     # 0.2 â‰¤ Î± < 0.3: ä¸­ç­‰åˆ‡å˜
            alpha >= self.shear_thresholds['moderate_upper']                       # Î± â‰¥ 0.3: å¼ºåˆ‡å˜
        ]
        
        choices = ['weak', 'moderate', 'strong']
        
        self.data['shear_group'] = np.select(conditions, choices, default='unknown')
        
        # ç»Ÿè®¡å„åˆ‡å˜ç»„åˆ«
        shear_counts = self.data['shear_group'].value_counts()
        print(f"\nğŸ“Š ä¸‰çº§é£åˆ‡å˜åˆ†ç±»ç»Ÿè®¡:")
        print(f"  å¼±åˆ‡å˜ (Î± < {self.shear_thresholds['weak_upper']}): {shear_counts.get('weak', 0)} æ¡")
        print(f"  ä¸­ç­‰åˆ‡å˜ ({self.shear_thresholds['weak_upper']} â‰¤ Î± < {self.shear_thresholds['moderate_upper']}): {shear_counts.get('moderate', 0)} æ¡")
        print(f"  å¼ºåˆ‡å˜ (Î± â‰¥ {self.shear_thresholds['moderate_upper']}): {shear_counts.get('strong', 0)} æ¡")
        
        # åˆ†æå„ç»„åˆ«çš„é£åˆ‡å˜ç»Ÿè®¡
        shear_stats = self.data.groupby('shear_group')['wind_shear_alpha'].agg(['count', 'mean', 'std', 'min', 'max'])
        print(f"\nå„åˆ‡å˜ç»„åˆ«ç»Ÿè®¡:")
        print(shear_stats.round(3))
        
        return shear_counts, shear_stats
    
    def determine_day_night(self):
        """ç¡®å®šæ˜¼å¤œåˆ†ç±»"""
        print("â˜€ï¸ğŸŒ™ ç¡®å®šæ˜¼å¤œåˆ†ç±»...")
        
        # æå–å°æ—¶ä¿¡æ¯
        self.data['hour'] = self.data['datetime'].dt.hour
        
        # æ˜¼å¤œåˆ’åˆ†ï¼ˆå¯æ ¹æ®åœ°ç†ä½ç½®è°ƒæ•´ï¼‰
        day_start, day_end = 6, 18
        
        self.data['is_daytime'] = ((self.data['hour'] >= day_start) & 
                                  (self.data['hour'] < day_end))
        
        day_count = self.data['is_daytime'].sum()
        night_count = len(self.data) - day_count
        
        print(f"âœ“ æ˜¼å¤œåˆ†ç±»å®Œæˆ:")
        print(f"  ç™½å¤© ({day_start}:00-{day_end}:00): {day_count} æ¡")
        print(f"  å¤œé—´: {night_count} æ¡")
        
        return day_start, day_end
    
    def create_three_group_classification(self):
        """åˆ›å»ºä¸‰çº§é£åˆ‡å˜-æ˜¼å¤œç»„åˆåˆ†ç±»"""
        print("ğŸ”„ åˆ›å»ºä¸‰çº§é£åˆ‡å˜-æ˜¼å¤œç»„åˆåˆ†ç±»...")
        
        # åˆ›å»ºç»„åˆåˆ†ç±»
        self.data['three_group_class'] = self.data['shear_group'].astype(str) + '_' + \
                                       self.data['is_daytime'].map({True: 'day', False: 'night'})
        
        # ç»Ÿè®¡å„åˆ†ç±»
        class_stats = self.data.groupby('three_group_class').agg({
            'power': ['count', 'mean', 'std'],
            'wind_shear_alpha': ['mean', 'std'],
            'hour': 'mean'
        }).round(3)
        
        print("\nğŸ“Š ä¸‰çº§é£åˆ‡å˜-æ˜¼å¤œåˆ†ç±»ç»Ÿè®¡:")
        print("=" * 80)
        for class_name in class_stats.index:
            if 'unknown' not in class_name:
                count = class_stats.loc[class_name, ('power', 'count')]
                power_mean = class_stats.loc[class_name, ('power', 'mean')]
                power_std = class_stats.loc[class_name, ('power', 'std')]
                shear_mean = class_stats.loc[class_name, ('wind_shear_alpha', 'mean')]
                shear_std = class_stats.loc[class_name, ('wind_shear_alpha', 'std')]
                avg_hour = class_stats.loc[class_name, ('hour', 'mean')]
                percentage = count / len(self.data) * 100
                
                # è·å–ç‰©ç†è§£é‡Š
                shear_type = class_name.split('_')[0]
                period = class_name.split('_')[1]
                
                print(f"{class_name}:")
                print(f"  æ ·æœ¬æ•°: {count} ({percentage:.1f}%)")
                print(f"  åŠŸç‡: {power_mean:.1f}Â±{power_std:.1f} MW")
                print(f"  é£åˆ‡å˜: {shear_mean:.3f}Â±{shear_std:.3f}")
                print(f"  å¹³å‡æ—¶é—´: {avg_hour:.1f}æ—¶")
                
                # æ·»åŠ ç‰©ç†è§£é‡Š
                if shear_type in self.shear_physics:
                    cause_key = f'{period}_cause'
                    if cause_key in self.shear_physics[shear_type]:
                        print(f"  ç‰©ç†æˆå› : {self.shear_physics[shear_type][cause_key]}")
                
                print("-" * 50)
        
        # åˆ†æç‰©ç†åˆç†æ€§
        self.analyze_three_group_physics()
        
        return class_stats
    
    def analyze_three_group_physics(self):
        """åˆ†æä¸‰çº§åˆ†ç±»çš„ç‰©ç†åˆç†æ€§"""
        print("ğŸ”¬ åˆ†æä¸‰çº§åˆ†ç±»çš„ç‰©ç†åˆç†æ€§...")
        
        # ç»Ÿè®¡å„ç»„åˆçš„æ•°é‡
        combinations = {}
        for shear in ['weak', 'moderate', 'strong']:
            for period in ['day', 'night']:
                class_name = f'{shear}_{period}'
                count = len(self.data[self.data['three_group_class'] == class_name])
                combinations[class_name] = count
        
        total = len(self.data)
        
        print(f"\nç‰©ç†åˆç†æ€§åˆ†æ:")
        print(f"  å¼±åˆ‡å˜-ç™½å¤© (å¼ºæ··åˆ): {combinations.get('weak_day', 0)} ({combinations.get('weak_day', 0)/total*100:.1f}%)")
        print(f"  å¼±åˆ‡å˜-å¤œé—´ (é«˜æ¹æµ): {combinations.get('weak_night', 0)} ({combinations.get('weak_night', 0)/total*100:.1f}%)")
        print(f"  ä¸­ç­‰åˆ‡å˜-ç™½å¤© (ä¸­æ€§): {combinations.get('moderate_day', 0)} ({combinations.get('moderate_day', 0)/total*100:.1f}%)")
        print(f"  ä¸­ç­‰åˆ‡å˜-å¤œé—´ (è¿‡æ¸¡): {combinations.get('moderate_night', 0)} ({combinations.get('moderate_night', 0)/total*100:.1f}%)")
        print(f"  å¼ºåˆ‡å˜-ç™½å¤© (å¼‚å¸¸): {combinations.get('strong_day', 0)} ({combinations.get('strong_day', 0)/total*100:.1f}%)")
        print(f"  å¼ºåˆ‡å˜-å¤œé—´ (å±‚ç»“): {combinations.get('strong_night', 0)} ({combinations.get('strong_night', 0)/total*100:.1f}%)")
        
        # æœŸæœ›çš„ç‰©ç†åˆ†å¸ƒ
        expected_dominant = ['moderate_day', 'strong_night']  # æœ€å¸¸è§çš„ç»„åˆ
        expected_rare = ['strong_day']  # æœ€å°‘è§çš„ç»„åˆ
        
        print(f"\næœŸæœ›ç‰©ç†åˆ†å¸ƒéªŒè¯:")
        for combo in expected_dominant:
            if combo in combinations:
                pct = combinations[combo] / total * 100
                print(f"  {combo} (æœŸæœ›å¸¸è§): {pct:.1f}% - {'âœ“ ç¬¦åˆ' if pct > 15 else 'âš  åå°‘'}")
        
        for combo in expected_rare:
            if combo in combinations:
                pct = combinations[combo] / total * 100
                print(f"  {combo} (æœŸæœ›ç½•è§): {pct:.1f}% - {'âœ“ ç¬¦åˆ' if pct < 10 else 'âš  åå¤š'}")
        
        return combinations
    
    def visualize_three_group_classification(self):
        """å¯è§†åŒ–ä¸‰çº§åˆ†ç±»ç»“æœ"""
        print("ğŸ“Š å¯è§†åŒ–ä¸‰çº§åˆ†ç±»ç»“æœ...")
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('ä¸‰çº§é£åˆ‡å˜-æ˜¼å¤œåˆ†ç±»åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. é£åˆ‡å˜åˆ†å¸ƒä¸ä¸‰çº§é˜ˆå€¼
        ax1 = axes[0, 0]
        alpha_values = self.data['wind_shear_alpha']
        ax1.hist(alpha_values, bins=50, alpha=0.7, color='skyblue', density=True)
        
        # æ ‡è®°ä¸‰çº§é˜ˆå€¼
        ax1.axvline(x=self.shear_thresholds['weak_upper'], color='green', linestyle='--', 
                   linewidth=2, label=f'å¼±åˆ‡å˜é˜ˆå€¼ (Î±={self.shear_thresholds["weak_upper"]})')
        ax1.axvline(x=self.shear_thresholds['moderate_upper'], color='orange', linestyle='--',
                   linewidth=2, label=f'å¼ºåˆ‡å˜é˜ˆå€¼ (Î±={self.shear_thresholds["moderate_upper"]})')
        
        # æ·»åŠ åŒºåŸŸæ ‡æ³¨
        ax1.axvspan(-0.5, self.shear_thresholds['weak_upper'], alpha=0.2, color='green', label='å¼±åˆ‡å˜åŒº')
        ax1.axvspan(self.shear_thresholds['weak_upper'], self.shear_thresholds['moderate_upper'], 
                   alpha=0.2, color='orange', label='ä¸­ç­‰åˆ‡å˜åŒº')
        ax1.axvspan(self.shear_thresholds['moderate_upper'], 1.0, alpha=0.2, color='red', label='å¼ºåˆ‡å˜åŒº')
        
        ax1.set_xlabel('é£åˆ‡å˜ç³»æ•° Î±')
        ax1.set_ylabel('å¯†åº¦')
        ax1.set_title('é£åˆ‡å˜åˆ†å¸ƒä¸ä¸‰çº§é˜ˆå€¼')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. ä¸‰çº§åˆ‡å˜æ—¥å˜åŒ–æ¨¡å¼
        ax2 = axes[0, 1]
        hourly_shear = self.data.groupby(['hour', 'shear_group']).size().unstack(fill_value=0)
        hourly_shear_pct = hourly_shear.div(hourly_shear.sum(axis=1), axis=0) * 100
        
        if not hourly_shear_pct.empty:
            colors_shear = {'weak': 'green', 'moderate': 'orange', 'strong': 'red'}
            hourly_shear_pct.plot(kind='area', stacked=True, ax=ax2, alpha=0.7, 
                                 color=[colors_shear.get(col, 'gray') for col in hourly_shear_pct.columns])
            ax2.set_xlabel('å°æ—¶')
            ax2.set_ylabel('ç™¾åˆ†æ¯” (%)')
            ax2.set_title('ä¸‰çº§åˆ‡å˜çš„æ—¥å˜åŒ–æ¨¡å¼')
            ax2.legend(title='åˆ‡å˜å¼ºåº¦')
            ax2.grid(True, alpha=0.3)
        
        # 3. ä¸‰çº§åˆ†ç±»æ•£ç‚¹å›¾
        ax3 = axes[0, 2]
        classes = self.data['three_group_class'].unique()
        colors = {'weak': 'green', 'moderate': 'orange', 'strong': 'red'}
        markers = {'day': 'o', 'night': '^'}
        
        for class_name in classes:
            if 'unknown' not in class_name:
                class_data = self.data[self.data['three_group_class'] == class_name]
                shear_type = class_name.split('_')[0]
                period = class_name.split('_')[1]
                
                color = colors.get(shear_type, 'gray')
                marker = markers.get(period, 'o')
                
                ax3.scatter(class_data['wind_shear_alpha'], class_data['power'], 
                           alpha=0.6, s=20, label=class_name, color=color, marker=marker)
        
        ax3.axvline(x=self.shear_thresholds['weak_upper'], color='green', linestyle='--', alpha=0.5)
        ax3.axvline(x=self.shear_thresholds['moderate_upper'], color='orange', linestyle='--', alpha=0.5)
        ax3.set_xlabel('é£åˆ‡å˜ç³»æ•° Î±')
        ax3.set_ylabel('åŠŸç‡ (MW)')
        ax3.set_title('ä¸‰çº§åˆ†ç±»æ•£ç‚¹å›¾\n(åœ†åœˆ=ç™½å¤©, ä¸‰è§’=å¤œé—´)')
        ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax3.grid(True, alpha=0.3)
        
        # 4. å„åˆ†ç±»åŠŸç‡ç®±çº¿å›¾
        ax4 = axes[1, 0]
        power_data_by_class = []
        class_labels = []
        
        for shear in ['weak', 'moderate', 'strong']:
            for period in ['day', 'night']:
                class_name = f'{shear}_{period}'
                if class_name in self.data['three_group_class'].values:
                    power_data = self.data[self.data['three_group_class'] == class_name]['power']
                    if len(power_data) > 0:
                        power_data_by_class.append(power_data)
                        class_labels.append(f'{shear}\n{period}')
        
        if power_data_by_class:
            bp = ax4.boxplot(power_data_by_class, labels=class_labels, patch_artist=True)
            
            # è®¾ç½®ç®±çº¿å›¾é¢œè‰²
            for i, patch in enumerate(bp['boxes']):
                shear_type = class_labels[i].split('\n')[0]
                color = colors.get(shear_type, 'gray')
                patch.set_facecolor(color)
                patch.set_alpha(0.7)
                
            ax4.set_ylabel('åŠŸç‡ (MW)')
            ax4.set_title('å„ä¸‰çº§åˆ†ç±»åŠŸç‡åˆ†å¸ƒ')
            ax4.tick_params(axis='x', rotation=0)
            ax4.grid(True, alpha=0.3)
        
        # 5. ç‰©ç†åˆç†æ€§é¥¼å›¾
        ax5 = axes[1, 1]
        
        # è®¡ç®—åˆç†æ€§åˆ†ç±»
        normal_physics = len(self.data[
            (self.data['three_group_class'].isin(['weak_day', 'moderate_day', 'strong_night'])) 
        ])
        transitional = len(self.data[
            (self.data['three_group_class'].isin(['weak_night', 'moderate_night']))
        ])
        unusual = len(self.data[
            (self.data['three_group_class'] == 'strong_day')
        ])
        
        physics_data = {
            'ç‰©ç†å¸¸è§\n(å¼±/ä¸­-ç™½å¤©, å¼º-å¤œé—´)': normal_physics,
            'è¿‡æ¸¡çŠ¶æ€\n(å¼±/ä¸­-å¤œé—´)': transitional,
            'ç‰©ç†å¼‚å¸¸\n(å¼º-ç™½å¤©)': unusual
        }
        
        colors_pie = ['lightgreen', 'lightyellow', 'lightcoral']
        ax5.pie(physics_data.values(), labels=physics_data.keys(), colors=colors_pie,
                autopct='%1.1f%%', startangle=90)
        ax5.set_title('ç‰©ç†æœºåˆ¶åˆç†æ€§åˆ†å¸ƒ')
        
        # 6. ä¸‰çº§åˆ‡å˜-åŠŸç‡ç›¸å…³æ€§åˆ†æ
        ax6 = axes[1, 2]
        
        # è®¡ç®—å„åˆ†ç±»çš„é£åˆ‡å˜-åŠŸç‡ç›¸å…³æ€§
        corr_data = []
        for shear in ['weak', 'moderate', 'strong']:
            for period in ['day', 'night']:
                class_name = f'{shear}_{period}'
                if class_name in self.data['three_group_class'].values:
                    subset = self.data[self.data['three_group_class'] == class_name]
                    if len(subset) > 20:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ ·æœ¬
                        corr = subset['wind_shear_alpha'].corr(subset['power'])
                        corr_data.append({
                            'class': class_name,
                            'shear_type': shear,
                            'period': period,
                            'correlation': corr,
                            'count': len(subset)
                        })
        
        if corr_data:
            corr_df = pd.DataFrame(corr_data)
            
            # åˆ†ç»„ç»˜åˆ¶
            x_pos = 0
            for shear in ['weak', 'moderate', 'strong']:
                shear_data = corr_df[corr_df['shear_type'] == shear]
                if len(shear_data) > 0:
                    day_data = shear_data[shear_data['period'] == 'day']
                    night_data = shear_data[shear_data['period'] == 'night']
                    
                    color = colors[shear]
                    if len(day_data) > 0:
                        ax6.bar(x_pos, day_data['correlation'].iloc[0], width=0.4, 
                               color=color, alpha=0.7, label=f'{shear}_day' if x_pos == 0 else "")
                    if len(night_data) > 0:
                        ax6.bar(x_pos + 0.4, night_data['correlation'].iloc[0], width=0.4, 
                               color=color, alpha=0.4, label=f'{shear}_night' if x_pos == 0 else "")
                    
                    x_pos += 1
            
            ax6.set_xticks([0.2, 1.2, 2.2])
            ax6.set_xticklabels(['å¼±åˆ‡å˜', 'ä¸­ç­‰åˆ‡å˜', 'å¼ºåˆ‡å˜'])
            ax6.set_ylabel('ç›¸å…³ç³»æ•°')
            ax6.set_title('é£åˆ‡å˜-åŠŸç‡ç›¸å…³æ€§\n(æ·±è‰²=ç™½å¤©, æµ…è‰²=å¤œé—´)')
            ax6.axhline(y=0, color='black', linestyle='-', alpha=0.5)
            ax6.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{self.save_path}/three_group_classification.png", dpi=300, bbox_inches='tight')
        plt.show()
    
    def prepare_classification_groups(self, min_samples=200):
        """æŒ‰ä¸‰çº§åˆ†ç±»åˆ†ç»„æ•°æ®"""
        print(f"ğŸ“Š æŒ‰ä¸‰çº§åˆ†ç±»åˆ†ç»„æ•°æ® (æœ€å°æ ·æœ¬æ•°: {min_samples})...")
        
        class_counts = self.data['three_group_class'].value_counts()
        print(f"æ‰€æœ‰åˆ†ç±»æ ·æœ¬æ•°: {dict(class_counts)}")
        
        # åªé€‰æ‹©æ ·æœ¬æ•°è¶³å¤Ÿçš„åˆ†ç±»
        valid_classes = class_counts[class_counts >= min_samples].index.tolist()
        valid_classes = [cls for cls in valid_classes if 'unknown' not in cls]
        
        print(f"æ ·æœ¬æ•°è¶³å¤Ÿçš„åˆ†ç±»: {valid_classes}")
        
        for class_name in valid_classes:
            class_data = self.data[self.data['three_group_class'] == class_name].copy()
            self.groups[class_name] = class_data
            print(f"  {class_name}: {len(class_data)} æ¡æ ·æœ¬")
        
        return self.groups
    
    def process_wind_direction(self, data):
        """å¤„ç†é£å‘å˜é‡ä¸ºsin/cosåˆ†é‡"""
        data = data.copy()
        wind_dir_cols = [col for col in data.columns if 'wind_direction' in col]
        
        if wind_dir_cols:
            for col in wind_dir_cols:
                # æ°”è±¡è§’åº¦è½¬æ¢ä¸ºæ•°å­¦è§’åº¦
                math_angle = (90 - data[col] + 360) % 360
                wind_dir_rad = np.deg2rad(math_angle)
                
                # åˆ›å»ºsin/cosåˆ†é‡
                sin_col = col.replace('wind_direction', 'wind_dir_sin')
                cos_col = col.replace('wind_direction', 'wind_dir_cos')
                
                data[sin_col] = np.sin(wind_dir_rad)
                data[cos_col] = np.cos(wind_dir_rad)
            
            # ç§»é™¤åŸå§‹é£å‘åˆ—
            data = data.drop(columns=wind_dir_cols)
        
        return data
    
    def train_three_group_models(self):
        """ä¸ºæ¯ç§ä¸‰çº§åˆ†ç±»è®­ç»ƒç‹¬ç«‹çš„é¢„æµ‹æ¨¡å‹"""
        print("ğŸš€ è®­ç»ƒä¸‰çº§åˆ†ç±»æ¨¡å‹...")
        
        # LightGBMåŸºç¡€å‚æ•°
        base_params = {
            'objective': 'regression',
            'metric': 'rmse',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.1,
            'n_estimators': 200,
            'reg_alpha': 0.1,
            'reg_lambda': 0.1,
            'min_child_samples': 20,
            'random_state': 42,
            'verbose': -1,
            'n_jobs': -1
        }
        
        for class_name, data in self.groups.items():
            print(f"\nè®­ç»ƒ {class_name} æ¨¡å‹...")
            print(f"æ•°æ®é‡: {len(data)} æ¡")
            
            # å¤„ç†é£å‘å’Œå‡†å¤‡ç‰¹å¾
            data_processed = self.process_wind_direction(data)
            
            # é€‰æ‹©ç‰¹å¾åˆ—
            exclude_cols = ['datetime', 'power', 'hour', 'is_daytime', 'wind_shear_alpha',
                          'shear_group', 'three_group_class']
            feature_cols = [col for col in data_processed.columns if col not in exclude_cols]
            
            # åˆ›å»ºç‰¹å¾çŸ©é˜µ
            X = data_processed[feature_cols].values
            y = data_processed['power'].values
            
            # ä¿å­˜ç‰¹å¾åç§°
            if self.feature_names is None:
                self.feature_names = feature_cols
                print(f"  è®¾ç½®ç‰¹å¾åç§°ï¼Œå…± {len(feature_cols)} ä¸ªç‰¹å¾")
            
            print(f"  ç‰¹å¾æ•°é‡: {len(feature_cols)}")
            print(f"  åŠŸç‡èŒƒå›´: {y.min():.1f} - {y.max():.1f} MW")
            print(f"  åŠŸç‡å‡å€¼: {y.mean():.1f} MW")
            print(f"  é£åˆ‡å˜èŒƒå›´: {data['wind_shear_alpha'].min():.3f} - {data['wind_shear_alpha'].max():.3f}")
            
            # æ•°æ®åˆ†å‰²
            if len(data) >= 100:
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42
                )
                
                # è®­ç»ƒæ¨¡å‹
                model = lgb.LGBMRegressor(**base_params)
                model.fit(X_train, y_train)
                
                # é¢„æµ‹å’Œè¯„ä¼°
                y_pred_train = model.predict(X_train)
                y_pred_test = model.predict(X_test)
                
                train_r2 = r2_score(y_train, y_pred_train)
                test_r2 = r2_score(y_test, y_pred_test)
                train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
                test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
                
                # ä¿å­˜æ¨¡å‹å’Œç»“æœ
                self.models[class_name] = model
                self.results[class_name] = {
                    'r2_train': train_r2,
                    'r2_test': test_r2,
                    'rmse_train': train_rmse,
                    'rmse_test': test_rmse,
                    'X_train': X_train,
                    'X_test': X_test,
                    'y_train': y_train,
                    'y_test': y_test,
                    'y_pred_train': y_pred_train,
                    'y_pred_test': y_pred_test,
                    'sample_count': len(data),
                    'power_mean': y.mean(),
                    'power_std': y.std(),
                    'shear_mean': data['wind_shear_alpha'].mean(),
                    'shear_std': data['wind_shear_alpha'].std()
                }
                
                print(f"  âœ“ è®­ç»ƒå®Œæˆ - RÂ²: {test_r2:.4f}, RMSE: {test_rmse:.2f} MW")
                print(f"    è¿‡æ‹Ÿåˆæ£€æŸ¥: è®­ç»ƒRÂ²={train_r2:.4f}, æµ‹è¯•RÂ²={test_r2:.4f}, å·®å€¼={train_r2-test_r2:.4f}")
                
            else:
                print(f"  âš ï¸ æ ·æœ¬æ•°ä¸è¶³ ({len(data)} < 100)ï¼Œè·³è¿‡è®­ç»ƒ")
        
        print(f"\nâœ“ å…±è®­ç»ƒäº† {len(self.models)} ä¸ªä¸‰çº§åˆ†ç±»æ¨¡å‹")
        return self.models
    
    def calculate_shap_values(self, n_samples=800):
        """è®¡ç®—å„åˆ†ç±»æ¨¡å‹çš„SHAPå€¼"""
        print("ğŸ“Š è®¡ç®—SHAPé‡è¦æ€§...")
        
        for class_name in self.models.keys():
            print(f"è®¡ç®— {class_name} çš„SHAPå€¼...")
            
            # è·å–æµ‹è¯•æ•°æ®
            X_test = self.results[class_name]['X_test']
            
            # é™åˆ¶æ ·æœ¬æ•°é‡
            if len(X_test) > n_samples:
                indices = np.random.choice(len(X_test), n_samples, replace=False)
                X_sample = X_test[indices]
            else:
                X_sample = X_test
            
            # è®¡ç®—SHAPå€¼
            explainer = shap.TreeExplainer(self.models[class_name])
            shap_values = explainer.shap_values(X_sample)
            
            # ä¿å­˜ç»“æœ
            self.shap_explainers[class_name] = explainer
            self.results[class_name]['shap_values'] = shap_values
            self.results[class_name]['X_shap'] = X_sample
            
            print(f"  âœ“ å®Œæˆ (æ ·æœ¬æ•°: {len(X_sample)})")
    
    def plot_performance_comparison(self):
        """ç»˜åˆ¶æ¨¡å‹æ€§èƒ½å¯¹æ¯”"""
        print("ğŸ“ˆ ç»˜åˆ¶æ¨¡å‹æ€§èƒ½å¯¹æ¯”...")
        
        if not self.results:
            print("âš ï¸ æ²¡æœ‰è®­ç»ƒç»“æœï¼Œè·³è¿‡æ€§èƒ½å¯¹æ¯”")
            return
        
        # å‡†å¤‡æ•°æ®
        class_names = list(self.results.keys())
        r2_values = [self.results[cls]['r2_test'] for cls in class_names]
        rmse_values = [self.results[cls]['rmse_test'] for cls in class_names]
        sample_counts = [self.results[cls]['sample_count'] for cls in class_names]
        power_means = [self.results[cls]['power_mean'] for cls in class_names]
        shear_means = [self.results[cls]['shear_mean'] for cls in class_names]
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('ä¸‰çº§é£åˆ‡å˜-æ˜¼å¤œåˆ†ç±»æ¨¡å‹æ€§èƒ½å¯¹æ¯”', fontsize=16, fontweight='bold')
        
        # è®¾ç½®é¢œè‰²æ˜ å°„
        color_map = {'weak': 'green', 'moderate': 'orange', 'strong': 'red'}
        
        # 1. RÂ² æ€§èƒ½å¯¹æ¯”
        ax1 = axes[0, 0]
        colors = []
        for name in class_names:
            shear_type = name.split('_')[0]
            colors.append(color_map.get(shear_type, 'gray'))
        
        bars1 = ax1.bar(range(len(class_names)), r2_values, color=colors, alpha=0.7)
        ax1.set_xticks(range(len(class_names)))
        ax1.set_xticklabels([name.replace('_', '\n') for name in class_names], rotation=0)
        ax1.set_ylabel('RÂ² Score')
        ax1.set_title('RÂ² æ€§èƒ½å¯¹æ¯”')
        ax1.set_ylim(0, 1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, r2 in zip(bars1, r2_values):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{r2:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 2. RMSE å¯¹æ¯”
        ax2 = axes[0, 1]
        bars2 = ax2.bar(range(len(class_names)), rmse_values, color=colors, alpha=0.7)
        ax2.set_xticks(range(len(class_names)))
        ax2.set_xticklabels([name.replace('_', '\n') for name in class_names], rotation=0)
        ax2.set_ylabel('RMSE (MW)')
        ax2.set_title('RMSE å¯¹æ¯”')
        
        for bar, rmse in zip(bars2, rmse_values):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                    f'{rmse:.1f}', ha='center', va='bottom', fontweight='bold')
        
        # 3. æ ·æœ¬æ•°é‡å¯¹æ¯”
        ax3 = axes[0, 2]
        bars3 = ax3.bar(range(len(class_names)), sample_counts, color=colors, alpha=0.7)
        ax3.set_xticks(range(len(class_names)))
        ax3.set_xticklabels([name.replace('_', '\n') for name in class_names], rotation=0)
        ax3.set_ylabel('æ ·æœ¬æ•°é‡')
        ax3.set_title('å„åˆ†ç±»æ ·æœ¬åˆ†å¸ƒ')
        
        for bar, count in zip(bars3, sample_counts):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                    f'{count}', ha='center', va='bottom', fontweight='bold')
        
        # 4. åˆ‡å˜å¼ºåº¦æ€§èƒ½å¯¹æ¯”
        ax4 = axes[1, 0]
        
        # æŒ‰åˆ‡å˜å¼ºåº¦åˆ†ç»„
        shear_performance = {}
        for shear in ['weak', 'moderate', 'strong']:
            day_class = f'{shear}_day'
            night_class = f'{shear}_night'
            
            day_r2 = self.results.get(day_class, {}).get('r2_test', None)
            night_r2 = self.results.get(night_class, {}).get('r2_test', None)
            
            shear_performance[shear] = {'day': day_r2, 'night': night_r2}
        
        x = np.arange(3)
        width = 0.35
        
        day_r2_vals = [shear_performance[s]['day'] for s in ['weak', 'moderate', 'strong']]
        night_r2_vals = [shear_performance[s]['night'] for s in ['weak', 'moderate', 'strong']]
        
        # åªç»˜åˆ¶æœ‰æ•ˆæ•°æ®
        day_r2_clean = [v if v is not None else 0 for v in day_r2_vals]
        night_r2_clean = [v if v is not None else 0 for v in night_r2_vals]
        
        ax4.bar(x - width/2, day_r2_clean, width, label='ç™½å¤©', alpha=0.7, color='orange')
        ax4.bar(x + width/2, night_r2_clean, width, label='å¤œé—´', alpha=0.7, color='navy')
        
        ax4.set_xticks(x)
        ax4.set_xticklabels(['å¼±åˆ‡å˜', 'ä¸­ç­‰åˆ‡å˜', 'å¼ºåˆ‡å˜'])
        ax4.set_ylabel('RÂ² Score')
        ax4.set_title('åˆ‡å˜å¼ºåº¦æ€§èƒ½å¯¹æ¯”')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        # 5. ç‰©ç†æœºåˆ¶éªŒè¯æ•£ç‚¹å›¾
        ax5 = axes[1, 1]
        
        # æŒ‰ç‰©ç†åˆç†æ€§ç€è‰²
        physical_colors = []
        for name in class_names:
            if name in ['weak_day', 'moderate_day', 'strong_night']:
                physical_colors.append('green')  # ç‰©ç†åˆç†
            elif name in ['weak_night', 'moderate_night']:
                physical_colors.append('orange')  # è¿‡æ¸¡çŠ¶æ€
            elif name == 'strong_day':
                physical_colors.append('red')  # ç‰©ç†å¼‚å¸¸
            else:
                physical_colors.append('gray')
        
        scatter = ax5.scatter(shear_means, r2_values, c=physical_colors, s=100, alpha=0.7)
        
        # æ·»åŠ åˆ†ç±»æ ‡ç­¾
        for i, class_name in enumerate(class_names):
            ax5.annotate(class_name.replace('_', '\n'), 
                        (shear_means[i], r2_values[i]),
                        xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        # æ·»åŠ é˜ˆå€¼çº¿
        ax5.axvline(x=self.shear_thresholds['weak_upper'], color='gray', linestyle='--', alpha=0.5)
        ax5.axvline(x=self.shear_thresholds['moderate_upper'], color='gray', linestyle='--', alpha=0.5)
        
        ax5.set_xlabel('å¹³å‡é£åˆ‡å˜ç³»æ•° Î±')
        ax5.set_ylabel('RÂ² Score')
        ax5.set_title('é£åˆ‡å˜-æ€§èƒ½å…³ç³»\n(ç»¿=ç‰©ç†åˆç†, æ©™=è¿‡æ¸¡, çº¢=å¼‚å¸¸)')
        ax5.grid(True, alpha=0.3)
        
        # 6. æ€§èƒ½ç¨³å®šæ€§åˆ†æ
        ax6 = axes[1, 2]
        
        # è®¡ç®—è®­ç»ƒ-æµ‹è¯•æ€§èƒ½å·®å¼‚
        overfitting = []
        for class_name in class_names:
            train_r2 = self.results[class_name]['r2_train']
            test_r2 = self.results[class_name]['r2_test']
            overfitting.append(train_r2 - test_r2)
        
        bars6 = ax6.bar(range(len(class_names)), overfitting, color=colors, alpha=0.7)
        ax6.set_xticks(range(len(class_names)))
        ax6.set_xticklabels([name.replace('_', '\n') for name in class_names], rotation=45, ha='right')
        ax6.set_ylabel('è¿‡æ‹Ÿåˆç¨‹åº¦ (è®­ç»ƒRÂ² - æµ‹è¯•RÂ²)')
        ax6.set_title('æ¨¡å‹ç¨³å®šæ€§åˆ†æ')
        ax6.axhline(y=0.1, color='red', linestyle='--', alpha=0.7, label='è¿‡æ‹Ÿåˆè­¦æˆ’çº¿')
        ax6.legend()
        ax6.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, overfit in zip(bars6, overfitting):
            height = bar.get_height()
            ax6.text(bar.get_x() + bar.get_width()/2., height + 0.001,
                    f'{overfit:.3f}', ha='center', va='bottom', fontsize=8)
        
        plt.tight_layout()
        plt.savefig(f"{self.save_path}/three_group_performance.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        # è¾“å‡ºæ€§èƒ½æ’å
        print("\nğŸ“Š æ€§èƒ½æ’å (æŒ‰RÂ²é™åº):")
        performance_df = pd.DataFrame({
            'classification': class_names,
            'r2': r2_values,
            'rmse': rmse_values,
            'samples': sample_counts,
            'power_mean': power_means,
            'shear_mean': shear_means,
            'overfitting': overfitting
        }).sort_values('r2', ascending=False)
        
        for i, row in performance_df.iterrows():
            shear_type = row['classification'].split('_')[0]
            period = row['classification'].split('_')[1]
            
            # ç‰©ç†åˆç†æ€§åˆ¤æ–­
            if row['classification'] in ['weak_day', 'moderate_day', 'strong_night']:
                physics = "åˆç†"
            elif row['classification'] in ['weak_night', 'moderate_night']:
                physics = "è¿‡æ¸¡"
            elif row['classification'] == 'strong_day':
                physics = "å¼‚å¸¸"
            else:
                physics = "æœªçŸ¥"
            
            print(f"  {i+1}. {row['classification']} ({shear_type}åˆ‡å˜+{period}, {physics}): "
                  f"RÂ²={row['r2']:.3f}, RMSE={row['rmse']:.1f}MW, "
                  f"æ ·æœ¬={row['samples']}, Î±={row['shear_mean']:.3f}, "
                  f"è¿‡æ‹Ÿåˆ={row['overfitting']:.3f}")
        
        return performance_df
    
    def plot_shap_comparison(self):
        """ç»˜åˆ¶SHAPé‡è¦æ€§å¯¹æ¯”"""
        print("ğŸ“Š ç»˜åˆ¶SHAPé‡è¦æ€§å¯¹æ¯”...")
        
        if not self.results or not any('shap_values' in result for result in self.results.values()):
            print("âš ï¸ æ²¡æœ‰SHAPç»“æœï¼Œè·³è¿‡SHAPå¯¹æ¯”")
            return
        
        # è®¡ç®—å„åˆ†ç±»çš„å¹³å‡SHAPé‡è¦æ€§
        shap_importance_df = pd.DataFrame({'feature': self.feature_names})
        
        for class_name in self.results.keys():
            if 'shap_values' in self.results[class_name]:
                shap_values = self.results[class_name]['shap_values']
                importance = np.abs(shap_values).mean(axis=0)
                shap_importance_df[f'{class_name}_importance'] = importance
        
        # è®¡ç®—æ€»ä½“é‡è¦æ€§æ’åº
        importance_cols = [col for col in shap_importance_df.columns if 'importance' in col]
        shap_importance_df['avg_importance'] = shap_importance_df[importance_cols].mean(axis=1)
        shap_importance_df = shap_importance_df.sort_values('avg_importance', ascending=False)
        
        # ç»˜åˆ¶å¯¹æ¯”å›¾
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))
        fig.suptitle('ä¸‰çº§é£åˆ‡å˜åˆ†ç±»SHAPé‡è¦æ€§å¯¹æ¯”', fontsize=16, fontweight='bold')
        
        # 1. Topç‰¹å¾é‡è¦æ€§å¯¹æ¯”
        top_n = 15
        top_features = shap_importance_df.head(top_n)
        
        ax1 = axes[0, 0]
        class_names = [col.replace('_importance', '') for col in importance_cols]
        x = np.arange(len(top_features))
        width = 0.8 / len(class_names)
        
        color_map = {'weak': 'green', 'moderate': 'orange', 'strong': 'red'}
        
        for i, class_name in enumerate(class_names):
            col = f'{class_name}_importance'
            offset = (i - len(class_names)/2 + 0.5) * width
            
            # æ ¹æ®åˆ‡å˜å¼ºåº¦è®¾ç½®é¢œè‰²
            shear_type = class_name.split('_')[0]
            period = class_name.split('_')[1]
            color = color_map.get(shear_type, 'gray')
            
            # æ ¹æ®æ˜¼å¤œè®¾ç½®å¡«å……æ ·å¼
            if period == 'night':
                alpha = 0.6
                hatch = '//'
            else:
                alpha = 0.9
                hatch = None
            
            ax1.barh(x + offset, top_features[col], width, 
                    label=f'{class_name}', 
                    color=color, alpha=alpha, hatch=hatch)
        
        ax1.set_yticks(x)
        ax1.set_yticklabels(top_features['feature'], fontsize=8)
        ax1.set_xlabel('SHAPé‡è¦æ€§')
        ax1.set_title(f'Top {top_n} ç‰¹å¾é‡è¦æ€§å¯¹æ¯”')
        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax1.grid(True, alpha=0.3)
        
        # 2. åˆ‡å˜å¼ºåº¦é‡è¦æ€§å¯¹æ¯”
        ax2 = axes[0, 1]
        
        # æŒ‰åˆ‡å˜å¼ºåº¦åˆ†ç»„
        shear_groups = {'weak': [], 'moderate': [], 'strong': []}
        for col in importance_cols:
            shear_type = col.replace('_importance', '').split('_')[0]
            if shear_type in shear_groups:
                shear_groups[shear_type].append(col)
        
        top_features_shear = shap_importance_df.head(20)
        x = np.arange(len(top_features_shear))
        width = 0.25
        
        for i, (shear, cols) in enumerate(shear_groups.items()):
            if cols:
                avg_importance = top_features_shear[cols].mean(axis=1)
                ax2.barh(x + i*width - width, avg_importance, width, 
                        label=f'{shear}åˆ‡å˜', color=color_map[shear], alpha=0.7)
        
        ax2.set_yticks(x)
        ax2.set_yticklabels(top_features_shear['feature'], fontsize=8)
        ax2.set_xlabel('å¹³å‡SHAPé‡è¦æ€§')
        ax2.set_title('æŒ‰åˆ‡å˜å¼ºåº¦åˆ†ç»„çš„é‡è¦æ€§')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. æ˜¼å¤œé‡è¦æ€§å¯¹æ¯”
        ax3 = axes[0, 2]
        
        day_cols = [col for col in importance_cols if 'day' in col]
        night_cols = [col for col in importance_cols if 'night' in col]
        
        if day_cols and night_cols:
            day_avg = shap_importance_df[day_cols].mean(axis=1)
            night_avg = shap_importance_df[night_cols].mean(axis=1)
            
            top_features_day_night = shap_importance_df.head(20)
            day_top = day_avg[top_features_day_night.index]
            night_top = night_avg[top_features_day_night.index]
            
            x = np.arange(len(top_features_day_night))
            width = 0.35
            
            ax3.barh(x - width/2, day_top, width, label='ç™½å¤©', alpha=0.7, color='orange')
            ax3.barh(x + width/2, night_top, width, label='å¤œé—´', alpha=0.7, color='navy')
            
            ax3.set_yticks(x)
            ax3.set_yticklabels(top_features_day_night['feature'], fontsize=8)
            ax3.set_xlabel('å¹³å‡SHAPé‡è¦æ€§')
            ax3.set_title('æ˜¼å¤œæ¡ä»¶é‡è¦æ€§å¯¹æ¯”')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
        
        # 4. é«˜åº¦é£é€Ÿé‡è¦æ€§éªŒè¯
        ax4 = axes[1, 0]
        
        # åˆ†æä¸åŒé«˜åº¦é£é€Ÿçš„é‡è¦æ€§
        wind_height_features = [f for f in self.feature_names if 'wind_speed' in f]
        
        if len(wind_height_features) >= 2:
            height_importance = {}
            for class_name in class_names:
                col = f'{class_name}_importance'
                if col in shap_importance_df.columns:
                    class_importance = {}
                    for wind_feature in wind_height_features:
                        feature_idx = shap_importance_df[shap_importance_df['feature'] == wind_feature].index
                        if len(feature_idx) > 0:
                            importance = shap_importance_df.loc[feature_idx[0], col]
                            class_importance[wind_feature] = importance
                    height_importance[class_name] = class_importance
            
            # ç»˜åˆ¶é£é€Ÿé«˜åº¦é‡è¦æ€§
            if height_importance:
                wind_features = list(height_importance[list(height_importance.keys())[0]].keys())
                x = np.arange(len(class_names))
                width = 0.8 / len(wind_features)
                
                for i, wind_feature in enumerate(wind_features):
                    importances = [height_importance[cls].get(wind_feature, 0) for cls in class_names]
                    offset = (i - len(wind_features)/2 + 0.5) * width
                    
                    # æå–é«˜åº¦ä¿¡æ¯ç”¨äºæ ‡ç­¾
                    height_label = wind_feature.split('_')[-1] if '_' in wind_feature else wind_feature
                    
                    ax4.bar(x + offset, importances, width, label=height_label, alpha=0.7)
                
                ax4.set_xticks(x)
                ax4.set_xticklabels([name.replace('_', '\n') for name in class_names], rotation=45, ha='right')
                ax4.set_ylabel('SHAPé‡è¦æ€§')
                ax4.set_title('ä¸åŒé«˜åº¦é£é€Ÿé‡è¦æ€§\n(éªŒè¯åˆ‡å˜æœºåˆ¶)')
                ax4.legend()
                ax4.grid(True, alpha=0.3)
        
        # 5. ç‰¹å¾ç±»å‹é‡è¦æ€§åˆ†å¸ƒ
        ax5 = axes[1, 1]
        
        # æŒ‰ç‰¹å¾ç±»å‹åˆ†ç»„
        feature_categories = {
            'wind_speed': [f for f in self.feature_names if 'wind_speed' in f],
            'wind_direction': [f for f in self.feature_names if 'wind_dir' in f],
            'temperature': [f for f in self.feature_names if 'temperature' in f],
            'pressure': [f for f in self.feature_names if 'pressure' in f],
            'other': [f for f in self.feature_names if not any(keyword in f for keyword in 
                     ['wind_speed', 'wind_dir', 'temperature', 'pressure'])]
        }
        
        category_importance = {}
        for class_name in class_names:
            col = f'{class_name}_importance'
            if col in shap_importance_df.columns:
                cat_importance = {}
                for category, features in feature_categories.items():
                    if features:
                        cat_features = shap_importance_df[shap_importance_df['feature'].isin(features)]
                        cat_importance[category] = cat_features[col].sum()
                    else:
                        cat_importance[category] = 0
                category_importance[class_name] = cat_importance
        
        # ç»˜åˆ¶ç‰¹å¾ç±»å‹é‡è¦æ€§
        if category_importance:
            categories = list(feature_categories.keys())
            x = np.arange(len(categories))
            width = 0.8 / len(class_names)
            
            for i, class_name in enumerate(class_names):
                importances = [category_importance[class_name].get(cat, 0) for cat in categories]
                offset = (i - len(class_names)/2 + 0.5) * width
                
                # è®¾ç½®é¢œè‰²
                shear_type = class_name.split('_')[0]
                color = color_map.get(shear_type, 'gray')
                
                ax5.bar(x + offset, importances, width, label=class_name, 
                       color=color, alpha=0.7)
            
            ax5.set_xticks(x)
            ax5.set_xticklabels(categories, rotation=45, ha='right')
            ax5.set_ylabel('ç´¯è®¡SHAPé‡è¦æ€§')
            ax5.set_title('ç‰¹å¾ç±»å‹é‡è¦æ€§åˆ†å¸ƒ')
            ax5.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax5.grid(True, alpha=0.3)
        
        # 6. ç‰©ç†æœºåˆ¶éªŒè¯çƒ­åŠ›å›¾
        ax6 = axes[1, 2]
        
        # é€‰æ‹©å…³é”®ç‰¹å¾è¿›è¡Œçƒ­åŠ›å›¾
        key_features = shap_importance_df.head(15)['feature'].tolist()
        heatmap_data = []
        heatmap_labels = []
        
        for class_name in class_names:
            col = f'{class_name}_importance'
            if col in shap_importance_df.columns:
                class_importances = []
                for feature in key_features:
                    feature_idx = shap_importance_df[shap_importance_df['feature'] == feature].index
                    if len(feature_idx) > 0:
                        importance = shap_importance_df.loc[feature_idx[0], col]
                        class_importances.append(importance)
                    else:
                        class_importances.append(0)
                heatmap_data.append(class_importances)
                heatmap_labels.append(class_name.replace('_', '\n'))
        
        if heatmap_data:
            heatmap_array = np.array(heatmap_data)
            im = ax6.imshow(heatmap_array, cmap='YlOrRd', aspect='auto')
            
            # è®¾ç½®æ ‡ç­¾
            ax6.set_xticks(range(len(key_features)))
            ax6.set_xticklabels([f.split('_')[-1] if '_' in f else f for f in key_features], 
                              rotation=45, ha='right', fontsize=8)
            ax6.set_yticks(range(len(heatmap_labels)))
            ax6.set_yticklabels(heatmap_labels, fontsize=9)
            
            # æ·»åŠ æ•°å€¼æ ‡æ³¨
            for i in range(len(heatmap_labels)):
                for j in range(len(key_features)):
                    text = ax6.text(j, i, f'{heatmap_array[i, j]:.2f}',
                                   ha="center", va="center", color="black", fontsize=6)
            
            ax6.set_title('å…³é”®ç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾')
            
            # æ·»åŠ é¢œè‰²æ¡
            cbar = plt.colorbar(im, ax=ax6)
            cbar.set_label('SHAPé‡è¦æ€§')
        
        plt.tight_layout()
        plt.savefig(f"{self.save_path}/three_group_shap_comparison.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        # ä¿å­˜é‡è¦æ€§å¯¹æ¯”æ•°æ®
        shap_importance_df.to_csv(f"{self.save_path}/three_group_shap_importance.csv", index=False)
        print("âœ“ SHAPé‡è¦æ€§å¯¹æ¯”æ•°æ®å·²ä¿å­˜")
        
        return shap_importance_df
    
    def save_models_and_results(self):
        """ä¿å­˜æ¨¡å‹å’Œç»“æœ"""
        print("ğŸ’¾ ä¿å­˜æ¨¡å‹å’Œç»“æœ...")
        
        # ä¿å­˜å„åˆ†ç±»æ¨¡å‹
        for class_name, model in self.models.items():
            model_path = f"{self.save_path}/three_group_model_{class_name}.pkl"
            joblib.dump(model, model_path)
            print(f"âœ“ {class_name}æ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        # ä¿å­˜ç‰¹å¾åç§°
        feature_names_path = f"{self.save_path}/feature_names.pkl"
        joblib.dump(self.feature_names, feature_names_path)
        print(f"âœ“ ç‰¹å¾åç§°å·²ä¿å­˜: {feature_names_path}")
        
        # ä¿å­˜ä¸‰çº§é˜ˆå€¼
        thresholds_path = f"{self.save_path}/three_group_thresholds.pkl"
        joblib.dump(self.shear_thresholds, thresholds_path)
        print(f"âœ“ ä¸‰çº§é˜ˆå€¼å·²ä¿å­˜: {thresholds_path}")
        
        # ä¿å­˜ç‰©ç†æœºåˆ¶ä¿¡æ¯
        physics_path = f"{self.save_path}/shear_physics_info.pkl"
        joblib.dump(self.shear_physics, physics_path)
        print(f"âœ“ ç‰©ç†æœºåˆ¶ä¿¡æ¯å·²ä¿å­˜: {physics_path}")
        
        # ä¿å­˜ç»“æœæ‘˜è¦
        results_summary = {}
        for class_name in self.results:
            results_summary[class_name] = {
                'r2_test': self.results[class_name]['r2_test'],
                'rmse_test': self.results[class_name]['rmse_test'],
                'sample_count': self.results[class_name]['sample_count'],
                'power_mean': self.results[class_name]['power_mean'],
                'power_std': self.results[class_name]['power_std'],
                'shear_mean': self.results[class_name]['shear_mean'],
                'shear_std': self.results[class_name]['shear_std']
            }
        
        summary_path = f"{self.save_path}/three_group_results_summary.pkl"
        joblib.dump(results_summary, summary_path)
        print(f"âœ“ ç»“æœæ‘˜è¦å·²ä¿å­˜: {summary_path}")
        
        return results_summary
    
    def generate_physics_insights(self, performance_df):
        """ç”ŸæˆåŸºäºç‰©ç†æœºåˆ¶çš„æ´å¯Ÿåˆ†æ"""
        print("ğŸ”¬ ç”Ÿæˆç‰©ç†æœºåˆ¶æ´å¯Ÿåˆ†æ...")
        
        insights = {
            'classification_performance': {},
            'physical_consistency': {},
            'feature_mechanisms': {},
            'recommendations': []
        }
        
        # 1. åˆ†ç±»æ€§èƒ½åˆ†æ
        for _, row in performance_df.iterrows():
            class_name = row['classification']
            shear_type = class_name.split('_')[0]
            period = class_name.split('_')[1]
            
            insights['classification_performance'][class_name] = {
                'r2': row['r2'],
                'rmse': row['rmse'],
                'shear_level': shear_type,
                'time_period': period,
                'sample_size': row['samples'],
                'physical_expectation': self.get_physical_expectation(class_name),
                'performance_level': self.classify_performance(row['r2'])
            }
        
        # 2. ç‰©ç†ä¸€è‡´æ€§åˆ†æ
        best_performing = performance_df.iloc[0]['classification']
        worst_performing = performance_df.iloc[-1]['classification']
        
        insights['physical_consistency'] = {
            'best_class': best_performing,
            'worst_class': worst_performing,
            'performance_gap': performance_df.iloc[0]['r2'] - performance_df.iloc[-1]['r2'],
            'physical_explanation': self.explain_performance_difference(best_performing, worst_performing)
        }
        
        # 3. ç‰¹å¾æœºåˆ¶åˆ†æ
        if hasattr(self, 'results') and self.results:
            insights['feature_mechanisms'] = self.analyze_feature_mechanisms()
        
        # 4. å®ç”¨å»ºè®®
        insights['recommendations'] = self.generate_recommendations(performance_df)
        
        return insights
    
    def get_physical_expectation(self, class_name):
        """è·å–åˆ†ç±»çš„ç‰©ç†é¢„æœŸ"""
        if class_name in ['weak_day', 'moderate_day']:
            return "ä¸­é«˜é¢„æµ‹æ€§èƒ½ - ç™½å¤©è¾¹ç•Œå±‚æ··åˆå……åˆ†ï¼Œæ¹æµç‰¹å¾æ˜æ˜¾"
        elif class_name == 'strong_night':
            return "é«˜é¢„æµ‹æ€§èƒ½ - å¤œé—´ç¨³å®šå±‚ç»“ï¼Œé£å‰–é¢è§„å¾‹æ€§å¼º"
        elif class_name in ['weak_night', 'moderate_night']:
            return "ä¸­ç­‰é¢„æµ‹æ€§èƒ½ - è¿‡æ¸¡çŠ¶æ€ï¼Œç¨³å®šåº¦å˜åŒ–"
        elif class_name == 'strong_day':
            return "ä½é¢„æµ‹æ€§èƒ½ - ç‰©ç†å¼‚å¸¸çŠ¶æ€ï¼Œé¢„æµ‹å›°éš¾"
        else:
            return "æœªçŸ¥ç‰©ç†çŠ¶æ€"
    
    def classify_performance(self, r2):
        """åˆ†ç±»æ€§èƒ½æ°´å¹³"""
        if r2 > 0.8:
            return "ä¼˜ç§€"
        elif r2 > 0.6:
            return "è‰¯å¥½"
        elif r2 > 0.4:
            return "ä¸€èˆ¬"
        else:
            return "è¾ƒå·®"
    
    def explain_performance_difference(self, best_class, worst_class):
        """è§£é‡Šæ€§èƒ½å·®å¼‚çš„ç‰©ç†åŸå› """
        explanations = {
            'strong_night': "å¤œé—´å¼ºå±‚ç»“æ¡ä»¶ä¸‹é£å‰–é¢ç¨³å®šï¼Œåˆ‡å˜è§„å¾‹æ€§å¼º",
            'moderate_day': "ç™½å¤©ä¸­ç­‰åˆ‡å˜ä»£è¡¨å…¸å‹çš„ä¸­æ€§è¾¹ç•Œå±‚",
            'weak_day': "ç™½å¤©å¼±åˆ‡å˜è¡¨æ˜å¼ºæ··åˆï¼Œä½†ä»æœ‰ä¸€å®šè§„å¾‹æ€§",
            'strong_day': "ç™½å¤©å¼ºåˆ‡å˜ä¸ºå¼‚å¸¸çŠ¶æ€ï¼Œå¯èƒ½ç”±ç‰¹æ®Šå¤©æ°”å¼•èµ·",
            'weak_night': "å¤œé—´å¼±åˆ‡å˜å¯èƒ½ç”±æ®‹ä½™æ¹æµæˆ–ç‰¹æ®Šåœ°å½¢å¼•èµ·",
            'moderate_night': "å¤œé—´ä¸­ç­‰åˆ‡å˜ä»£è¡¨ç¨³å®šå±‚ç»“å»ºç«‹çš„è¿‡æ¸¡é˜¶æ®µ"
        }
        
        best_explanation = explanations.get(best_class, "æœªçŸ¥æœºåˆ¶")
        worst_explanation = explanations.get(worst_class, "æœªçŸ¥æœºåˆ¶")
        
        return {
            'best_mechanism': best_explanation,
            'worst_mechanism': worst_explanation,
            'physical_logic': f"æœ€ä½³æ€§èƒ½({best_class})çš„ç‰©ç†æœºåˆ¶æ›´ç¨³å®šè§„å¾‹ï¼Œè€Œæœ€å·®æ€§èƒ½({worst_class})å¯èƒ½æ¶‰åŠå¤æ‚çš„éçº¿æ€§è¿‡ç¨‹"
        }
    
    def analyze_feature_mechanisms(self):
        """åˆ†æç‰¹å¾é‡è¦æ€§çš„ç‰©ç†æœºåˆ¶"""
        mechanisms = {}
        
        # åˆ†æé£é€Ÿç‰¹å¾
        wind_features = [f for f in self.feature_names if 'wind_speed' in f]
        if len(wind_features) >= 2:
            mechanisms['wind_profile'] = "å¤šé«˜åº¦é£é€Ÿç‰¹å¾åæ˜ é£åˆ‡å˜å‰–é¢ç‰¹å¾"
        
        # åˆ†ææ¸©åº¦ç‰¹å¾
        temp_features = [f for f in self.feature_names if 'temperature' in f]
        if temp_features:
            mechanisms['thermal_stability'] = "æ¸©åº¦ç‰¹å¾å½±å“å¤§æ°”ç¨³å®šåº¦å’Œè¾¹ç•Œå±‚å‘å±•"
        
        # åˆ†æé£å‘ç‰¹å¾
        dir_features = [f for f in self.feature_names if 'wind_dir' in f]
        if dir_features:
            mechanisms['wind_direction'] = "é£å‘å˜åŒ–åæ˜ åœ°å½¢å½±å“å’Œè¾¹ç•Œå±‚ç»“æ„"
        
        return mechanisms
    
    def generate_recommendations(self, performance_df):
        """ç”Ÿæˆå®ç”¨å»ºè®®"""
        recommendations = []
        
        # åŸºäºæ€§èƒ½æ’åçš„å»ºè®®
        best_classes = performance_df.head(2)['classification'].tolist()
        worst_classes = performance_df.tail(2)['classification'].tolist()
        
        recommendations.append(f"ä¼˜å…ˆä½¿ç”¨{best_classes}æ¨¡å‹ï¼Œå…¶ç‰©ç†æœºåˆ¶æ¸…æ™°ä¸”é¢„æµ‹æ€§èƒ½ä¼˜ç§€")
        
        if any('strong_day' in cls for cls in worst_classes):
            recommendations.append("å¼ºåˆ‡å˜-ç™½å¤©ç»„åˆé¢„æµ‹å›°éš¾ï¼Œå»ºè®®ç»“åˆå¤©æ°”ç±»å‹è¿›è¡Œç»†åˆ†")
        
        if any('night' in cls for cls in best_classes):
            recommendations.append("å¤œé—´æ¡ä»¶ä¸‹çš„é¢„æµ‹æ¨¡å‹è¡¨ç°è¾ƒå¥½ï¼Œå¯é‡ç‚¹ä¼˜åŒ–å¤œé—´é¢„æµ‹ç­–ç•¥")
        
        # åŸºäºæ ·æœ¬æ•°é‡çš„å»ºè®®
        small_sample_classes = performance_df[performance_df['samples'] < 500]['classification'].tolist()
        if small_sample_classes:
            recommendations.append(f"å¢åŠ {small_sample_classes}ç±»å‹çš„è®­ç»ƒæ ·æœ¬ä»¥æå‡æ¨¡å‹ç¨³å®šæ€§")
        
        # åŸºäºç‰©ç†æœºåˆ¶çš„å»ºè®®
        recommendations.append("å»ºè®®ç»“åˆå±€åœ°æ°”è±¡è§‚æµ‹ï¼Œä¼˜åŒ–åˆ‡å˜é˜ˆå€¼è®¾å®š")
        recommendations.append("è€ƒè™‘å¼•å…¥ç¨³å®šåº¦å‚æ•°(å¦‚Richardsonæ•°)è¿›ä¸€æ­¥ç»†åŒ–åˆ†ç±»")
        
        return recommendations
    
    def run_full_three_group_analysis(self):
        """è¿è¡Œå®Œæ•´çš„ä¸‰çº§é£åˆ‡å˜åˆ†ææµç¨‹"""
        print("=" * 70)
        print("ğŸŒªï¸ ä¸‰çº§é£åˆ‡å˜-æ˜¼å¤œåˆ†ç±»é£ç”µé¢„æµ‹åˆ†æ")
        print("=" * 70)
        
        try:
            # 1. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
            self.load_and_prepare_data()
            
            # 2. è®¡ç®—é£åˆ‡å˜ç³»æ•°
            h1, h2 = self.calculate_wind_shear()
            
            # 3. ä¸‰çº§é£åˆ‡å˜åˆ†ç±»
            shear_counts, shear_stats = self.classify_three_group_shear()
            
            # 4. ç¡®å®šæ˜¼å¤œåˆ†ç±»
            day_start, day_end = self.determine_day_night()
            
            # 5. åˆ›å»ºä¸‰çº§ç»„åˆåˆ†ç±»
            class_stats = self.create_three_group_classification()
            
            # 6. å¯è§†åŒ–åˆ†ç±»ç»“æœ
            self.visualize_three_group_classification()
            
            # 7. æŒ‰åˆ†ç±»åˆ†ç»„
            self.prepare_classification_groups(min_samples=200)
            
            # 8. è®­ç»ƒåˆ†ç±»æ¨¡å‹
            self.train_three_group_models()
            
            # 9. è®¡ç®—SHAPå€¼
            self.calculate_shap_values()
            
            # 10. ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”
            performance_df = self.plot_performance_comparison()
            
            # 11. ç»˜åˆ¶SHAPå¯¹æ¯”
            shap_comparison = self.plot_shap_comparison()
            
            # 12. ç”Ÿæˆç‰©ç†æ´å¯Ÿ
            insights = self.generate_physics_insights(performance_df)
            
            # 13. ä¿å­˜æ¨¡å‹å’Œç»“æœ
            results_summary = self.save_models_and_results()
            
            print("\n" + "=" * 70)
            print("ğŸ‰ ä¸‰çº§é£åˆ‡å˜åˆ†æå®Œæˆï¼")
            print("=" * 70)
            
            print("ğŸ“Š ä¸»è¦å‘ç°:")
            print(f"  é£åˆ‡å˜è®¡ç®—: ä½¿ç”¨ {h1}m å’Œ {h2}m é«˜åº¦æ•°æ®")
            print(f"  ä¸‰çº§é˜ˆå€¼: å¼±åˆ‡å˜(Î±<{self.shear_thresholds['weak_upper']}), "
                  f"ä¸­ç­‰åˆ‡å˜({self.shear_thresholds['weak_upper']}â‰¤Î±<{self.shear_thresholds['moderate_upper']}), "
                  f"å¼ºåˆ‡å˜(Î±â‰¥{self.shear_thresholds['moderate_upper']})")
            print(f"  æ˜¼å¤œåˆ’åˆ†: {day_start}:00-{day_end}:00ä¸ºç™½å¤©")
            print(f"  è®­ç»ƒçš„åˆ†ç±»æ¨¡å‹æ•°é‡: {len(self.models)}")
            print(f"  åˆ†ç±»ç±»å‹: {list(self.models.keys())}")
            
            if performance_df is not None and len(performance_df) > 0:
                best_class = performance_df.iloc[0]['classification']
                best_r2 = performance_df.iloc[0]['r2']
                worst_class = performance_df.iloc[-1]['classification']
                worst_r2 = performance_df.iloc[-1]['r2']
                
                print(f"  æœ€ä½³é¢„æµ‹æ€§èƒ½: {best_class} (RÂ²={best_r2:.3f})")
                print(f"  æœ€ä½é¢„æµ‹æ€§èƒ½: {worst_class} (RÂ²={worst_r2:.3f})")
                
                r2_range = best_r2 - worst_r2
                print(f"  æ€§èƒ½å·®è·: {r2_range:.3f}")
                
                if r2_range > 0.15:
                    print("  â†’ ä¸‰çº§é£åˆ‡å˜åˆ†ç±»å¾ˆæœ‰ä»·å€¼ï¼Œä¸åŒæ¡ä»¶ä¸‹é¢„æµ‹å·®å¼‚æ˜¾è‘—")
                elif r2_range > 0.08:
                    print("  â†’ ä¸‰çº§åˆ†ç±»æœ‰ä¸€å®šä»·å€¼ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–é˜ˆå€¼")
                else:
                    print("  â†’ å„åˆ†ç±»é¢„æµ‹æ€§èƒ½ç›¸è¿‘ï¼Œå¯è€ƒè™‘ç®€åŒ–åˆ†ç±»ç­–ç•¥")
            
            # è¾“å‡ºç‰©ç†æ´å¯Ÿ
            print(f"\nğŸ”¬ ç‰©ç†æœºåˆ¶æ´å¯Ÿ:")
            if insights['physical_consistency']:
                best = insights['physical_consistency']['best_class']
                worst = insights['physical_consistency']['worst_class']
                gap = insights['physical_consistency']['performance_gap']
                
                print(f"  æœ€ä½³ç»„åˆ: {best} - ç‰©ç†æœºåˆ¶ç¨³å®š")
                print(f"  æœ€å·®ç»„åˆ: {worst} - å¯èƒ½æ¶‰åŠå¤æ‚éçº¿æ€§è¿‡ç¨‹")
                print(f"  æ€§èƒ½å·®è·: {gap:.3f}")
            
            # è¾“å‡ºå®ç”¨å»ºè®®
            print(f"\nğŸ’¡ å®ç”¨å»ºè®®:")
            if insights['recommendations']:
                for i, rec in enumerate(insights['recommendations'], 1):
                    print(f"  {i}. {rec}")
            
            print(f"\nğŸ“ ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: {self.save_path}")
            print("  - three_group_classification.png: ä¸‰çº§åˆ†ç±»åˆ†æ")
            print("  - three_group_performance.png: æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
            print("  - three_group_shap_comparison.png: SHAPé‡è¦æ€§å¯¹æ¯”")
            print("  - three_group_shap_importance.csv: è¯¦ç»†é‡è¦æ€§æ•°æ®")
            
            # åˆ†æå„ç»„åˆçš„æ•°æ®åˆ†å¸ƒ
            print(f"\nğŸ“ˆ æ•°æ®åˆ†å¸ƒåˆ†æ:")
            for shear_type in ['weak', 'moderate', 'strong']:
                day_count = shear_counts.get(f'{shear_type}_day', 0) if hasattr(self, 'data') else 0
                night_count = shear_counts.get(f'{shear_type}_night', 0) if hasattr(self, 'data') else 0
                
                # ç›´æ¥ä»self.dataç»Ÿè®¡
                if hasattr(self, 'data') and 'three_group_class' in self.data.columns:
                    day_count = len(self.data[self.data['three_group_class'] == f'{shear_type}_day'])
                    night_count = len(self.data[self.data['three_group_class'] == f'{shear_type}_night'])
                    total = len(self.data)
                    
                    print(f"  {shear_type}åˆ‡å˜: ç™½å¤©{day_count}æ¡({day_count/total*100:.1f}%), "
                          f"å¤œé—´{night_count}æ¡({night_count/total*100:.1f}%)")
            
            return True
            
        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

if __name__ == "__main__":
    # é…ç½®è·¯å¾„
    DATA_PATH = "/Users/xiaxin/work/WindForecast_Project/01_Data/processed/imputed_data/changma_imputed_complete.csv"
    SAVE_PATH = "/Users/xiaxin/work/WindForecast_Project/03_Results/SHAP-three_group_wind_shear_analysis"
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    import os
    os.makedirs(SAVE_PATH, exist_ok=True)
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ
    analyzer = ThreeGroupWindShearAnalyzer(DATA_PATH, SAVE_PATH)
    success = analyzer.run_full_three_group_analysis()
    
    if success:
        print("\nğŸ¯ ä¸‰çº§é£åˆ‡å˜åˆ†ææˆåŠŸå®Œæˆï¼")
        print("\nğŸ’¡ æ ¸å¿ƒä¼˜åŠ¿:")
        print("  1. æ›´ç²¾ç»†çš„ç‰©ç†åˆ†ç±» - å¼±/ä¸­/å¼ºä¸‰çº§åˆ‡å˜æ›´ç¬¦åˆå¤§æ°”ç‰©ç†")
        print("  2. ç‰©ç†æœºåˆ¶æ¸…æ™° - æ¯ç§ç»„åˆéƒ½æœ‰æ˜ç¡®çš„è¾¹ç•Œå±‚ç‰©ç†è§£é‡Š")
        print("  3. é¢„æµ‹ç­–ç•¥å·®å¼‚åŒ– - ä¸åŒæ¡ä»¶ä¸‹é‡‡ç”¨æœ€é€‚åˆçš„é¢„æµ‹æ¨¡å‹")
        print("  4. å·¥ç¨‹åº”ç”¨ä»·å€¼ - å¯æ ¹æ®å®æ—¶æ°”è±¡æ¡ä»¶é€‰æ‹©æœ€ä¼˜æ¨¡å‹")
        print("\nğŸ”® åç»­ç ”ç©¶æ–¹å‘:")
        print("  1. ç»“åˆRichardsonæ•°ç­‰ç¨³å®šåº¦å‚æ•°è¿›ä¸€æ­¥ç»†åŒ–")
        print("  2. åˆ†æå­£èŠ‚æ€§å¯¹ä¸‰çº§åˆ†ç±»æ•ˆæœçš„å½±å“")
        print("  3. å¼€å‘å®æ—¶åˆ†ç±»è¯†åˆ«å’Œæ¨¡å‹åˆ‡æ¢ç³»ç»Ÿ")
        print("  4. éªŒè¯åœ¨ä¸åŒåœ°å½¢æ¡ä»¶ä¸‹çš„é€‚ç”¨æ€§")
        print("  5. æ¢ç´¢ä¸å¤©æ°”ç±»å‹çš„è€¦åˆåˆ†ç±»ç­–ç•¥")
    else:
        print("\nâš ï¸ åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å’Œæ•°æ®è·¯å¾„")