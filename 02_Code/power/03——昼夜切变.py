#!/usr/bin/env python3
"""
åŸºäºé£åˆ‡å˜-æ˜¼å¤œåˆ†ç±»çš„é£ç”µé¢„æµ‹ä¸SHAPé‡è¦æ€§åˆ†æ
åˆ†ç±»ç­–ç•¥ï¼šé«˜é£åˆ‡å˜+ç™½å¤© / ä½é£åˆ‡å˜+å¤œé—´
Author: Research Team
Date: 2025-06-09
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import lightgbm as lgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import shap
from datetime import datetime, time
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class WindShearDiurnalAnalyzer:
    def __init__(self, data_path, save_path):
        self.data_path = data_path
        self.save_path = save_path
        self.data = None
        self.groups = {}
        self.feature_names = None
        self.models = {}
        self.shap_explainers = {}
        self.results = {}
        self.wind_shear_threshold = None
        
    def load_and_prepare_data(self):
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
        print("ğŸ“Š åŠ è½½å’Œé¢„å¤„ç†æ•°æ®...")
        
        # åŠ è½½æ•°æ®
        self.data = pd.read_csv(self.data_path)
        print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {self.data.shape}")
        
        # è½¬æ¢datetimeåˆ—
        self.data['datetime'] = pd.to_datetime(self.data['datetime'])
        
        # é€‰æ‹©è§‚æµ‹æ•°æ®åˆ—
        obs_columns = [col for col in self.data.columns if col.startswith('obs_')]
        obs_columns += ['datetime', 'power']
        
        # ç§»é™¤å¯†åº¦å’Œæ¹¿åº¦
        obs_columns = [col for col in obs_columns if 'density' not in col and 'humidity' not in col]
        
        self.data = self.data[obs_columns].copy()
        print(f"é€‰æ‹©åˆ—æ•°: {len(obs_columns)-2}")
        
        # ç§»é™¤ç¼ºå¤±å€¼å’Œè´ŸåŠŸç‡
        initial_shape = self.data.shape[0]
        self.data = self.data.dropna()
        self.data = self.data[self.data['power'] >= 0]
        final_shape = self.data.shape[0]
        print(f"æ¸…ç†åæ•°æ®: {final_shape} è¡Œ (ç§»é™¤äº† {initial_shape - final_shape} è¡Œ)")
        
        return self.data
    
    def calculate_wind_shear(self):
        """è®¡ç®—é£åˆ‡å˜ç³»æ•°"""
        print("ğŸŒªï¸ è®¡ç®—é£åˆ‡å˜ç³»æ•°...")
        
        # æ‰¾åˆ°ä¸åŒé«˜åº¦çš„é£é€Ÿåˆ—
        wind_speed_cols = [col for col in self.data.columns if 'wind_speed' in col and col.startswith('obs_')]
        wind_speed_cols.sort()  # æŒ‰åç§°æ’åºï¼Œé€šå¸¸åŒ…å«é«˜åº¦ä¿¡æ¯
        
        print(f"å‘ç°é£é€Ÿåˆ—: {wind_speed_cols}")
        
        if len(wind_speed_cols) < 2:
            raise ValueError("éœ€è¦è‡³å°‘2ä¸ªé«˜åº¦çš„é£é€Ÿæ•°æ®æ¥è®¡ç®—é£åˆ‡å˜")
        
        # è®¡ç®—é£åˆ‡å˜ç³»æ•° Î±ï¼Œä½¿ç”¨é£é€Ÿå‰–é¢å…¬å¼: V(z) = V(z_ref) * (z/z_ref)^Î±
        # Î± = ln(V2/V1) / ln(z2/z1)
        
        # æå–é«˜åº¦ä¿¡æ¯ï¼ˆå‡è®¾åˆ—åæ ¼å¼ä¸º obs_wind_speed_XXXmï¼‰
        heights = []
        wind_speeds = {}
        
        for col in wind_speed_cols:
            try:
                # æå–é«˜åº¦æ•°å­—
                height_str = col.split('_')[-1].replace('m', '')
                height = float(height_str)
                heights.append(height)
                wind_speeds[height] = self.data[col]
                print(f"  {col} -> {height}m")
            except:
                print(f"  è­¦å‘Š: æ— æ³•ä» {col} æå–é«˜åº¦ä¿¡æ¯")
        
        if len(heights) < 2:
            raise ValueError("æ— æ³•æå–è¶³å¤Ÿçš„é«˜åº¦ä¿¡æ¯")
        
        heights.sort()
        print(f"âœ“ å¯ç”¨é«˜åº¦: {heights} m")
        
        # è®¡ç®—é£åˆ‡å˜ç³»æ•°ï¼ˆä½¿ç”¨æœ€ä½å’Œæœ€é«˜ä¸¤ä¸ªé«˜åº¦ï¼‰
        h1, h2 = heights[0], heights[-1]
        v1, v2 = wind_speeds[h1], wind_speeds[h2]
        
        # é¿å…é™¤é›¶å’Œå¯¹æ•°é”™è¯¯
        valid_mask = (v1 > 0.5) & (v2 > 0.5)  # é£é€Ÿå¤§äº0.5m/s
        
        self.data = self.data[valid_mask].copy()
        v1, v2 = v1[valid_mask], v2[valid_mask]
        
        # è®¡ç®—é£åˆ‡å˜ç³»æ•°
        self.data['wind_shear_alpha'] = np.log(v2 / v1) / np.log(h2 / h1)
        
        print(f"âœ“ é£åˆ‡å˜è®¡ç®—å®Œæˆï¼Œä½¿ç”¨ {h1}m å’Œ {h2}m é«˜åº¦")
        print(f"  æœ‰æ•ˆæ•°æ®: {len(self.data)} æ¡")
        print(f"  é£åˆ‡å˜èŒƒå›´: {self.data['wind_shear_alpha'].min():.3f} ~ {self.data['wind_shear_alpha'].max():.3f}")
        print(f"  é£åˆ‡å˜å‡å€¼: {self.data['wind_shear_alpha'].mean():.3f}")
        
        return h1, h2
    
    def determine_day_night(self):
        """ç¡®å®šæ˜¼å¤œåˆ†ç±»"""
        print("â˜€ï¸ğŸŒ™ ç¡®å®šæ˜¼å¤œåˆ†ç±»...")
        
        # æå–å°æ—¶ä¿¡æ¯
        self.data['hour'] = self.data['datetime'].dt.hour
        
        # ç®€å•çš„æ˜¼å¤œåˆ’åˆ†ï¼ˆ6:00-18:00ä¸ºç™½å¤©ï¼‰
        # å¯ä»¥æ ¹æ®å®é™…åœ°ç†ä½ç½®å’Œå­£èŠ‚è°ƒæ•´
        day_start, day_end = 6, 18
        
        self.data['is_daytime'] = ((self.data['hour'] >= day_start) & 
                                  (self.data['hour'] < day_end))
        
        day_count = self.data['is_daytime'].sum()
        night_count = len(self.data) - day_count
        
        print(f"âœ“ æ˜¼å¤œåˆ†ç±»å®Œæˆ:")
        print(f"  ç™½å¤© ({day_start}:00-{day_end}:00): {day_count} æ¡")
        print(f"  å¤œé—´: {night_count} æ¡")
        
        return day_start, day_end
    
    def analyze_wind_shear_diurnal_pattern(self):
        """åˆ†æé£åˆ‡å˜çš„æ—¥å˜åŒ–æ¨¡å¼"""
        print("ğŸ“ˆ åˆ†æé£åˆ‡å˜æ—¥å˜åŒ–æ¨¡å¼...")
        
        # è®¡ç®—æ¯å°æ—¶çš„é£åˆ‡å˜ç»Ÿè®¡
        hourly_shear = self.data.groupby('hour')['wind_shear_alpha'].agg(['mean', 'std', 'count']).reset_index()
        
        # ç»˜åˆ¶é£åˆ‡å˜æ—¥å˜åŒ–
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('é£åˆ‡å˜ç³»æ•°çš„æ—¥å˜åŒ–ç‰¹å¾åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. é£åˆ‡å˜æ—¥å˜åŒ–æ›²çº¿
        ax1 = axes[0, 0]
        ax1.plot(hourly_shear['hour'], hourly_shear['mean'], 'b-', linewidth=2, marker='o')
        ax1.fill_between(hourly_shear['hour'], 
                        hourly_shear['mean'] - hourly_shear['std'],
                        hourly_shear['mean'] + hourly_shear['std'], 
                        alpha=0.3)
        ax1.axhspan(self.data['wind_shear_alpha'].quantile(0.5), 
                   self.data['wind_shear_alpha'].max(), alpha=0.2, color='orange', label='é«˜é£åˆ‡å˜åŒºé—´')
        ax1.axhspan(self.data['wind_shear_alpha'].min(),
                   self.data['wind_shear_alpha'].quantile(0.5), alpha=0.2, color='blue', label='ä½é£åˆ‡å˜åŒºé—´')
        
        ax1.set_xlabel('å°æ—¶')
        ax1.set_ylabel('é£åˆ‡å˜ç³»æ•° Î±')
        ax1.set_title('é£åˆ‡å˜ç³»æ•°æ—¥å˜åŒ–')
        ax1.grid(True, alpha=0.3)
        ax1.legend()
        ax1.set_xticks(range(0, 24, 2))
        
        # 2. æ˜¼å¤œé£åˆ‡å˜åˆ†å¸ƒå¯¹æ¯”
        ax2 = axes[0, 1]
        day_shear = self.data[self.data['is_daytime']]['wind_shear_alpha']
        night_shear = self.data[~self.data['is_daytime']]['wind_shear_alpha']
        
        ax2.hist(day_shear, bins=50, alpha=0.6, label=f'ç™½å¤© (Î¼={day_shear.mean():.3f})', color='orange')
        ax2.hist(night_shear, bins=50, alpha=0.6, label=f'å¤œé—´ (Î¼={night_shear.mean():.3f})', color='navy')
        ax2.set_xlabel('é£åˆ‡å˜ç³»æ•° Î±')
        ax2.set_ylabel('é¢‘æ¬¡')
        ax2.set_title('æ˜¼å¤œé£åˆ‡å˜åˆ†å¸ƒå¯¹æ¯”')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. é£åˆ‡å˜ä¸åŠŸç‡å…³ç³»
        ax3 = axes[1, 0]
        ax3.scatter(self.data['wind_shear_alpha'], self.data['power'], alpha=0.3, s=10)
        
        # è®¡ç®—åˆ†ç»„å¹³å‡å€¼
        shear_bins = np.linspace(self.data['wind_shear_alpha'].min(), 
                                self.data['wind_shear_alpha'].max(), 20)
        self.data['shear_bin'] = pd.cut(self.data['wind_shear_alpha'], bins=shear_bins)
        bin_stats = self.data.groupby('shear_bin')['power'].agg(['mean', 'count']).reset_index()
        bin_centers = [(interval.left + interval.right) / 2 for interval in bin_stats['shear_bin']]
        
        ax3.plot(bin_centers, bin_stats['mean'], 'r-', linewidth=2, label='åˆ†ç»„å¹³å‡å€¼')
        ax3.set_xlabel('é£åˆ‡å˜ç³»æ•° Î±')
        ax3.set_ylabel('åŠŸç‡ (MW)')
        ax3.set_title('é£åˆ‡å˜ä¸åŠŸç‡å…³ç³»')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. ç›¸å…³æ€§åˆ†æè¡¨
        ax4 = axes[1, 1]
        ax4.axis('tight')
        ax4.axis('off')
        
        # è®¡ç®—ç›¸å…³æ€§ç»Ÿè®¡
        corr_stats = []
        corr_stats.append(['æ•´ä½“', f"{self.data['wind_shear_alpha'].corr(self.data['power']):.3f}"])
        corr_stats.append(['ç™½å¤©', f"{day_shear.corr(self.data[self.data['is_daytime']]['power']):.3f}"])
        corr_stats.append(['å¤œé—´', f"{night_shear.corr(self.data[~self.data['is_daytime']]['power']):.3f}"])
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_data = [
            ['æŒ‡æ ‡', 'ç™½å¤©', 'å¤œé—´', 'å·®å¼‚'],
            ['æ ·æœ¬æ•°', f"{len(day_shear)}", f"{len(night_shear)}", f"{len(day_shear)-len(night_shear)}"],
            ['é£åˆ‡å˜å‡å€¼', f"{day_shear.mean():.3f}", f"{night_shear.mean():.3f}", f"{day_shear.mean()-night_shear.mean():.3f}"],
            ['é£åˆ‡å˜æ ‡å‡†å·®', f"{day_shear.std():.3f}", f"{night_shear.std():.3f}", f"{day_shear.std()-night_shear.std():.3f}"],
            ['åŠŸç‡å‡å€¼(MW)', f"{self.data[self.data['is_daytime']]['power'].mean():.1f}", 
             f"{self.data[~self.data['is_daytime']]['power'].mean():.1f}",
             f"{self.data[self.data['is_daytime']]['power'].mean()-self.data[~self.data['is_daytime']]['power'].mean():.1f}"]
        ]
        
        table = ax4.table(cellText=stats_data,
                         cellLoc='center',
                         loc='center')
        table.auto_set_font_size(False)
        table.set_fontsize(9)
        table.scale(1.2, 1.5)
        ax4.set_title('æ˜¼å¤œé£åˆ‡å˜ç»Ÿè®¡å¯¹æ¯”', pad=20)
        
        plt.tight_layout()
        plt.savefig(f"{self.save_path}/wind_shear_diurnal_analysis.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        return hourly_shear, day_shear.mean(), night_shear.mean()
    
    def create_shear_diurnal_classification(self):
        """åˆ›å»ºé£åˆ‡å˜-æ˜¼å¤œç»„åˆåˆ†ç±»"""
        print("ğŸ”„ åˆ›å»ºé£åˆ‡å˜-æ˜¼å¤œç»„åˆåˆ†ç±»...")
        
        # ç¡®å®šé£åˆ‡å˜é˜ˆå€¼ï¼ˆä½¿ç”¨ä¸­ä½æ•°ï¼‰
        self.wind_shear_threshold = self.data['wind_shear_alpha'].median()
        print(f"é£åˆ‡å˜é˜ˆå€¼ï¼ˆä¸­ä½æ•°ï¼‰: {self.wind_shear_threshold:.3f}")
        
        # åˆ›å»ºé«˜/ä½é£åˆ‡å˜æ ‡è¯†
        self.data['high_shear'] = self.data['wind_shear_alpha'] > self.wind_shear_threshold
        
        # åˆ›å»ºç»„åˆåˆ†ç±»
        conditions = [
            self.data['high_shear'] & self.data['is_daytime'],      # é«˜é£åˆ‡å˜ + ç™½å¤©
            ~self.data['high_shear'] & ~self.data['is_daytime'],   # ä½é£åˆ‡å˜ + å¤œé—´
            self.data['high_shear'] & ~self.data['is_daytime'],    # é«˜é£åˆ‡å˜ + å¤œé—´
            ~self.data['high_shear'] & self.data['is_daytime']     # ä½é£åˆ‡å˜ + ç™½å¤©
        ]
        
        choices = [
            'high_shear_day',     # é«˜é£åˆ‡å˜ç™½å¤©
            'low_shear_night',    # ä½é£åˆ‡å˜å¤œé—´
            'high_shear_night',   # é«˜é£åˆ‡å˜å¤œé—´
            'low_shear_day'       # ä½é£åˆ‡å˜ç™½å¤©
        ]
        
        self.data['shear_diurnal_class'] = np.select(conditions, choices, default='unknown')
        
        # ç»Ÿè®¡å„åˆ†ç±»çš„æ•°é‡å’Œç‰¹å¾
        class_stats = self.data.groupby('shear_diurnal_class').agg({
            'power': ['count', 'mean', 'std'],
            'wind_shear_alpha': ['mean', 'std']
        }).round(3)
        
        print("\nğŸ“Š é£åˆ‡å˜-æ˜¼å¤œåˆ†ç±»ç»Ÿè®¡:")
        print("=" * 80)
        for class_name in choices:
            if class_name in class_stats.index:
                count = class_stats.loc[class_name, ('power', 'count')]
                power_mean = class_stats.loc[class_name, ('power', 'mean')]
                power_std = class_stats.loc[class_name, ('power', 'std')]
                shear_mean = class_stats.loc[class_name, ('wind_shear_alpha', 'mean')]
                shear_std = class_stats.loc[class_name, ('wind_shear_alpha', 'std')]
                percentage = count / len(self.data) * 100
                
                print(f"{class_name}:")
                print(f"  æ ·æœ¬æ•°: {count} ({percentage:.1f}%)")
                print(f"  åŠŸç‡: {power_mean:.1f}Â±{power_std:.1f} MW")
                print(f"  é£åˆ‡å˜: {shear_mean:.3f}Â±{shear_std:.3f}")
                print("-" * 50)
        
        # å¯è§†åŒ–åˆ†ç±»ç»“æœ
        self.visualize_classification()
        
        return class_stats
    
    def visualize_classification(self):
        """å¯è§†åŒ–åˆ†ç±»ç»“æœ"""
        print("ğŸ“Š å¯è§†åŒ–åˆ†ç±»ç»“æœ...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('é£åˆ‡å˜-æ˜¼å¤œåˆ†ç±»ç»“æœå¯è§†åŒ–', fontsize=16, fontweight='bold')
        
        # 1. åˆ†ç±»æ•£ç‚¹å›¾
        ax1 = axes[0, 0]
        classes = self.data['shear_diurnal_class'].unique()
        colors = ['red', 'blue', 'orange', 'green']
        
        for i, class_name in enumerate(classes):
            if class_name != 'unknown':
                class_data = self.data[self.data['shear_diurnal_class'] == class_name]
                ax1.scatter(class_data['wind_shear_alpha'], class_data['power'], 
                           alpha=0.6, s=20, label=class_name, color=colors[i % len(colors)])
        
        ax1.axvline(x=self.wind_shear_threshold, color='black', linestyle='--', 
                   alpha=0.7, label=f'é£åˆ‡å˜é˜ˆå€¼={self.wind_shear_threshold:.3f}')
        ax1.set_xlabel('é£åˆ‡å˜ç³»æ•° Î±')
        ax1.set_ylabel('åŠŸç‡ (MW)')
        ax1.set_title('é£åˆ‡å˜-åŠŸç‡åˆ†ç±»æ•£ç‚¹å›¾')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. å„åˆ†ç±»åŠŸç‡åˆ†å¸ƒ
        ax2 = axes[0, 1]
        power_data_by_class = []
        class_labels = []
        
        for class_name in ['high_shear_day', 'low_shear_night', 'high_shear_night', 'low_shear_day']:
            if class_name in self.data['shear_diurnal_class'].values:
                power_data = self.data[self.data['shear_diurnal_class'] == class_name]['power']
                power_data_by_class.append(power_data)
                class_labels.append(class_name.replace('_', '\n'))
        
        ax2.boxplot(power_data_by_class, labels=class_labels)
        ax2.set_ylabel('åŠŸç‡ (MW)')
        ax2.set_title('å„åˆ†ç±»åŠŸç‡åˆ†å¸ƒ')
        ax2.tick_params(axis='x', rotation=0)
        ax2.grid(True, alpha=0.3)
        
        # 3. æ—¶é—´åºåˆ—æ¨¡å¼
        ax3 = axes[1, 0]
        hourly_class = self.data.groupby(['hour', 'shear_diurnal_class']).size().unstack(fill_value=0)
        hourly_class_pct = hourly_class.div(hourly_class.sum(axis=1), axis=0) * 100
        
        if not hourly_class_pct.empty:
            hourly_class_pct.plot(kind='area', stacked=True, ax=ax3, alpha=0.7)
            ax3.set_xlabel('å°æ—¶')
            ax3.set_ylabel('ç™¾åˆ†æ¯” (%)')
            ax3.set_title('åˆ†ç±»çš„æ—¥å˜åŒ–æ¨¡å¼')
            ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax3.grid(True, alpha=0.3)
        
        # 4. åˆ†ç±»ç‰¹å¾å¯¹æ¯”é›·è¾¾å›¾
        ax4 = axes[1, 1]
        
        # è®¡ç®—å„åˆ†ç±»çš„æ ‡å‡†åŒ–ç‰¹å¾
        class_features = self.data.groupby('shear_diurnal_class').agg({
            'power': 'mean',
            'wind_shear_alpha': 'mean'
        })
        
        # æ·»åŠ ç¬¬ä¸€ä¸ªé£é€Ÿåˆ—ä½œä¸ºå‚è€ƒ
        wind_speed_cols = [col for col in self.data.columns if 'wind_speed' in col and col.startswith('obs_')]
        if wind_speed_cols:
            main_wind_col = wind_speed_cols[0]
            class_features[main_wind_col] = self.data.groupby('shear_diurnal_class')[main_wind_col].mean()
        
        # æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
        class_features_norm = (class_features - class_features.min()) / (class_features.max() - class_features.min())
        
        # ç»˜åˆ¶ç®€åŒ–çš„ç‰¹å¾å¯¹æ¯”
        if not class_features_norm.empty:
            class_features_norm.plot(kind='bar', ax=ax4, alpha=0.7)
            ax4.set_title('å„åˆ†ç±»æ ‡å‡†åŒ–ç‰¹å¾å¯¹æ¯”')
            ax4.set_xlabel('åˆ†ç±»')
            ax4.set_ylabel('æ ‡å‡†åŒ–æ•°å€¼')
            ax4.tick_params(axis='x', rotation=45)
            ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{self.save_path}/shear_diurnal_classification.png", dpi=300, bbox_inches='tight')
        plt.show()
    
    def prepare_classification_groups(self, min_samples=300):
        """æŒ‰åˆ†ç±»åˆ†ç»„æ•°æ®"""
        print(f"ğŸ“Š æŒ‰åˆ†ç±»åˆ†ç»„æ•°æ® (æœ€å°æ ·æœ¬æ•°: {min_samples})...")
        
        class_counts = self.data['shear_diurnal_class'].value_counts()
        print(f"æ‰€æœ‰åˆ†ç±»æ ·æœ¬æ•°: {dict(class_counts)}")
        
        # åªé€‰æ‹©æ ·æœ¬æ•°è¶³å¤Ÿçš„åˆ†ç±»
        valid_classes = class_counts[class_counts >= min_samples].index.tolist()
        valid_classes = [cls for cls in valid_classes if cls != 'unknown']
        
        print(f"æ ·æœ¬æ•°è¶³å¤Ÿçš„åˆ†ç±»: {valid_classes}")
        
        for class_name in valid_classes:
            class_data = self.data[self.data['shear_diurnal_class'] == class_name].copy()
            self.groups[class_name] = class_data
            print(f"  {class_name}: {len(class_data)} æ¡æ ·æœ¬")
        
        return self.groups
    
    def process_wind_direction(self, data):
        """å¤„ç†é£å‘å˜é‡ä¸ºsin/cosåˆ†é‡"""
        data = data.copy()
        wind_dir_cols = [col for col in data.columns if 'wind_direction' in col]
        
        if wind_dir_cols:
            for col in wind_dir_cols:
                # æ°”è±¡è§’åº¦è½¬æ¢ä¸ºæ•°å­¦è§’åº¦
                math_angle = (90 - data[col] + 360) % 360
                wind_dir_rad = np.deg2rad(math_angle)
                
                # åˆ›å»ºsin/cosåˆ†é‡
                sin_col = col.replace('wind_direction', 'wind_dir_sin')
                cos_col = col.replace('wind_direction', 'wind_dir_cos')
                
                data[sin_col] = np.sin(wind_dir_rad)
                data[cos_col] = np.cos(wind_dir_rad)
            
            # ç§»é™¤åŸå§‹é£å‘åˆ—
            data = data.drop(columns=wind_dir_cols)
        
        return data
    
    def train_classification_models(self):
        """ä¸ºæ¯ç§åˆ†ç±»è®­ç»ƒç‹¬ç«‹çš„é¢„æµ‹æ¨¡å‹"""
        print("ğŸš€ è®­ç»ƒåˆ†ç±»æ¨¡å‹...")
        
        # LightGBMåŸºç¡€å‚æ•°
        base_params = {
            'objective': 'regression',
            'metric': 'rmse',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.1,
            'n_estimators': 200,
            'reg_alpha': 0.1,
            'reg_lambda': 0.1,
            'min_child_samples': 20,
            'random_state': 42,
            'verbose': -1,
            'n_jobs': -1
        }
        
        for class_name, data in self.groups.items():
            print(f"\nè®­ç»ƒ {class_name} æ¨¡å‹...")
            print(f"æ•°æ®é‡: {len(data)} æ¡")
            
            # å¤„ç†é£å‘å’Œå‡†å¤‡ç‰¹å¾
            data_processed = self.process_wind_direction(data)
            
            # é€‰æ‹©ç‰¹å¾åˆ—
            exclude_cols = ['datetime', 'power', 'hour', 'is_daytime', 'wind_shear_alpha',
                          'high_shear', 'shear_diurnal_class', 'shear_bin']
            feature_cols = [col for col in data_processed.columns if col not in exclude_cols]
            
            # åˆ›å»ºç‰¹å¾çŸ©é˜µ
            X = data_processed[feature_cols].values
            y = data_processed['power'].values
            
            # ä¿å­˜ç‰¹å¾åç§°
            if self.feature_names is None:
                self.feature_names = feature_cols
                print(f"  è®¾ç½®ç‰¹å¾åç§°ï¼Œå…± {len(feature_cols)} ä¸ªç‰¹å¾")
            
            print(f"  ç‰¹å¾æ•°é‡: {len(feature_cols)}")
            print(f"  åŠŸç‡èŒƒå›´: {y.min():.1f} - {y.max():.1f} MW")
            print(f"  åŠŸç‡å‡å€¼: {y.mean():.1f} MW")
            print(f"  é£åˆ‡å˜èŒƒå›´: {data['wind_shear_alpha'].min():.3f} - {data['wind_shear_alpha'].max():.3f}")
            
            # æ•°æ®åˆ†å‰²
            if len(data) >= 100:
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42
                )
                
                # è®­ç»ƒæ¨¡å‹
                model = lgb.LGBMRegressor(**base_params)
                model.fit(X_train, y_train)
                
                # é¢„æµ‹å’Œè¯„ä¼°
                y_pred_train = model.predict(X_train)
                y_pred_test = model.predict(X_test)
                
                train_r2 = r2_score(y_train, y_pred_train)
                test_r2 = r2_score(y_test, y_pred_test)
                train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
                test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
                
                # ä¿å­˜æ¨¡å‹å’Œç»“æœ
                self.models[class_name] = model
                self.results[class_name] = {
                    'r2_train': train_r2,
                    'r2_test': test_r2,
                    'rmse_train': train_rmse,
                    'rmse_test': test_rmse,
                    'X_train': X_train,
                    'X_test': X_test,
                    'y_train': y_train,
                    'y_test': y_test,
                    'y_pred_train': y_pred_train,
                    'y_pred_test': y_pred_test,
                    'sample_count': len(data),
                    'power_mean': y.mean(),
                    'power_std': y.std(),
                    'shear_mean': data['wind_shear_alpha'].mean(),
                    'shear_std': data['wind_shear_alpha'].std()
                }
                
                print(f"  âœ“ è®­ç»ƒå®Œæˆ - RÂ²: {test_r2:.4f}, RMSE: {test_rmse:.2f} MW")
                print(f"    è¿‡æ‹Ÿåˆæ£€æŸ¥: è®­ç»ƒRÂ²={train_r2:.4f}, æµ‹è¯•RÂ²={test_r2:.4f}, å·®å€¼={train_r2-test_r2:.4f}")
                
            else:
                print(f"  âš ï¸ æ ·æœ¬æ•°ä¸è¶³ ({len(data)} < 100)ï¼Œè·³è¿‡è®­ç»ƒ")
        
        print(f"\nâœ“ å…±è®­ç»ƒäº† {len(self.models)} ä¸ªåˆ†ç±»æ¨¡å‹")
        return self.models
    
    def calculate_shap_values(self, n_samples=800):
        """è®¡ç®—å„åˆ†ç±»æ¨¡å‹çš„SHAPå€¼"""
        print("ğŸ“Š è®¡ç®—SHAPé‡è¦æ€§...")
        
        for class_name in self.models.keys():
            print(f"è®¡ç®— {class_name} çš„SHAPå€¼...")
            
            # è·å–æµ‹è¯•æ•°æ®
            X_test = self.results[class_name]['X_test']
            
            # é™åˆ¶æ ·æœ¬æ•°é‡
            if len(X_test) > n_samples:
                indices = np.random.choice(len(X_test), n_samples, replace=False)
                X_sample = X_test[indices]
            else:
                X_sample = X_test
            
            # è®¡ç®—SHAPå€¼
            explainer = shap.TreeExplainer(self.models[class_name])
            shap_values = explainer.shap_values(X_sample)
            
            # ä¿å­˜ç»“æœ
            self.shap_explainers[class_name] = explainer
            self.results[class_name]['shap_values'] = shap_values
            self.results[class_name]['X_shap'] = X_sample
            
            print(f"  âœ“ å®Œæˆ (æ ·æœ¬æ•°: {len(X_sample)})")
    
    def plot_performance_comparison(self):
        """ç»˜åˆ¶æ¨¡å‹æ€§èƒ½å¯¹æ¯”"""
        print("ğŸ“ˆ ç»˜åˆ¶æ¨¡å‹æ€§èƒ½å¯¹æ¯”...")
        
        if not self.results:
            print("âš ï¸ æ²¡æœ‰è®­ç»ƒç»“æœï¼Œè·³è¿‡æ€§èƒ½å¯¹æ¯”")
            return
        
        # å‡†å¤‡æ•°æ®
        class_names = list(self.results.keys())
        r2_values = [self.results[cls]['r2_test'] for cls in class_names]
        rmse_values = [self.results[cls]['rmse_test'] for cls in class_names]
        sample_counts = [self.results[cls]['sample_count'] for cls in class_names]
        power_means = [self.results[cls]['power_mean'] for cls in class_names]
        shear_means = [self.results[cls]['shear_mean'] for cls in class_names]
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('é£åˆ‡å˜-æ˜¼å¤œåˆ†ç±»æ¨¡å‹æ€§èƒ½å¯¹æ¯”', fontsize=16, fontweight='bold')
        
        # 1. RÂ² æ€§èƒ½å¯¹æ¯”
        ax1 = axes[0, 0]
        bars1 = ax1.bar(range(len(class_names)), r2_values, color='skyblue', alpha=0.7)
        ax1.set_xticks(range(len(class_names)))
        ax1.set_xticklabels([name.replace('_', '\n') for name in class_names], rotation=0)
        ax1.set_ylabel('RÂ² Score')
        ax1.set_title('RÂ² æ€§èƒ½å¯¹æ¯”')
        ax1.set_ylim(0, 1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, r2 in zip(bars1, r2_values):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{r2:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 2. RMSE å¯¹æ¯”
        ax2 = axes[0, 1]
        bars2 = ax2.bar(range(len(class_names)), rmse_values, color='lightcoral', alpha=0.7)
        ax2.set_xticks(range(len(class_names)))
        ax2.set_xticklabels([name.replace('_', '\n') for name in class_names], rotation=0)
        ax2.set_ylabel('RMSE (MW)')
        ax2.set_title('RMSE å¯¹æ¯”')
        
        for bar, rmse in zip(bars2, rmse_values):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                    f'{rmse:.1f}', ha='center', va='bottom', fontweight='bold')
        
        # 3. æ ·æœ¬æ•°é‡å¯¹æ¯”
        ax3 = axes[0, 2]
        bars3 = ax3.bar(range(len(class_names)), sample_counts, color='lightgreen', alpha=0.7)
        ax3.set_xticks(range(len(class_names)))
        ax3.set_xticklabels([name.replace('_', '\n') for name in class_names], rotation=0)
        ax3.set_ylabel('æ ·æœ¬æ•°é‡')
        ax3.set_title('å„åˆ†ç±»æ ·æœ¬åˆ†å¸ƒ')
        
        for bar, count in zip(bars3, sample_counts):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                    f'{count}', ha='center', va='bottom', fontweight='bold')
        
        # 4. åŠŸç‡å‡å€¼å¯¹æ¯”
        ax4 = axes[1, 0]
        bars4 = ax4.bar(range(len(class_names)), power_means, color='gold', alpha=0.7)
        ax4.set_xticks(range(len(class_names)))
        ax4.set_xticklabels([name.replace('_', '\n') for name in class_names], rotation=0)
        ax4.set_ylabel('å¹³å‡åŠŸç‡ (MW)')
        ax4.set_title('å„åˆ†ç±»å¹³å‡åŠŸç‡')
        
        for bar, power in zip(bars4, power_means):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                    f'{power:.1f}', ha='center', va='bottom', fontweight='bold')
        
        # 5. é¢„æµ‹æ•ˆæœæ•£ç‚¹å›¾ï¼ˆé€‰æ‹©æœ€å¥½çš„æ¨¡å‹ï¼‰
        best_class = class_names[np.argmax(r2_values)]
        ax5 = axes[1, 1]
        
        y_test = self.results[best_class]['y_test']
        y_pred = self.results[best_class]['y_pred_test']
        
        ax5.scatter(y_test, y_pred, alpha=0.5, s=20)
        min_val = min(y_test.min(), y_pred.min())
        max_val = max(y_test.max(), y_pred.max())
        ax5.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)
        
        ax5.set_xlabel('å®é™…åŠŸç‡ (MW)')
        ax5.set_ylabel('é¢„æµ‹åŠŸç‡ (MW)')
        ax5.set_title(f'æœ€ä½³æ¨¡å‹é¢„æµ‹æ•ˆæœ\n({best_class.replace("_", " ")})')
        ax5.grid(True, alpha=0.3)
        
        r2_best = self.results[best_class]['r2_test']
        ax5.text(0.05, 0.95, f'RÂ² = {r2_best:.3f}', transform=ax5.transAxes,
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        # 6. é£åˆ‡å˜-æ€§èƒ½å…³ç³»
        ax6 = axes[1, 2]
        scatter = ax6.scatter(shear_means, r2_values, c=rmse_values, 
                            s=[count/50 for count in sample_counts], 
                            cmap='viridis_r', alpha=0.7)
        
        # æ·»åŠ åˆ†ç±»æ ‡ç­¾
        for i, class_name in enumerate(class_names):
            ax6.annotate(class_name.replace('_', '\n'), 
                        (shear_means[i], r2_values[i]),
                        xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        ax6.set_xlabel('å¹³å‡é£åˆ‡å˜ç³»æ•°')
        ax6.set_ylabel('RÂ² Score')
        ax6.set_title('é£åˆ‡å˜ä¸æ€§èƒ½å…³ç³»\n(ç‚¹å¤§å°=æ ·æœ¬æ•°)')
        ax6.grid(True, alpha=0.3)
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(scatter, ax=ax6)
        cbar.set_label('RMSE (MW)')
        
        plt.tight_layout()
        plt.savefig(f"{self.save_path}/shear_diurnal_performance.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        # è¾“å‡ºæ€§èƒ½æ’å
        print("\nğŸ“Š æ€§èƒ½æ’å (æŒ‰RÂ²é™åº):")
        performance_df = pd.DataFrame({
            'classification': class_names,
            'r2': r2_values,
            'rmse': rmse_values,
            'samples': sample_counts,
            'power_mean': power_means,
            'shear_mean': shear_means
        }).sort_values('r2', ascending=False)
        
        for i, row in performance_df.iterrows():
            print(f"  {i+1}. {row['classification']}: RÂ²={row['r2']:.3f}, "
                  f"RMSE={row['rmse']:.1f}MW, æ ·æœ¬={row['samples']}, "
                  f"é£åˆ‡å˜={row['shear_mean']:.3f}")
        
        return performance_df
    
    def plot_shap_comparison(self):
        """ç»˜åˆ¶SHAPé‡è¦æ€§å¯¹æ¯”"""
        print("ğŸ“Š ç»˜åˆ¶SHAPé‡è¦æ€§å¯¹æ¯”...")
        
        if not self.results or not any('shap_values' in result for result in self.results.values()):
            print("âš ï¸ æ²¡æœ‰SHAPç»“æœï¼Œè·³è¿‡SHAPå¯¹æ¯”")
            return
        
        # è®¡ç®—å„åˆ†ç±»çš„å¹³å‡SHAPé‡è¦æ€§
        shap_importance_df = pd.DataFrame({'feature': self.feature_names})
        
        for class_name in self.results.keys():
            if 'shap_values' in self.results[class_name]:
                shap_values = self.results[class_name]['shap_values']
                importance = np.abs(shap_values).mean(axis=0)
                shap_importance_df[f'{class_name}_importance'] = importance
        
        # è®¡ç®—æ€»ä½“é‡è¦æ€§æ’åº
        importance_cols = [col for col in shap_importance_df.columns if 'importance' in col]
        shap_importance_df['avg_importance'] = shap_importance_df[importance_cols].mean(axis=1)
        shap_importance_df = shap_importance_df.sort_values('avg_importance', ascending=False)
        
        # ç»˜åˆ¶å¯¹æ¯”å›¾
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('é£åˆ‡å˜-æ˜¼å¤œåˆ†ç±»SHAPé‡è¦æ€§å¯¹æ¯”', fontsize=16, fontweight='bold')
        
        # 1. Topç‰¹å¾é‡è¦æ€§å¯¹æ¯”
        top_n = 15
        top_features = shap_importance_df.head(top_n)
        
        ax1 = axes[0, 0]
        class_names = [col.replace('_importance', '') for col in importance_cols]
        x = np.arange(len(top_features))
        width = 0.8 / len(class_names)
        
        colors = ['red', 'blue', 'orange', 'green']
        for i, class_name in enumerate(class_names):
            col = f'{class_name}_importance'
            offset = (i - len(class_names)/2 + 0.5) * width
            ax1.barh(x + offset, top_features[col], width, 
                    label=class_name.replace('_', ' '), alpha=0.7, color=colors[i % len(colors)])
        
        ax1.set_yticks(x)
        ax1.set_yticklabels(top_features['feature'], fontsize=8)
        ax1.set_xlabel('SHAPé‡è¦æ€§')
        ax1.set_title(f'Top {top_n} ç‰¹å¾é‡è¦æ€§å¯¹æ¯”')
        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax1.grid(True, alpha=0.3)
        
        # 2. ç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾
        ax2 = axes[0, 1]
        top_20_features = shap_importance_df.head(20)
        heatmap_data = top_20_features[importance_cols].T
        heatmap_data.columns = top_20_features['feature']
        heatmap_data.index = [idx.replace('_importance', '').replace('_', ' ') for idx in heatmap_data.index]
        
        sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='YlOrRd', 
                   ax=ax2, cbar_kws={'label': 'SHAPé‡è¦æ€§'})
        ax2.set_title('Top 20 ç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾')
        ax2.set_xlabel('ç‰¹å¾')
        ax2.set_ylabel('åˆ†ç±»')
        
        # 3. æŒ‰å˜é‡ç±»å‹åˆ†ç»„çš„é‡è¦æ€§
        ax3 = axes[1, 0]
        
        feature_categories = {
            'wind_speed': [f for f in self.feature_names if 'wind_speed' in f],
            'wind_direction': [f for f in self.feature_names if 'wind_dir' in f],  
            'temperature': [f for f in self.feature_names if 'temperature' in f],
            'alpha': [f for f in self.feature_names if 'alpha' in f],
            'other': [f for f in self.feature_names if not any(keyword in f for keyword in 
                     ['wind_speed', 'wind_dir', 'temperature', 'alpha'])]
        }
        
        category_importance = pd.DataFrame()
        for category, features in feature_categories.items():
            if features:
                cat_data = {'category': category}
                for class_name in class_names:
                    col = f'{class_name}_importance'
                    if col in shap_importance_df.columns:
                        cat_features = shap_importance_df[shap_importance_df['feature'].isin(features)]
                        cat_data[class_name] = cat_features[col].sum()
                    else:
                        cat_data[class_name] = 0
                category_importance = pd.concat([category_importance, pd.DataFrame([cat_data])], ignore_index=True)
        
        # ç»˜åˆ¶åˆ†ç±»é‡è¦æ€§å¯¹æ¯”
        x = np.arange(len(category_importance))
        width = 0.8 / len(class_names)
        
        for i, class_name in enumerate(class_names):
            offset = (i - len(class_names)/2 + 0.5) * width
            if class_name in category_importance.columns:
                ax3.bar(x + offset, category_importance[class_name], width, 
                       label=class_name.replace('_', ' '), alpha=0.7, color=colors[i % len(colors)])
        
        ax3.set_xticks(x)
        ax3.set_xticklabels(category_importance['category'])
        ax3.set_ylabel('ç´¯è®¡SHAPé‡è¦æ€§')
        ax3.set_title('æŒ‰å˜é‡ç±»å‹åˆ†ç»„çš„é‡è¦æ€§å¯¹æ¯”')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. åˆ†ç±»é—´é‡è¦æ€§å·®å¼‚åˆ†æ
        ax4 = axes[1, 1]
        
        if len(class_names) >= 2:
            # æ¯”è¾ƒé«˜é£åˆ‡å˜ç™½å¤© vs ä½é£åˆ‡å˜å¤œé—´ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            target_classes = ['high_shear_day', 'low_shear_night']
            available_classes = [cls for cls in target_classes if f'{cls}_importance' in shap_importance_df.columns]
            
            if len(available_classes) >= 2:
                class1, class2 = available_classes[0], available_classes[1]
                col1, col2 = f'{class1}_importance', f'{class2}_importance'
                
                diff = shap_importance_df[col1] - shap_importance_df[col2]
                shap_importance_df['diff'] = diff
                diff_sorted = shap_importance_df.sort_values('diff', ascending=True)
                
                colors_diff = ['red' if x < 0 else 'blue' for x in diff_sorted['diff']]
                ax4.barh(range(len(diff_sorted)), diff_sorted['diff'], color=colors_diff, alpha=0.6)
                ax4.set_yticks(range(len(diff_sorted)))
                ax4.set_yticklabels(diff_sorted['feature'], fontsize=6)
                ax4.set_xlabel(f'é‡è¦æ€§å·®å¼‚\n({class1.replace("_", " ")} - {class2.replace("_", " ")})')
                ax4.set_title('ä¸»è¦åˆ†ç±»é‡è¦æ€§å·®å¼‚')
                ax4.axvline(x=0, color='black', linestyle='--', alpha=0.5)
                ax4.grid(True, alpha=0.3)
            else:
                ax4.text(0.5, 0.5, 'éœ€è¦è‡³å°‘2ç§åˆ†ç±»\nè¿›è¡Œå·®å¼‚åˆ†æ', 
                        ha='center', va='center', transform=ax4.transAxes)
                ax4.set_title('é‡è¦æ€§å·®å¼‚åˆ†æ')
        else:
            ax4.text(0.5, 0.5, 'éœ€è¦è‡³å°‘2ç§åˆ†ç±»\nè¿›è¡Œå·®å¼‚åˆ†æ', 
                    ha='center', va='center', transform=ax4.transAxes)
            ax4.set_title('é‡è¦æ€§å·®å¼‚åˆ†æ')
        
        plt.tight_layout()
        plt.savefig(f"{self.save_path}/shear_diurnal_shap_comparison.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        # ä¿å­˜é‡è¦æ€§å¯¹æ¯”æ•°æ®
        shap_importance_df.to_csv(f"{self.save_path}/shear_diurnal_shap_importance.csv", index=False)
        print("âœ“ SHAPé‡è¦æ€§å¯¹æ¯”æ•°æ®å·²ä¿å­˜")
        
        return shap_importance_df
    
    def save_models_and_results(self):
        """ä¿å­˜æ¨¡å‹å’Œç»“æœ"""
        print("ğŸ’¾ ä¿å­˜æ¨¡å‹å’Œç»“æœ...")
        
        # ä¿å­˜å„åˆ†ç±»æ¨¡å‹
        for class_name, model in self.models.items():
            model_path = f"{self.save_path}/lightgbm_model_{class_name}.pkl"
            joblib.dump(model, model_path)
            print(f"âœ“ {class_name}æ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        # ä¿å­˜ç‰¹å¾åç§°
        feature_names_path = f"{self.save_path}/feature_names.pkl"
        joblib.dump(self.feature_names, feature_names_path)
        print(f"âœ“ ç‰¹å¾åç§°å·²ä¿å­˜: {feature_names_path}")
        
        # ä¿å­˜ç»“æœæ‘˜è¦
        results_summary = {}
        for class_name in self.results:
            results_summary[class_name] = {
                'r2_test': self.results[class_name]['r2_test'],
                'rmse_test': self.results[class_name]['rmse_test'],
                'sample_count': self.results[class_name]['sample_count'],
                'power_mean': self.results[class_name]['power_mean'],
                'power_std': self.results[class_name]['power_std'],
                'shear_mean': self.results[class_name]['shear_mean'],
                'shear_std': self.results[class_name]['shear_std']
            }
        
        summary_path = f"{self.save_path}/shear_diurnal_results_summary.pkl"
        joblib.dump(results_summary, summary_path)
        print(f"âœ“ ç»“æœæ‘˜è¦å·²ä¿å­˜: {summary_path}")
        
        # ä¿å­˜é£åˆ‡å˜é˜ˆå€¼
        threshold_info = {
            'wind_shear_threshold': self.wind_shear_threshold,
            'day_start': 6,
            'day_end': 18
        }
        
        threshold_path = f"{self.save_path}/classification_thresholds.pkl"
        joblib.dump(threshold_info, threshold_path)
        print(f"âœ“ åˆ†ç±»é˜ˆå€¼å·²ä¿å­˜: {threshold_path}")
        
        return results_summary, threshold_info
    
    def run_full_analysis(self):
        """è¿è¡Œå®Œæ•´çš„é£åˆ‡å˜-æ˜¼å¤œåˆ†ææµç¨‹"""
        print("=" * 70)
        print("ğŸŒªï¸ åŸºäºé£åˆ‡å˜-æ˜¼å¤œåˆ†ç±»çš„é£ç”µé¢„æµ‹åˆ†æ")
        print("=" * 70)
        
        try:
            # 1. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
            self.load_and_prepare_data()
            
            # 2. è®¡ç®—é£åˆ‡å˜ç³»æ•°
            h1, h2 = self.calculate_wind_shear()
            
            # 3. ç¡®å®šæ˜¼å¤œåˆ†ç±»
            day_start, day_end = self.determine_day_night()
            
            # 4. åˆ†æé£åˆ‡å˜æ—¥å˜åŒ–æ¨¡å¼
            hourly_shear, day_shear_mean, night_shear_mean = self.analyze_wind_shear_diurnal_pattern()
            
            # 5. åˆ›å»ºç»„åˆåˆ†ç±»
            class_stats = self.create_shear_diurnal_classification()
            
            # 6. æŒ‰åˆ†ç±»åˆ†ç»„
            self.prepare_classification_groups(min_samples=300)
            
            # 7. è®­ç»ƒåˆ†ç±»æ¨¡å‹
            self.train_classification_models()
            
            # 8. è®¡ç®—SHAPå€¼
            self.calculate_shap_values()
            
            # 9. ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”
            performance_df = self.plot_performance_comparison()
            
            # 10. ç»˜åˆ¶SHAPå¯¹æ¯”
            shap_comparison = self.plot_shap_comparison()
            
            # 11. ä¿å­˜æ¨¡å‹å’Œç»“æœ
            results_summary, threshold_info = self.save_models_and_results()
            
            print("\n" + "=" * 70)
            print("ğŸ‰ é£åˆ‡å˜-æ˜¼å¤œåˆ†æå®Œæˆï¼")
            print("=" * 70)
            
            print("ğŸ“Š ä¸»è¦å‘ç°:")
            print(f"  é£åˆ‡å˜è®¡ç®—: ä½¿ç”¨ {h1}m å’Œ {h2}m é«˜åº¦æ•°æ®")
            print(f"  é£åˆ‡å˜é˜ˆå€¼: {self.wind_shear_threshold:.3f}")
            print(f"  æ˜¼å¤œåˆ’åˆ†: {day_start}:00-{day_end}:00ä¸ºç™½å¤©")
            print(f"  ç™½å¤©å¹³å‡é£åˆ‡å˜: {day_shear_mean:.3f}")
            print(f"  å¤œé—´å¹³å‡é£åˆ‡å˜: {night_shear_mean:.3f}")
            print(f"  è®­ç»ƒçš„åˆ†ç±»æ¨¡å‹æ•°é‡: {len(self.models)}")
            print(f"  åˆ†ç±»ç±»å‹: {list(self.models.keys())}")
            
            if performance_df is not None and len(performance_df) > 0:
                best_class = performance_df.iloc[0]['classification']
                best_r2 = performance_df.iloc[0]['r2']
                worst_class = performance_df.iloc[-1]['classification']
                worst_r2 = performance_df.iloc[-1]['r2']
                
                print(f"  æœ€ä½³é¢„æµ‹æ€§èƒ½: {best_class} (RÂ²={best_r2:.3f})")
                print(f"  æœ€ä½é¢„æµ‹æ€§èƒ½: {worst_class} (RÂ²={worst_r2:.3f})")
                
                r2_range = best_r2 - worst_r2
                print(f"  æ€§èƒ½å·®è·: {r2_range:.3f}")
                
                if r2_range > 0.1:
                    print("  â†’ é£åˆ‡å˜-æ˜¼å¤œåˆ†ç±»å»ºæ¨¡å¾ˆæœ‰ä»·å€¼ï¼Œæ€§èƒ½å·®å¼‚æ˜æ˜¾")
                else:
                    print("  â†’ å„åˆ†ç±»é¢„æµ‹æ€§èƒ½ç›¸è¿‘ï¼Œå¯è€ƒè™‘ç®€åŒ–åˆ†ç±»ç­–ç•¥")
            
            print(f"\nğŸ“ ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: {self.save_path}")
            print("  - wind_shear_diurnal_analysis.png: é£åˆ‡å˜æ—¥å˜åŒ–åˆ†æ")
            print("  - shear_diurnal_classification.png: åˆ†ç±»ç»“æœå¯è§†åŒ–")
            print("  - shear_diurnal_performance.png: æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
            print("  - shear_diurnal_shap_comparison.png: SHAPé‡è¦æ€§å¯¹æ¯”")
            
            # åˆ†æå…³é”®æ´å¯Ÿ
            print(f"\nğŸ” å…³é”®æ´å¯Ÿ:")
            print(f"  é£åˆ‡å˜ä¸æ˜¼å¤œçš„å…³ç³»:")
            if day_shear_mean > night_shear_mean:
                print(f"    - ç™½å¤©é£åˆ‡å˜æ›´å¼º ({day_shear_mean:.3f} vs {night_shear_mean:.3f})")
                print(f"    - ç¬¦åˆè¾¹ç•Œå±‚ç†è®ºï¼šç™½å¤©ä¸ç¨³å®šå¯¼è‡´æ›´å¼ºé£åˆ‡å˜")
            else:
                print(f"    - å¤œé—´é£åˆ‡å˜æ›´å¼º ({night_shear_mean:.3f} vs {day_shear_mean:.3f})")
                print(f"    - å¯èƒ½å­˜åœ¨ç‰¹æ®Šåœ°å½¢æˆ–æ°”å€™å½±å“")
            
            if len(self.models) >= 2:
                print("  ä¸åŒåˆ†ç±»æ¡ä»¶ä¸‹çš„é¢„æµ‹ç‰¹å¾:")
                for class_name in self.models.keys():
                    r2 = results_summary[class_name]['r2_test']
                    samples = results_summary[class_name]['sample_count']
                    shear_mean = results_summary[class_name]['shear_mean']
                    
                    if r2 > 0.8:
                        perf_level = "ä¼˜ç§€"
                    elif r2 > 0.6:
                        perf_level = "è‰¯å¥½"
                    elif r2 > 0.4:
                        perf_level = "ä¸€èˆ¬"
                    else:
                        perf_level = "è¾ƒå·®"
                    
                    print(f"    - {class_name}: {perf_level}é¢„æµ‹æ€§èƒ½ (RÂ²={r2:.3f}), "
                          f"é£åˆ‡å˜={shear_mean:.3f}, æ ·æœ¬{samples}æ¡")
            
            return True
            
        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

if __name__ == "__main__":
    # é…ç½®è·¯å¾„
    DATA_PATH = "/Users/xiaxin/work/WindForecast_Project/01_Data/processed/imputed_data/changma_imputed_complete.csv"
    SAVE_PATH = "/Users/xiaxin/work/WindForecast_Project/03_Results/wind_shear_diurnal_analysis"
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    import os
    os.makedirs(SAVE_PATH, exist_ok=True)
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ
    analyzer = WindShearDiurnalAnalyzer(DATA_PATH, SAVE_PATH)
    success = analyzer.run_full_analysis()
    
    if success:
        print("\nğŸ¯ é£åˆ‡å˜-æ˜¼å¤œåˆ†ææˆåŠŸå®Œæˆï¼")
        print("\nğŸ’¡ åç»­ç ”ç©¶å»ºè®®:")
        print("  1. å¯¹æ¯”ä¸åŒåˆ†ç±»ç­–ç•¥çš„ä¼˜åŠ£")
        print("  2. ç ”ç©¶é£åˆ‡å˜ä¸ç¨³å®šåº¦çš„å…³ç³»")
        print("  3. åˆ†æå­£èŠ‚æ€§å¯¹é£åˆ‡å˜æ¨¡å¼çš„å½±å“")
        print("  4. å¼€å‘åŸºäºé£åˆ‡å˜çš„åŠ¨æ€é¢„æµ‹æ¨¡å‹")
        print("  5. éªŒè¯åˆ†ç±»ç­–ç•¥åœ¨ä¸åŒé£ç”µåœºçš„é€‚ç”¨æ€§")
    else:
        print("\nâš ï¸ åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å’Œæ•°æ®è·¯å¾„")