#!/usr/bin/env python3
"""
åŸºäºå¤§æ°”ç¨³å®šåº¦åˆ†ç±»çš„é£ç”µé¢„æµ‹ä¸SHAPé‡è¦æ€§åˆ†æ
Author: Research Team
Date: 2025-06-09
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import lightgbm as lgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import shap
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class StabilityBasedWindPredictionAnalyzer:
    def __init__(self, wind_data_path, stability_data_path, save_path):
        self.wind_data_path = wind_data_path
        self.stability_data_path = stability_data_path
        self.save_path = save_path
        self.wind_data = None
        self.stability_data = None
        self.merged_data = None
        self.stability_groups = {}
        self.feature_names = None
        self.models = {}
        self.shap_explainers = {}
        self.results = {}
        
    def load_data(self):
        """åŠ è½½é£ç”µæ•°æ®å’Œç¨³å®šåº¦æ•°æ®"""
        print("ğŸ“Š åŠ è½½æ•°æ®...")
        
        # åŠ è½½é£ç”µæ•°æ®
        self.wind_data = pd.read_csv(self.wind_data_path)
        print(f"é£ç”µæ•°æ®å½¢çŠ¶: {self.wind_data.shape}")
        
        # åŠ è½½ç¨³å®šåº¦æ•°æ®
        self.stability_data = pd.read_csv(self.stability_data_path)
        print(f"ç¨³å®šåº¦æ•°æ®å½¢çŠ¶: {self.stability_data.shape}")
        
        # è½¬æ¢æ—¶é—´åˆ—
        if 'datetime' in self.wind_data.columns:
            self.wind_data['datetime'] = pd.to_datetime(self.wind_data['datetime'])
        
        if 'timestamp' in self.stability_data.columns:
            self.stability_data['timestamp'] = pd.to_datetime(self.stability_data['timestamp'])
            # é‡å‘½åä¸ºdatetimeä»¥ä¾¿åˆå¹¶
            self.stability_data = self.stability_data.rename(columns={'timestamp': 'datetime'})
        
        return self.wind_data, self.stability_data
    
    def analyze_stability_distribution(self):
        """åˆ†æç¨³å®šåº¦åˆ†å¸ƒ"""
        print("ğŸŒ€ åˆ†æç¨³å®šåº¦åˆ†å¸ƒ...")
        
        # ç¨³å®šåº¦åˆ†å¸ƒç»Ÿè®¡
        stability_counts = self.stability_data['stability_final'].value_counts()
        confidence_stats = self.stability_data.groupby('stability_final')['confidence_final'].agg(['mean', 'std', 'count'])
        
        print("\nç¨³å®šåº¦åˆ†å¸ƒ:")
        for stability, count in stability_counts.items():
            percentage = count / len(self.stability_data) * 100
            print(f"  {stability}: {count} æ¡ ({percentage:.1f}%)")
        
        # ç»˜åˆ¶åˆ†å¸ƒå›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('å¤§æ°”ç¨³å®šåº¦åˆ†å¸ƒåˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. ç¨³å®šåº¦é¢‘æ¬¡åˆ†å¸ƒ
        ax1 = axes[0, 0]
        stability_counts.plot(kind='bar', ax=ax1, color='skyblue', alpha=0.7)
        ax1.set_title('ç¨³å®šåº¦ç±»å‹åˆ†å¸ƒ')
        ax1.set_xlabel('ç¨³å®šåº¦ç±»å‹')
        ax1.set_ylabel('é¢‘æ¬¡')
        ax1.tick_params(axis='x', rotation=45)
        
        # æ·»åŠ ç™¾åˆ†æ¯”æ ‡ç­¾
        total = len(self.stability_data)
        for i, (stability, count) in enumerate(stability_counts.items()):
            percentage = count / total * 100
            ax1.text(i, count + total*0.01, f'{percentage:.1f}%', 
                    ha='center', va='bottom', fontweight='bold')
        
        # 2. ç½®ä¿¡åº¦åˆ†å¸ƒ
        ax2 = axes[0, 1]
        self.stability_data.boxplot(column='confidence_final', by='stability_final', ax=ax2)
        ax2.set_title('å„ç¨³å®šåº¦ç±»å‹çš„ç½®ä¿¡åº¦åˆ†å¸ƒ')
        ax2.set_xlabel('ç¨³å®šåº¦ç±»å‹')
        ax2.set_ylabel('ç½®ä¿¡åº¦')
        
        # 3. æ—¶é—´åºåˆ—åˆ†å¸ƒ
        ax3 = axes[1, 0]
        # æŒ‰å°æ—¶ç»Ÿè®¡ç¨³å®šåº¦åˆ†å¸ƒ
        hourly_stability = self.stability_data.groupby(['hour', 'stability_final']).size().unstack(fill_value=0)
        hourly_stability_pct = hourly_stability.div(hourly_stability.sum(axis=1), axis=0) * 100
        
        hourly_stability_pct.plot(kind='area', stacked=True, ax=ax3, alpha=0.7)
        ax3.set_title('ç¨³å®šåº¦çš„æ—¥å˜åŒ–æ¨¡å¼')
        ax3.set_xlabel('å°æ—¶')
        ax3.set_ylabel('ç™¾åˆ†æ¯” (%)')
        ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        # 4. å­£èŠ‚æ€§åˆ†å¸ƒ
        ax4 = axes[1, 1]
        seasonal_stability = self.stability_data.groupby(['season', 'stability_final']).size().unstack(fill_value=0)
        seasonal_stability_pct = seasonal_stability.div(seasonal_stability.sum(axis=1), axis=0) * 100
        
        seasonal_stability_pct.plot(kind='bar', stacked=True, ax=ax4, alpha=0.7)
        ax4.set_title('ç¨³å®šåº¦çš„å­£èŠ‚å˜åŒ–')
        ax4.set_xlabel('å­£èŠ‚')
        ax4.set_ylabel('ç™¾åˆ†æ¯” (%)')
        ax4.tick_params(axis='x', rotation=0)
        ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        plt.tight_layout()
        plt.savefig(f"{self.save_path}/stability_distribution_analysis.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        return stability_counts, confidence_stats
    
    def merge_data_by_time(self):
        """æŒ‰æ—¶é—´åˆå¹¶é£ç”µæ•°æ®å’Œç¨³å®šåº¦æ•°æ®"""
        print("ğŸ”— åˆå¹¶é£ç”µæ•°æ®å’Œç¨³å®šåº¦æ•°æ®...")
        
        # é€‰æ‹©é£ç”µè§‚æµ‹æ•°æ®åˆ—
        obs_columns = [col for col in self.wind_data.columns if col.startswith('obs_')]
        obs_columns += ['datetime', 'power']
        
        # ç§»é™¤å¯†åº¦å’Œæ¹¿åº¦
        obs_columns = [col for col in obs_columns if 'density' not in col and 'humidity' not in col]
        wind_data_clean = self.wind_data[obs_columns].copy()
        
        # é€‰æ‹©å…³é”®ç¨³å®šåº¦ä¿¡æ¯
        stability_columns = ['datetime', 'stability_final', 'confidence_final', 'alpha_main', 
                           'data_quality', 'is_daytime', 'temp_change_rate']
        stability_data_clean = self.stability_data[stability_columns].copy()
        
        # æŒ‰æ—¶é—´åˆå¹¶
        self.merged_data = pd.merge(wind_data_clean, stability_data_clean, on='datetime', how='inner')
        
        print(f"åˆå¹¶å‰é£ç”µæ•°æ®: {len(wind_data_clean)} æ¡")
        print(f"åˆå¹¶å‰ç¨³å®šåº¦æ•°æ®: {len(stability_data_clean)} æ¡")
        print(f"åˆå¹¶åæ•°æ®: {len(self.merged_data)} æ¡")
        
        # æ¸…ç†æ•°æ®
        initial_shape = len(self.merged_data)
        self.merged_data = self.merged_data.dropna()
        self.merged_data = self.merged_data[self.merged_data['power'] >= 0]
        
        # åªä¿ç•™é«˜è´¨é‡å’Œç½®ä¿¡åº¦æ•°æ®
        quality_mask = (self.merged_data['data_quality'].isin(['high', 'medium'])) & \
                      (self.merged_data['confidence_final'] >= 0.6)
        self.merged_data = self.merged_data[quality_mask]
        
        final_shape = len(self.merged_data)
        print(f"æ•°æ®æ¸…ç†: ä» {initial_shape} æ¡å‡å°‘åˆ° {final_shape} æ¡")
        
        # åˆ†æåˆå¹¶åçš„ç¨³å®šåº¦åˆ†å¸ƒ
        merged_stability_counts = self.merged_data['stability_final'].value_counts()
        print(f"\nåˆå¹¶åç¨³å®šåº¦åˆ†å¸ƒ:")
        for stability, count in merged_stability_counts.items():
            percentage = count / len(self.merged_data) * 100
            print(f"  {stability}: {count} æ¡ ({percentage:.1f}%)")
        
        return self.merged_data
    
    def process_wind_direction(self, data):
        """å¤„ç†é£å‘å˜é‡ä¸ºsin/cosåˆ†é‡"""
        data = data.copy()
        wind_dir_cols = [col for col in data.columns if 'wind_direction' in col]
        
        if wind_dir_cols:
            print(f"å¤„ç† {len(wind_dir_cols)} ä¸ªé£å‘åˆ—...")
            
            for col in wind_dir_cols:
                # æ°”è±¡è§’åº¦è½¬æ¢ä¸ºæ•°å­¦è§’åº¦
                math_angle = (90 - data[col] + 360) % 360
                wind_dir_rad = np.deg2rad(math_angle)
                
                # åˆ›å»ºsin/cosåˆ†é‡
                sin_col = col.replace('wind_direction', 'wind_dir_sin')
                cos_col = col.replace('wind_direction', 'wind_dir_cos')
                
                data[sin_col] = np.sin(wind_dir_rad)
                data[cos_col] = np.cos(wind_dir_rad)
            
            # ç§»é™¤åŸå§‹é£å‘åˆ—
            data = data.drop(columns=wind_dir_cols)
        
        return data
    
    def prepare_stability_groups(self, min_samples=500):
        """æŒ‰ç¨³å®šåº¦åˆ†ç»„æ•°æ®ï¼Œç¡®ä¿æ¯ç»„æœ‰è¶³å¤Ÿæ ·æœ¬"""
        print("ğŸ“Š æŒ‰ç¨³å®šåº¦åˆ†ç»„æ•°æ®...")
        
        stability_counts = self.merged_data['stability_final'].value_counts()
        
        # åªé€‰æ‹©æ ·æœ¬æ•°è¶³å¤Ÿçš„ç¨³å®šåº¦ç±»å‹
        valid_stabilities = stability_counts[stability_counts >= min_samples].index.tolist()
        
        print(f"æ ·æœ¬æ•°è¶³å¤Ÿçš„ç¨³å®šåº¦ç±»å‹ (>={min_samples}): {valid_stabilities}")
        
        for stability in valid_stabilities:
            stability_data = self.merged_data[self.merged_data['stability_final'] == stability].copy()
            self.stability_groups[stability] = stability_data
            print(f"  {stability}: {len(stability_data)} æ¡æ ·æœ¬")
        
        # å¦‚æœæŸäº›ç¨³å®šåº¦æ ·æœ¬å¤ªå°‘ï¼Œå¯ä»¥è€ƒè™‘åˆå¹¶ç›¸ä¼¼ç±»å‹
        small_stabilities = stability_counts[stability_counts < min_samples].index.tolist()
        if small_stabilities:
            print(f"\næ ·æœ¬æ•°ä¸è¶³çš„ç¨³å®šåº¦ç±»å‹: {small_stabilities}")
            print("å»ºè®®ï¼šå¯ä»¥è€ƒè™‘å°†ç›¸ä¼¼ç¨³å®šåº¦ç±»å‹åˆå¹¶æˆ–è°ƒæ•´min_sampleså‚æ•°")
        
        return self.stability_groups
    
    def train_stability_models(self):
        """ä¸ºæ¯ç§ç¨³å®šåº¦è®­ç»ƒç‹¬ç«‹çš„é¢„æµ‹æ¨¡å‹"""
        print("ğŸš€ è®­ç»ƒç¨³å®šåº¦åˆ†ç±»æ¨¡å‹...")
        
        # LightGBMåŸºç¡€å‚æ•°
        base_params = {
            'objective': 'regression',
            'metric': 'rmse',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.1,
            'n_estimators': 200,
            'reg_alpha': 0.1,
            'reg_lambda': 0.1,
            'min_child_samples': 20,
            'random_state': 42,
            'verbose': -1,
            'n_jobs': -1
        }
        
        for stability, data in self.stability_groups.items():
            print(f"\nè®­ç»ƒ {stability} ç¨³å®šåº¦æ¨¡å‹...")
            print(f"æ•°æ®é‡: {len(data)} æ¡")
            
            # å¤„ç†é£å‘å’Œå‡†å¤‡ç‰¹å¾
            data_processed = self.process_wind_direction(data)
            
            # é€‰æ‹©ç‰¹å¾åˆ—
            exclude_cols = ['datetime', 'power', 'stability_final', 'confidence_final', 
                          'data_quality', 'is_daytime']
            feature_cols = [col for col in data_processed.columns if col not in exclude_cols]
            
            # åˆ›å»ºç‰¹å¾çŸ©é˜µ
            X = data_processed[feature_cols].values
            y = data_processed['power'].values
            
            # ä¿å­˜ç‰¹å¾åç§°ï¼ˆæ‰€æœ‰ç¨³å®šåº¦ä½¿ç”¨ç›¸åŒç‰¹å¾ï¼‰
            if self.feature_names is None:
                self.feature_names = feature_cols
                print(f"  è®¾ç½®ç‰¹å¾åç§°ï¼Œå…± {len(feature_cols)} ä¸ªç‰¹å¾")
            
            print(f"  ç‰¹å¾æ•°é‡: {len(feature_cols)}")
            print(f"  åŠŸç‡èŒƒå›´: {y.min():.1f} - {y.max():.1f} MW")
            print(f"  åŠŸç‡å‡å€¼: {y.mean():.1f} MW")
            
            # æ•°æ®åˆ†å‰²
            if len(data) >= 100:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è¿›è¡Œåˆ†å‰²
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42
                )
                
                # è®­ç»ƒæ¨¡å‹
                model = lgb.LGBMRegressor(**base_params)
                model.fit(X_train, y_train)
                
                # é¢„æµ‹å’Œè¯„ä¼°
                y_pred_train = model.predict(X_train)
                y_pred_test = model.predict(X_test)
                
                train_r2 = r2_score(y_train, y_pred_train)
                test_r2 = r2_score(y_test, y_pred_test)
                train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
                test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
                
                # ä¿å­˜æ¨¡å‹å’Œç»“æœ
                self.models[stability] = model
                self.results[stability] = {
                    'r2_train': train_r2,
                    'r2_test': test_r2,
                    'rmse_train': train_rmse,
                    'rmse_test': test_rmse,
                    'X_train': X_train,
                    'X_test': X_test,
                    'y_train': y_train,
                    'y_test': y_test,
                    'y_pred_train': y_pred_train,
                    'y_pred_test': y_pred_test,
                    'sample_count': len(data),
                    'power_mean': y.mean(),
                    'power_std': y.std()
                }
                
                print(f"  âœ“ è®­ç»ƒå®Œæˆ - RÂ²: {test_r2:.4f}, RMSE: {test_rmse:.2f} MW")
                print(f"    è¿‡æ‹Ÿåˆæ£€æŸ¥: è®­ç»ƒRÂ²={train_r2:.4f}, æµ‹è¯•RÂ²={test_r2:.4f}, å·®å€¼={train_r2-test_r2:.4f}")
                
            else:
                print(f"  âš ï¸ æ ·æœ¬æ•°ä¸è¶³ ({len(data)} < 100)ï¼Œè·³è¿‡è®­ç»ƒ")
        
        print(f"\nâœ“ å…±è®­ç»ƒäº† {len(self.models)} ä¸ªç¨³å®šåº¦æ¨¡å‹")
        return self.models
    
    def calculate_stability_shap_values(self, n_samples=800):
        """è®¡ç®—å„ç¨³å®šåº¦æ¨¡å‹çš„SHAPå€¼"""
        print("ğŸ“Š è®¡ç®—ç¨³å®šåº¦SHAPé‡è¦æ€§...")
        
        for stability in self.models.keys():
            print(f"è®¡ç®— {stability} çš„SHAPå€¼...")
            
            # è·å–æµ‹è¯•æ•°æ®
            X_test = self.results[stability]['X_test']
            
            # é™åˆ¶æ ·æœ¬æ•°é‡
            if len(X_test) > n_samples:
                indices = np.random.choice(len(X_test), n_samples, replace=False)
                X_sample = X_test[indices]
            else:
                X_sample = X_test
            
            # è®¡ç®—SHAPå€¼
            explainer = shap.TreeExplainer(self.models[stability])
            shap_values = explainer.shap_values(X_sample)
            
            # ä¿å­˜ç»“æœ
            self.shap_explainers[stability] = explainer
            self.results[stability]['shap_values'] = shap_values
            self.results[stability]['X_shap'] = X_sample
            
            print(f"  âœ“ å®Œæˆ (æ ·æœ¬æ•°: {len(X_sample)})")
    
    def plot_stability_performance_comparison(self):
        """ç»˜åˆ¶ä¸åŒç¨³å®šåº¦æ¨¡å‹çš„æ€§èƒ½å¯¹æ¯”"""
        print("ğŸ“ˆ ç»˜åˆ¶ç¨³å®šåº¦æ¨¡å‹æ€§èƒ½å¯¹æ¯”...")
        
        if not self.results:
            print("âš ï¸ æ²¡æœ‰è®­ç»ƒç»“æœï¼Œè·³è¿‡æ€§èƒ½å¯¹æ¯”")
            return
        
        # å‡†å¤‡æ•°æ®
        stabilities = list(self.results.keys())
        r2_values = [self.results[s]['r2_test'] for s in stabilities]
        rmse_values = [self.results[s]['rmse_test'] for s in stabilities]
        sample_counts = [self.results[s]['sample_count'] for s in stabilities]
        power_means = [self.results[s]['power_mean'] for s in stabilities]
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('ä¸åŒç¨³å®šåº¦æ¡ä»¶ä¸‹çš„æ¨¡å‹æ€§èƒ½å¯¹æ¯”', fontsize=16, fontweight='bold')
        
        # 1. RÂ² æ€§èƒ½å¯¹æ¯”
        ax1 = axes[0, 0]
        bars1 = ax1.bar(stabilities, r2_values, color='skyblue', alpha=0.7)
        ax1.set_ylabel('RÂ² Score')
        ax1.set_title('RÂ² æ€§èƒ½å¯¹æ¯”')
        ax1.set_ylim(0, 1)
        ax1.tick_params(axis='x', rotation=45)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, r2 in zip(bars1, r2_values):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{r2:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 2. RMSE å¯¹æ¯”
        ax2 = axes[0, 1]
        bars2 = ax2.bar(stabilities, rmse_values, color='lightcoral', alpha=0.7)
        ax2.set_ylabel('RMSE (MW)')
        ax2.set_title('RMSE å¯¹æ¯”')
        ax2.tick_params(axis='x', rotation=45)
        
        for bar, rmse in zip(bars2, rmse_values):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                    f'{rmse:.1f}', ha='center', va='bottom', fontweight='bold')
        
        # 3. æ ·æœ¬æ•°é‡å¯¹æ¯”
        ax3 = axes[0, 2]
        bars3 = ax3.bar(stabilities, sample_counts, color='lightgreen', alpha=0.7)
        ax3.set_ylabel('æ ·æœ¬æ•°é‡')
        ax3.set_title('å„ç¨³å®šåº¦æ ·æœ¬åˆ†å¸ƒ')
        ax3.tick_params(axis='x', rotation=45)
        
        for bar, count in zip(bars3, sample_counts):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                    f'{count}', ha='center', va='bottom', fontweight='bold')
        
        # 4. åŠŸç‡å‡å€¼å¯¹æ¯”
        ax4 = axes[1, 0]
        bars4 = ax4.bar(stabilities, power_means, color='gold', alpha=0.7)
        ax4.set_ylabel('å¹³å‡åŠŸç‡ (MW)')
        ax4.set_title('å„ç¨³å®šåº¦å¹³å‡åŠŸç‡')
        ax4.tick_params(axis='x', rotation=45)
        
        for bar, power in zip(bars4, power_means):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                    f'{power:.1f}', ha='center', va='bottom', fontweight='bold')
        
        # 5. é¢„æµ‹æ•ˆæœæ•£ç‚¹å›¾ï¼ˆé€‰æ‹©æœ€å¥½çš„æ¨¡å‹ï¼‰
        best_stability = stabilities[np.argmax(r2_values)]
        ax5 = axes[1, 1]
        
        y_test = self.results[best_stability]['y_test']
        y_pred = self.results[best_stability]['y_pred_test']
        
        ax5.scatter(y_test, y_pred, alpha=0.5, s=20)
        min_val = min(y_test.min(), y_pred.min())
        max_val = max(y_test.max(), y_pred.max())
        ax5.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)
        
        ax5.set_xlabel('å®é™…åŠŸç‡ (MW)')
        ax5.set_ylabel('é¢„æµ‹åŠŸç‡ (MW)')
        ax5.set_title(f'æœ€ä½³æ¨¡å‹é¢„æµ‹æ•ˆæœ ({best_stability})')
        ax5.grid(True, alpha=0.3)
        
        r2_best = self.results[best_stability]['r2_test']
        ax5.text(0.05, 0.95, f'RÂ² = {r2_best:.3f}', transform=ax5.transAxes,
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        # 6. æ€§èƒ½-æ ·æœ¬é‡å…³ç³»
        ax6 = axes[1, 2]
        scatter = ax6.scatter(sample_counts, r2_values, c=rmse_values, 
                            cmap='viridis_r', s=100, alpha=0.7)
        
        # æ·»åŠ ç¨³å®šåº¦æ ‡ç­¾
        for i, stability in enumerate(stabilities):
            ax6.annotate(stability, (sample_counts[i], r2_values[i]),
                        xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        ax6.set_xlabel('æ ·æœ¬æ•°é‡')
        ax6.set_ylabel('RÂ² Score')
        ax6.set_title('æ€§èƒ½ä¸æ ·æœ¬é‡å…³ç³»')
        ax6.grid(True, alpha=0.3)
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(scatter, ax=ax6)
        cbar.set_label('RMSE (MW)')
        
        plt.tight_layout()
        plt.savefig(f"{self.save_path}/stability_performance_comparison.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        # è¾“å‡ºæ€§èƒ½æ’å
        print("\nğŸ“Š æ€§èƒ½æ’å (æŒ‰RÂ²é™åº):")
        performance_df = pd.DataFrame({
            'stability': stabilities,
            'r2': r2_values,
            'rmse': rmse_values,
            'samples': sample_counts,
            'power_mean': power_means
        }).sort_values('r2', ascending=False)
        
        for i, row in performance_df.iterrows():
            print(f"  {i+1}. {row['stability']}: RÂ²={row['r2']:.3f}, "
                  f"RMSE={row['rmse']:.1f}MW, æ ·æœ¬={row['samples']}")
        
        return performance_df
    
    def plot_stability_shap_comparison(self):
        """ç»˜åˆ¶ä¸åŒç¨³å®šåº¦çš„SHAPé‡è¦æ€§å¯¹æ¯”"""
        print("ğŸ“Š ç»˜åˆ¶ç¨³å®šåº¦SHAPé‡è¦æ€§å¯¹æ¯”...")
        
        if not self.results or not any('shap_values' in result for result in self.results.values()):
            print("âš ï¸ æ²¡æœ‰SHAPç»“æœï¼Œè·³è¿‡SHAPå¯¹æ¯”")
            return
        
        # è®¡ç®—å„ç¨³å®šåº¦çš„å¹³å‡SHAPé‡è¦æ€§
        shap_importance_df = pd.DataFrame({'feature': self.feature_names})
        
        for stability in self.results.keys():
            if 'shap_values' in self.results[stability]:
                shap_values = self.results[stability]['shap_values']
                importance = np.abs(shap_values).mean(axis=0)
                shap_importance_df[f'{stability}_importance'] = importance
        
        # è®¡ç®—æ€»ä½“é‡è¦æ€§æ’åº
        importance_cols = [col for col in shap_importance_df.columns if 'importance' in col]
        shap_importance_df['avg_importance'] = shap_importance_df[importance_cols].mean(axis=1)
        shap_importance_df = shap_importance_df.sort_values('avg_importance', ascending=False)
        
        # ç»˜åˆ¶å¯¹æ¯”å›¾
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('ä¸åŒç¨³å®šåº¦æ¡ä»¶ä¸‹çš„SHAPé‡è¦æ€§å¯¹æ¯”', fontsize=16, fontweight='bold')
        
        # 1. Topç‰¹å¾é‡è¦æ€§å¯¹æ¯”
        top_n = 15
        top_features = shap_importance_df.head(top_n)
        
        ax1 = axes[0, 0]
        stabilities = [col.replace('_importance', '') for col in importance_cols]
        x = np.arange(len(top_features))
        width = 0.8 / len(stabilities)
        
        for i, stability in enumerate(stabilities):
            col = f'{stability}_importance'
            offset = (i - len(stabilities)/2 + 0.5) * width
            ax1.barh(x + offset, top_features[col], width, 
                    label=stability, alpha=0.7)
        
        ax1.set_yticks(x)
        ax1.set_yticklabels(top_features['feature'], fontsize=8)
        ax1.set_xlabel('SHAPé‡è¦æ€§')
        ax1.set_title(f'Top {top_n} ç‰¹å¾é‡è¦æ€§å¯¹æ¯”')
        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax1.grid(True, alpha=0.3)
        
        # 2. ç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾
        ax2 = axes[0, 1]
        # é€‰æ‹©topç‰¹å¾ç»˜åˆ¶çƒ­åŠ›å›¾
        top_20_features = shap_importance_df.head(20)
        heatmap_data = top_20_features[importance_cols].T
        heatmap_data.columns = top_20_features['feature']
        
        sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='YlOrRd', 
                   ax=ax2, cbar_kws={'label': 'SHAPé‡è¦æ€§'})
        ax2.set_title('Top 20 ç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾')
        ax2.set_xlabel('ç‰¹å¾')
        ax2.set_ylabel('ç¨³å®šåº¦ç±»å‹')
        
        # 3. æŒ‰å˜é‡ç±»å‹åˆ†ç»„çš„é‡è¦æ€§
        ax3 = axes[1, 0]
        
        feature_categories = {
            'wind_speed': [f for f in self.feature_names if 'wind_speed' in f],
            'wind_direction': [f for f in self.feature_names if 'wind_dir' in f],  
            'temperature': [f for f in self.feature_names if 'temperature' in f],
            'alpha': [f for f in self.feature_names if 'alpha' in f],
            'other': [f for f in self.feature_names if not any(keyword in f for keyword in 
                     ['wind_speed', 'wind_dir', 'temperature', 'alpha'])]
        }
        
        category_importance = pd.DataFrame()
        for category, features in feature_categories.items():
            if features:
                cat_data = {}
                cat_data['category'] = category
                for stability in stabilities:
                    col = f'{stability}_importance'
                    if col in shap_importance_df.columns:
                        cat_features = shap_importance_df[shap_importance_df['feature'].isin(features)]
                        cat_data[stability] = cat_features[col].sum()
                    else:
                        cat_data[stability] = 0
                category_importance = pd.concat([category_importance, pd.DataFrame([cat_data])], ignore_index=True)
        
        # ç»˜åˆ¶åˆ†ç±»é‡è¦æ€§å¯¹æ¯”
        x = np.arange(len(category_importance))
        width = 0.8 / len(stabilities)
        
        for i, stability in enumerate(stabilities):
            offset = (i - len(stabilities)/2 + 0.5) * width
            if stability in category_importance.columns:
                ax3.bar(x + offset, category_importance[stability], width, 
                       label=stability, alpha=0.7)
        
        ax3.set_xticks(x)
        ax3.set_xticklabels(category_importance['category'])
        ax3.set_ylabel('ç´¯è®¡SHAPé‡è¦æ€§')
        ax3.set_title('æŒ‰å˜é‡ç±»å‹åˆ†ç»„çš„é‡è¦æ€§å¯¹æ¯”')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. ç¨³å®šåº¦é—´é‡è¦æ€§å·®å¼‚åˆ†æ
        ax4 = axes[1, 1]
        
        if len(stabilities) >= 2:
            # è®¡ç®—ä¸åŒç¨³å®šåº¦é—´çš„é‡è¦æ€§å·®å¼‚
            stability1, stability2 = stabilities[0], stabilities[1]
            col1, col2 = f'{stability1}_importance', f'{stability2}_importance'
            
            if col1 in shap_importance_df.columns and col2 in shap_importance_df.columns:
                diff = shap_importance_df[col1] - shap_importance_df[col2]
                shap_importance_df['diff'] = diff
                diff_sorted = shap_importance_df.sort_values('diff', ascending=True)
                
                colors = ['red' if x < 0 else 'blue' for x in diff_sorted['diff']]
                ax4.barh(range(len(diff_sorted)), diff_sorted['diff'], color=colors, alpha=0.6)
                ax4.set_yticks(range(len(diff_sorted)))
                ax4.set_yticklabels(diff_sorted['feature'], fontsize=6)
                ax4.set_xlabel(f'é‡è¦æ€§å·®å¼‚ ({stability1} - {stability2})')
                ax4.set_title(f'{stability1} vs {stability2} é‡è¦æ€§å·®å¼‚')
                ax4.axvline(x=0, color='black', linestyle='--', alpha=0.5)
                ax4.grid(True, alpha=0.3)
            else:
                ax4.text(0.5, 0.5, 'æ•°æ®ä¸è¶³\næ— æ³•è¿›è¡Œå·®å¼‚åˆ†æ', 
                        ha='center', va='center', transform=ax4.transAxes)
                ax4.set_title('é‡è¦æ€§å·®å¼‚åˆ†æ')
        else:
            ax4.text(0.5, 0.5, 'éœ€è¦è‡³å°‘2ç§ç¨³å®šåº¦\nè¿›è¡Œå·®å¼‚åˆ†æ', 
                    ha='center', va='center', transform=ax4.transAxes)
            ax4.set_title('é‡è¦æ€§å·®å¼‚åˆ†æ')
        
        plt.tight_layout()
        plt.savefig(f"{self.save_path}/stability_shap_comparison.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        # ä¿å­˜é‡è¦æ€§å¯¹æ¯”æ•°æ®
        shap_importance_df.to_csv(f"{self.save_path}/stability_shap_importance.csv", index=False)
        print("âœ“ SHAPé‡è¦æ€§å¯¹æ¯”æ•°æ®å·²ä¿å­˜")
        
        return shap_importance_df
    
    def analyze_stability_power_characteristics(self):
        """åˆ†æä¸åŒç¨³å®šåº¦ä¸‹çš„åŠŸç‡ç‰¹å¾"""
        print("âš¡ åˆ†æä¸åŒç¨³å®šåº¦çš„åŠŸç‡ç‰¹å¾...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('ä¸åŒç¨³å®šåº¦æ¡ä»¶ä¸‹çš„åŠŸç‡ç‰¹å¾åˆ†æ', fontsize=16, fontweight='bold')
        
        stabilities = list(self.stability_groups.keys())
        
        # 1. åŠŸç‡åˆ†å¸ƒå¯¹æ¯”
        ax1 = axes[0, 0]
        for stability in stabilities:
            power_data = self.stability_groups[stability]['power']
            ax1.hist(power_data, bins=30, alpha=0.6, label=f'{stability} (Î¼={power_data.mean():.1f})', 
                    density=True)
        
        ax1.set_xlabel('åŠŸç‡ (MW)')
        ax1.set_ylabel('å¯†åº¦')
        ax1.set_title('åŠŸç‡åˆ†å¸ƒå¯¹æ¯”')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. åŠŸç‡ç»Ÿè®¡ç®±çº¿å›¾
        ax2 = axes[0, 1]
        power_data_list = []
        labels = []
        for stability in stabilities:
            power_data_list.append(self.stability_groups[stability]['power'])
            labels.append(stability)
        
        ax2.boxplot(power_data_list, labels=labels)
        ax2.set_ylabel('åŠŸç‡ (MW)')
        ax2.set_title('åŠŸç‡ç»Ÿè®¡åˆ†å¸ƒ')
        ax2.tick_params(axis='x', rotation=45)
        ax2.grid(True, alpha=0.3)
        
        # 3. åŠŸç‡ä¸é£é€Ÿå…³ç³» - å…ˆæ‰¾åˆ°é£é€Ÿåˆ—
        ax3 = axes[1, 0]
        # ä»ç¬¬ä¸€ä¸ªç¨³å®šåº¦ç»„ä¸­æ‰¾é£é€Ÿåˆ—
        sample_data = self.stability_groups[stabilities[0]]
        wind_speed_cols = [col for col in sample_data.columns if 'wind_speed' in col and col.startswith('obs_')]
        
        if wind_speed_cols:
            main_wind_col = wind_speed_cols[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªé£é€Ÿåˆ—
            print(f"  ä½¿ç”¨é£é€Ÿåˆ—: {main_wind_col}")
            
            for stability in stabilities:
                data = self.stability_groups[stability]
                if main_wind_col in data.columns:
                    ax3.scatter(data[main_wind_col], data['power'], 
                              alpha=0.5, s=10, label=stability)
            
            ax3.set_xlabel(f'{main_wind_col} (m/s)')
            ax3.set_ylabel('åŠŸç‡ (MW)')
            ax3.set_title('åŠŸç‡-é£é€Ÿå…³ç³»')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
        else:
            ax3.text(0.5, 0.5, 'æœªæ‰¾åˆ°é£é€Ÿæ•°æ®', ha='center', va='center', transform=ax3.transAxes)
            ax3.set_title('åŠŸç‡-é£é€Ÿå…³ç³»')
        
        # 4. ç¨³å®šåº¦åŠŸç‡ç»Ÿè®¡è¡¨
        ax4 = axes[1, 1]
        ax4.axis('tight')
        ax4.axis('off')
        
        # åˆ›å»ºç»Ÿè®¡è¡¨
        stats_data = []
        for stability in stabilities:
            power = self.stability_groups[stability]['power']
            stats_data.append([
                stability,
                f"{len(power)}",
                f"{power.mean():.1f}",
                f"{power.std():.1f}",
                f"{power.min():.1f}",
                f"{power.max():.1f}",
                f"{power.quantile(0.5):.1f}"
            ])
        
        table = ax4.table(cellText=stats_data,
                         colLabels=['ç¨³å®šåº¦', 'æ ·æœ¬æ•°', 'å‡å€¼', 'æ ‡å‡†å·®', 'æœ€å°å€¼', 'æœ€å¤§å€¼', 'ä¸­ä½æ•°'],
                         cellLoc='center',
                         loc='center')
        table.auto_set_font_size(False)
        table.set_fontsize(9)
        table.scale(1.2, 1.5)
        ax4.set_title('åŠŸç‡ç»Ÿè®¡æ‘˜è¦', pad=20)
        
        plt.tight_layout()
        plt.savefig(f"{self.save_path}/stability_power_characteristics.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        return stats_data
    
    def save_stability_models_and_results(self):
        """ä¿å­˜ç¨³å®šåº¦æ¨¡å‹å’Œç»“æœ"""
        print("ğŸ’¾ ä¿å­˜ç¨³å®šåº¦æ¨¡å‹å’Œç»“æœ...")
        
        # ä¿å­˜å„ç¨³å®šåº¦æ¨¡å‹
        for stability, model in self.models.items():
            model_path = f"{self.save_path}/lightgbm_model_{stability}.pkl"
            joblib.dump(model, model_path)
            print(f"âœ“ {stability}æ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        # ä¿å­˜ç‰¹å¾åç§°
        feature_names_path = f"{self.save_path}/feature_names.pkl"
        joblib.dump(self.feature_names, feature_names_path)
        print(f"âœ“ ç‰¹å¾åç§°å·²ä¿å­˜: {feature_names_path}")
        
        # ä¿å­˜ç»“æœæ‘˜è¦
        results_summary = {}
        for stability in self.results:
            results_summary[stability] = {
                'r2_test': self.results[stability]['r2_test'],
                'rmse_test': self.results[stability]['rmse_test'],
                'sample_count': self.results[stability]['sample_count'],
                'power_mean': self.results[stability]['power_mean'],
                'power_std': self.results[stability]['power_std']
            }
        
        summary_path = f"{self.save_path}/stability_results_summary.pkl"
        joblib.dump(results_summary, summary_path)
        print(f"âœ“ ç»“æœæ‘˜è¦å·²ä¿å­˜: {summary_path}")
        
        # ä¿å­˜ç¨³å®šåº¦åˆ†ç»„æ•°æ®ä¿¡æ¯
        stability_info = {}
        for stability, data in self.stability_groups.items():
            stability_info[stability] = {
                'sample_count': len(data),
                'power_range': [data['power'].min(), data['power'].max()],
                'power_mean': data['power'].mean(),
                'confidence_mean': data['confidence_final'].mean() if 'confidence_final' in data.columns else None
            }
        
        info_path = f"{self.save_path}/stability_groups_info.pkl"
        joblib.dump(stability_info, info_path)
        print(f"âœ“ ç¨³å®šåº¦åˆ†ç»„ä¿¡æ¯å·²ä¿å­˜: {info_path}")
        
        return results_summary, stability_info
    
    def create_stability_prediction_function(self):
        """åˆ›å»ºåŸºäºç¨³å®šåº¦çš„é¢„æµ‹å‡½æ•°ç¤ºä¾‹"""
        print("ğŸ“ åˆ›å»ºç¨³å®šåº¦é¢„æµ‹å‡½æ•°ç¤ºä¾‹...")
        
        example_code = f'''
# ===== åŸºäºç¨³å®šåº¦çš„é£ç”µé¢„æµ‹ä½¿ç”¨ç¤ºä¾‹ =====
import joblib
import numpy as np
import pandas as pd

# 1. åŠ è½½æ‰€æœ‰ç¨³å®šåº¦æ¨¡å‹
models = {{}}
stabilities = {list(self.models.keys())}

for stability in stabilities:
    model_path = "{self.save_path}/lightgbm_model_{{stability}}.pkl"
    models[stability] = joblib.load(model_path)

# åŠ è½½ç‰¹å¾åç§°å’Œç»“æœä¿¡æ¯
feature_names = joblib.load("{self.save_path}/feature_names.pkl")
results_summary = joblib.load("{self.save_path}/stability_results_summary.pkl")

print("å·²åŠ è½½çš„ç¨³å®šåº¦æ¨¡å‹:", list(models.keys()))
print("ç‰¹å¾æ•°é‡:", len(feature_names))

# 2. ç»Ÿä¸€çš„ç¨³å®šåº¦é¢„æµ‹å‡½æ•°
def predict_by_stability(input_data, stability_labels, feature_names):
    \"\"\"
    åŸºäºç¨³å®šåº¦è¿›è¡Œé£ç”µåŠŸç‡é¢„æµ‹
    
    Parameters:
    -----------
    input_data : pd.DataFrame
        è¾“å…¥ç‰¹å¾æ•°æ®
    stability_labels : list or array
        å¯¹åº”æ¯æ¡æ•°æ®çš„ç¨³å®šåº¦æ ‡ç­¾
    feature_names : list
        ç‰¹å¾åç§°åˆ—è¡¨
    
    Returns:
    --------
    predictions : np.array
        é¢„æµ‹ç»“æœ
    used_models : list
        å®é™…ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨
    \"\"\"
    predictions = np.zeros(len(input_data))
    used_models = []
    
    # å‡†å¤‡ç‰¹å¾çŸ©é˜µ
    X = input_data[feature_names].values
    
    for stability in set(stability_labels):
        if stability in models:
            # æ‰¾åˆ°å¯¹åº”ç¨³å®šåº¦çš„æ•°æ®ç´¢å¼•
            mask = np.array(stability_labels) == stability
            if np.any(mask):
                # ä½¿ç”¨å¯¹åº”æ¨¡å‹é¢„æµ‹
                predictions[mask] = models[stability].predict(X[mask])
                used_models.append(stability)
                print(f"ä½¿ç”¨ {{stability}} æ¨¡å‹é¢„æµ‹äº† {{np.sum(mask)}} æ¡æ•°æ®")
        else:
            print(f"è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ° {{stability}} ç¨³å®šåº¦çš„æ¨¡å‹")
    
    return predictions, used_models

# 3. å¤„ç†æ–°æ•°æ®çš„å®Œæ•´æµç¨‹ç¤ºä¾‹
def process_new_data_with_stability(wind_data_path, stability_data_path):
    \"\"\"
    å¤„ç†æ–°æ•°æ®å¹¶è¿›è¡Œç¨³å®šåº¦åˆ†ç±»é¢„æµ‹çš„å®Œæ•´æµç¨‹
    \"\"\"
    # åŠ è½½æ•°æ®
    wind_data = pd.read_csv(wind_data_path)
    stability_data = pd.read_csv(stability_data_path)
    
    # æ—¶é—´å¯¹é½å’Œåˆå¹¶ï¼ˆæ ¹æ®ä½ çš„æ•°æ®ç»“æ„è°ƒæ•´ï¼‰
    wind_data['datetime'] = pd.to_datetime(wind_data['datetime'])
    stability_data['datetime'] = pd.to_datetime(stability_data['timestamp'])
    
    merged_data = pd.merge(wind_data, stability_data[['datetime', 'stability_final']], 
                          on='datetime', how='inner')
    
    # å¤„ç†é£å‘ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    wind_dir_cols = [col for col in merged_data.columns if 'wind_direction' in col]
    for col in wind_dir_cols:
        math_angle = (90 - merged_data[col] + 360) % 360
        wind_dir_rad = np.deg2rad(math_angle)
        
        sin_col = col.replace('wind_direction', 'wind_dir_sin')
        cos_col = col.replace('wind_direction', 'wind_dir_cos')
        merged_data[sin_col] = np.sin(wind_dir_rad)
        merged_data[cos_col] = np.cos(wind_dir_rad)
    
    merged_data = merged_data.drop(columns=wind_dir_cols)
    
    # è¿›è¡Œé¢„æµ‹
    predictions, used_models = predict_by_stability(
        merged_data, 
        merged_data['stability_final'].values,
        feature_names
    )
    
    # æ·»åŠ é¢„æµ‹ç»“æœ
    merged_data['predicted_power'] = predictions
    
    return merged_data, used_models

# 4. æ¨¡å‹æ€§èƒ½å¯¹æ¯”
print("\\nå„ç¨³å®šåº¦æ¨¡å‹æ€§èƒ½:")
for stability, summary in results_summary.items():
    print(f"  {{stability}}: RÂ²={{summary['r2_test']:.3f}}, "
          f"RMSE={{summary['rmse_test']:.1f}}MW, "
          f"æ ·æœ¬={{summary['sample_count']}}")

# 5. ä½¿ç”¨å»ºè®®
print("\\nä½¿ç”¨å»ºè®®:")
print("1. ç¡®ä¿è¾“å…¥æ•°æ®åŒ…å«æ‰€æœ‰è®­ç»ƒç‰¹å¾")
print("2. é£å‘æ•°æ®éœ€è¦æŒ‰ç…§è®­ç»ƒæ—¶çš„æ–¹å¼å¤„ç†ï¼ˆsin/cosåˆ†é‡ï¼‰")
print("3. ç¨³å®šåº¦æ ‡ç­¾å¿…é¡»ä¸è®­ç»ƒæ—¶çš„ç±»åˆ«ä¸€è‡´")
print("4. å¯¹äºæœªè§è¿‡çš„ç¨³å®šåº¦ç±»å‹ï¼Œå»ºè®®ä½¿ç”¨æœ€ç›¸è¿‘çš„ç¨³å®šåº¦æ¨¡å‹")
print("5. å¯ä»¥æ ¹æ®ç½®ä¿¡åº¦å¯¹é¢„æµ‹ç»“æœè¿›è¡ŒåŠ æƒ")

# ===== è¯¯å·®ä¼ æ’­åˆ†ææ‰©å±• =====
def analyze_stability_error_propagation(obs_data, forecast_data, stability_labels):
    \"\"\"
    åˆ†æä¸åŒç¨³å®šåº¦æ¡ä»¶ä¸‹çš„è¯¯å·®ä¼ æ’­ç‰¹æ€§
    \"\"\"
    results = {{}}
    
    for stability in set(stability_labels):
        mask = np.array(stability_labels) == stability
        if np.any(mask) and stability in models:
            # åˆ†åˆ«ç”¨è§‚æµ‹å’Œé¢„æŠ¥æ•°æ®é¢„æµ‹
            P_obs = models[stability].predict(obs_data[mask])
            P_forecast = models[stability].predict(forecast_data[mask])
            
            # è®¡ç®—è¯¯å·®ä¼ æ’­
            propagation_error = P_forecast - P_obs
            
            results[stability] = {{
                'rmse_propagation': np.sqrt(np.mean(propagation_error**2)),
                'mean_propagation': np.mean(propagation_error),
                'std_propagation': np.std(propagation_error),
                'sample_count': np.sum(mask)
            }}
    
    return results
        '''
        
        example_path = f"{self.save_path}/stability_prediction_usage.py"
        with open(example_path, 'w', encoding='utf-8') as f:
            f.write(example_code)
        print(f"âœ“ ä½¿ç”¨ç¤ºä¾‹å·²ä¿å­˜: {example_path}")
        
        return example_path
    
    def run_full_stability_analysis(self):
        """è¿è¡Œå®Œæ•´çš„ç¨³å®šåº¦åˆ†ææµç¨‹"""
        print("=" * 70)
        print("ğŸŒ€ åŸºäºå¤§æ°”ç¨³å®šåº¦åˆ†ç±»çš„é£ç”µé¢„æµ‹åˆ†æ")
        print("=" * 70)
        
        try:
            # 1. åŠ è½½æ•°æ®
            self.load_data()
            
            # 2. åˆ†æç¨³å®šåº¦åˆ†å¸ƒ
            stability_counts, confidence_stats = self.analyze_stability_distribution()
            
            # 3. åˆå¹¶æ•°æ®
            self.merge_data_by_time()
            
            # 4. æŒ‰ç¨³å®šåº¦åˆ†ç»„
            self.prepare_stability_groups(min_samples=500)
            
            # 5. è®­ç»ƒç¨³å®šåº¦æ¨¡å‹ï¼ˆè¿™ä¸€æ­¥ä¼šè®¾ç½®feature_namesï¼‰
            self.train_stability_models()
            
            # 6. åˆ†æåŠŸç‡ç‰¹å¾ï¼ˆç°åœ¨feature_nameså·²ç»è®¾ç½®å¥½äº†ï¼‰
            power_stats = self.analyze_stability_power_characteristics()
            
            # 7. è®¡ç®—SHAPå€¼
            self.calculate_stability_shap_values()
            
            # 8. ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”
            performance_df = self.plot_stability_performance_comparison()
            
            # 9. ç»˜åˆ¶SHAPå¯¹æ¯”
            shap_comparison = self.plot_stability_shap_comparison()
            
            # 10. ä¿å­˜æ¨¡å‹å’Œç»“æœ
            results_summary, stability_info = self.save_stability_models_and_results()
            
            # 11. åˆ›å»ºä½¿ç”¨ç¤ºä¾‹
            self.create_stability_prediction_function()
            
            print("\n" + "=" * 70)
            print("ğŸ‰ ç¨³å®šåº¦åˆ†æå®Œæˆï¼")
            print("=" * 70)
            
            print("ğŸ“Š ä¸»è¦å‘ç°:")
            print(f"  è®­ç»ƒçš„ç¨³å®šåº¦æ¨¡å‹æ•°é‡: {len(self.models)}")
            print(f"  ç¨³å®šåº¦ç±»å‹: {list(self.models.keys())}")
            
            if performance_df is not None and len(performance_df) > 0:
                best_stability = performance_df.iloc[0]['stability']
                best_r2 = performance_df.iloc[0]['r2']
                print(f"  æœ€ä½³é¢„æµ‹æ€§èƒ½: {best_stability} (RÂ²={best_r2:.3f})")
                
                worst_stability = performance_df.iloc[-1]['stability']
                worst_r2 = performance_df.iloc[-1]['r2']
                print(f"  æœ€ä½é¢„æµ‹æ€§èƒ½: {worst_stability} (RÂ²={worst_r2:.3f})")
                
                r2_range = best_r2 - worst_r2
                print(f"  æ€§èƒ½å·®è·: {r2_range:.3f}")
                
                if r2_range > 0.1:
                    print("  â†’ ä¸åŒç¨³å®šåº¦çš„é¢„æµ‹éš¾åº¦å·®å¼‚è¾ƒå¤§ï¼Œåˆ†ç±»å»ºæ¨¡å¾ˆæœ‰ä»·å€¼")
                else:
                    print("  â†’ ä¸åŒç¨³å®šåº¦çš„é¢„æµ‹æ€§èƒ½ç›¸è¿‘ï¼Œå¯è€ƒè™‘ç»Ÿä¸€å»ºæ¨¡")
            
            print(f"\nğŸ“ ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: {self.save_path}")
            print("  - stability_distribution_analysis.png: ç¨³å®šåº¦åˆ†å¸ƒåˆ†æ")
            print("  - stability_power_characteristics.png: åŠŸç‡ç‰¹å¾åˆ†æ")
            print("  - stability_performance_comparison.png: æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
            print("  - stability_shap_comparison.png: SHAPé‡è¦æ€§å¯¹æ¯”")
            print("  - stability_prediction_usage.py: ä½¿ç”¨ç¤ºä¾‹ä»£ç ")
            
            print(f"\nğŸ” å…³é”®æ´å¯Ÿ:")
            
            # åˆ†æç¨³å®šåº¦ä¸é¢„æµ‹æ€§èƒ½çš„å…³ç³»
            if len(self.models) >= 2:
                print("  ä¸åŒç¨³å®šåº¦æ¡ä»¶ä¸‹çš„é¢„æµ‹ç‰¹å¾:")
                for stability in self.models.keys():
                    r2 = results_summary[stability]['r2_test']
                    samples = results_summary[stability]['sample_count']
                    power_mean = results_summary[stability]['power_mean']
                    
                    if r2 > 0.8:
                        perf_level = "ä¼˜ç§€"
                    elif r2 > 0.6:
                        perf_level = "è‰¯å¥½"
                    elif r2 > 0.4:
                        perf_level = "ä¸€èˆ¬"
                    else:
                        perf_level = "è¾ƒå·®"
                    
                    print(f"    - {stability}: {perf_level}é¢„æµ‹æ€§èƒ½ (RÂ²={r2:.3f}), "
                          f"å¹³å‡åŠŸç‡{power_mean:.1f}MW, æ ·æœ¬{samples}æ¡")
            
            return True
            
        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

if __name__ == "__main__":
    # é…ç½®è·¯å¾„
    WIND_DATA_PATH = "/Users/xiaxin/work/WindForecast_Project/01_Data/processed/imputed_data/changma_imputed_complete.csv"
    STABILITY_DATA_PATH = "/Users/xiaxin/work/WindForecast_Project/03_Results/stability_analysis/changma_stability_results.csv"
    SAVE_PATH = "/Users/xiaxin/work/WindForecast_Project/03_Results/stability_based_prediction"
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    import os
    os.makedirs(SAVE_PATH, exist_ok=True)
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ
    analyzer = StabilityBasedWindPredictionAnalyzer(WIND_DATA_PATH, STABILITY_DATA_PATH, SAVE_PATH)
    success = analyzer.run_full_stability_analysis()
    
    if success:
        print("\nğŸ¯ ç¨³å®šåº¦åˆ†ææˆåŠŸå®Œæˆï¼")
        print("\nğŸ’¡ åç»­ç ”ç©¶å»ºè®®:")
        print("  1. æ·±å…¥åˆ†æé¢„æµ‹æ€§èƒ½å·®å¼‚çš„ç‰©ç†æœºåˆ¶")
        print("  2. ç»“åˆå¤©æ°”ç±»å‹è¿›ä¸€æ­¥ç»†åŒ–ç¨³å®šåº¦åˆ†ç±»")
        print("  3. ç ”ç©¶ç¨³å®šåº¦è½¬æ¢æ—¶æ®µçš„é¢„æµ‹ç­–ç•¥")
        print("  4. å¼€å‘ç¨³å®šåº¦è‡ªé€‚åº”çš„æ··åˆé¢„æµ‹æ¨¡å‹")
        print("  5. åˆ†æä¸åŒç¨³å®šåº¦ä¸‹çš„è¯¯å·®ä¼ æ’­ç‰¹æ€§")
    else:
        print("\nâš ï¸ åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å’Œæ•°æ®è·¯å¾„")