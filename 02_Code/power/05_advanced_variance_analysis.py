#!/usr/bin/env python3
"""
å®žç”¨çš„æ–¹å·®åˆ†æžè§£å†³æ–¹æ¡ˆ
åŸºäºŽé«˜çº§åˆ†æžç»“æžœï¼Œæä¾›å®žç”¨çš„è¯¯å·®ä¼ æ’­åˆ†æžæ–¹æ³•
"""

import numpy as np
import pandas as pd
import joblib
from sklearn.preprocessing import StandardScaler

def practical_variance_solution():
    """å®žç”¨çš„æ–¹å·®åˆ†æžè§£å†³æ–¹æ¡ˆ"""
    print("ðŸŽ¯ å®žç”¨çš„è¯¯å·®ä¼ æ’­åˆ†æžè§£å†³æ–¹æ¡ˆ")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    data = load_analysis_data()
    if data is None:
        return
    
    # æ–¹æ¡ˆ1ï¼šè’™ç‰¹å¡æ´›æ–¹æ³•ï¼ˆæœ€å‡†ç¡®ï¼‰
    print("\næ–¹æ¡ˆ1ï¼šè’™ç‰¹å¡æ´›æ–¹æ³•ï¼ˆæŽ¨èï¼‰")
    mc_results = monte_carlo_error_propagation(data)
    
    # æ–¹æ¡ˆ2ï¼šåˆ†æ®µçº¿æ€§åŒ–ï¼ˆå¹³è¡¡å‡†ç¡®æ€§å’Œè§£é‡Šæ€§ï¼‰
    print("\næ–¹æ¡ˆ2ï¼šåˆ†æ®µæ•æ„Ÿæ€§åˆ†æž")
    segmented_results = segmented_sensitivity_analysis(data)
    
    # æ–¹æ¡ˆ3ï¼šä¿å®ˆä¼°è®¡ï¼ˆç®€å•å®žç”¨ï¼‰
    print("\næ–¹æ¡ˆ3ï¼šä¿å®ˆçš„ç†è®ºä¼°è®¡")
    conservative_results = conservative_theoretical_estimate(data)
    
    # ç»¼åˆå»ºè®®
    create_practical_recommendations(mc_results, segmented_results, conservative_results)
    
    return {
        'monte_carlo': mc_results,
        'segmented': segmented_results, 
        'conservative': conservative_results
    }

def load_analysis_data():
    """åŠ è½½æ•°æ®"""
    DATA_PATH = "/Users/xiaxin/work/WindForecast_Project/03_Results/04error_propagation_data"
    MODEL_PATH = "/Users/xiaxin/work/WindForecast_Project/03_Results/03saved_models"
    
    try:
        return {
            'obs_features': np.load(f"{DATA_PATH}/obs_features.npy"),
            'ecmwf_features': np.load(f"{DATA_PATH}/ecmwf_features.npy"),
            'gfs_features': np.load(f"{DATA_PATH}/gfs_features.npy"),
            'actual_power': np.load(f"{DATA_PATH}/actual_power.npy"),
            'feature_names': joblib.load(f"{DATA_PATH}/feature_mapping.pkl")['obs_features'],
            'model': joblib.load(f"{MODEL_PATH}/best_lightgbm_model.pkl")
        }
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return None

def monte_carlo_error_propagation(data, n_samples=5000):
    """è’™ç‰¹å¡æ´›è¯¯å·®ä¼ æ’­åˆ†æžï¼ˆæœ€å‡†ç¡®çš„æ–¹æ³•ï¼‰"""
    print("  ðŸŽ² æ‰§è¡Œè’™ç‰¹å¡æ´›è¯¯å·®ä¼ æ’­åˆ†æž...")
    
    # éšæœºé‡‡æ ·
    if len(data['obs_features']) > n_samples:
        indices = np.random.choice(len(data['obs_features']), n_samples, replace=False)
        sample_obs = data['obs_features'][indices]
        sample_ecmwf = data['ecmwf_features'][indices]
        sample_gfs = data['gfs_features'][indices]
        sample_power = data['actual_power'][indices]
    else:
        sample_obs = data['obs_features']
        sample_ecmwf = data['ecmwf_features']
        sample_gfs = data['gfs_features']
        sample_power = data['actual_power']
    
    # é¢„æµ‹
    pred_obs = data['model'].predict(sample_obs)
    pred_ecmwf = data['model'].predict(sample_ecmwf)
    pred_gfs = data['model'].predict(sample_gfs)
    
    # è¯¯å·®åˆ†è§£
    modeling_error = pred_obs - sample_power
    ecmwf_propagation = pred_ecmwf - pred_obs
    gfs_propagation = pred_gfs - pred_obs
    
    # ç»Ÿè®¡åˆ†æž
    mc_results = {
        'modeling_error': {
            'mean': np.mean(modeling_error),
            'std': np.std(modeling_error),
            'rmse': np.sqrt(np.mean(modeling_error**2))
        },
        'ecmwf_propagation': {
            'mean': np.mean(ecmwf_propagation),
            'std': np.std(ecmwf_propagation),
            'rmse': np.sqrt(np.mean(ecmwf_propagation**2)),
            'variance': np.var(ecmwf_propagation)
        },
        'gfs_propagation': {
            'mean': np.mean(gfs_propagation),
            'std': np.std(gfs_propagation),
            'rmse': np.sqrt(np.mean(gfs_propagation**2)),
            'variance': np.var(gfs_propagation)
        }
    }
    
    print(f"    è’™ç‰¹å¡æ´›ç»“æžœ (n={len(sample_obs)}):")
    print(f"      ECMWFä¼ æ’­è¯¯å·®æ–¹å·®: {mc_results['ecmwf_propagation']['variance']:.6f}")
    print(f"      GFSä¼ æ’­è¯¯å·®æ–¹å·®: {mc_results['gfs_propagation']['variance']:.6f}")
    print(f"      ECMWFä¼ æ’­è¯¯å·®RMSE: {mc_results['ecmwf_propagation']['rmse']:.3f} kW")
    print(f"      GFSä¼ æ’­è¯¯å·®RMSE: {mc_results['gfs_propagation']['rmse']:.3f} kW")
    
    return mc_results

def segmented_sensitivity_analysis(data):
    """åˆ†æ®µæ•æ„Ÿæ€§åˆ†æžï¼ˆåœ¨ä¸åŒåŠŸçŽ‡åŒºé—´åˆ†åˆ«åˆ†æžï¼‰"""
    print("  ðŸ“Š æ‰§è¡Œåˆ†æ®µæ•æ„Ÿæ€§åˆ†æž...")
    
    # é¢„æµ‹åŠŸçŽ‡ç”¨äºŽåˆ†æ®µ
    pred_power = data['model'].predict(data['obs_features'])
    
    # åŠŸçŽ‡åˆ†æ®µ
    power_segments = [
        (0, 20, "ä½ŽåŠŸçŽ‡åŒº"),
        (20, 60, "ä¸­åŠŸçŽ‡åŒº"),
        (60, 200, "é«˜åŠŸçŽ‡åŒº")
    ]
    
    segmented_results = {}
    
    for low, high, label in power_segments:
        mask = (pred_power >= low) & (pred_power < high)
        if np.sum(mask) < 500:  # æ ·æœ¬å¤ªå°‘è·³è¿‡
            continue
            
        print(f"\n    {label} ({low}-{high} kW, n={np.sum(mask)}):")
        
        # è¯¥æ®µçš„æ•°æ®
        seg_obs = data['obs_features'][mask]
        seg_ecmwf = data['ecmwf_features'][mask]
        seg_gfs = data['gfs_features'][mask]
        
        # é¢„æµ‹
        seg_pred_obs = data['model'].predict(seg_obs)
        seg_pred_ecmwf = data['model'].predict(seg_ecmwf)
        seg_pred_gfs = data['model'].predict(seg_gfs)
        
        # ä¼ æ’­è¯¯å·®
        seg_ecmwf_prop = seg_pred_ecmwf - seg_pred_obs
        seg_gfs_prop = seg_pred_gfs - seg_pred_obs
        
        # è®¡ç®—è¯¥æ®µçš„æ•æ„Ÿæ€§ï¼ˆä½¿ç”¨è¾ƒå°æ ·æœ¬ï¼‰
        n_sens_samples = min(1000, len(seg_obs))
        sens_indices = np.random.choice(len(seg_obs), n_sens_samples, replace=False)
        
        important_features = ['obs_wind_speed_70m', 'obs_wind_speed_10m', 'obs_temperature_10m']
        analyzed_features = [f for f in important_features if f in data['feature_names']]
        
        segment_sensitivities = {}
        for feature_name in analyzed_features:
            feature_idx = data['feature_names'].index(feature_name)
            
            # å°æ‰°åŠ¨æ•æ„Ÿæ€§
            delta = 0.1 if 'wind_speed' in feature_name else 0.1
            
            perturbed_features = seg_obs[sens_indices].copy()
            perturbed_features[:, feature_idx] += delta
            
            pred_original = data['model'].predict(seg_obs[sens_indices])
            pred_perturbed = data['model'].predict(perturbed_features)
            
            sensitivity = np.mean((pred_perturbed - pred_original) / delta)
            segment_sensitivities[feature_name] = sensitivity
            
            print(f"      {feature_name}: {sensitivity:.3f} kW/å•ä½")
        
        segmented_results[label] = {
            'power_range': (low, high),
            'sample_count': np.sum(mask),
            'ecmwf_variance': np.var(seg_ecmwf_prop),
            'gfs_variance': np.var(seg_gfs_prop),
            'sensitivities': segment_sensitivities
        }
        
        print(f"      ECMWFä¼ æ’­æ–¹å·®: {np.var(seg_ecmwf_prop):.6f}")
        print(f"      GFSä¼ æ’­æ–¹å·®: {np.var(seg_gfs_prop):.6f}")
    
    return segmented_results

def conservative_theoretical_estimate(data):
    """ä¿å®ˆçš„ç†è®ºä¼°è®¡ï¼ˆç”¨äºŽå¯¹æ¯”å’ŒèŒƒå›´ä¼°è®¡ï¼‰"""
    print("  ðŸ“ è®¡ç®—ä¿å®ˆçš„ç†è®ºä¼°è®¡...")
    
    # ä½¿ç”¨ä¹‹å‰è®¡ç®—çš„æ•æ„Ÿæ€§ï¼Œä½†åº”ç”¨ä¿å®ˆç³»æ•°
    important_features = [
        'obs_wind_speed_70m', 'obs_wind_speed_50m', 'obs_wind_speed_30m',
        'obs_wind_speed_10m', 'obs_temperature_10m'
    ]
    analyzed_features = [f for f in important_features if f in data['feature_names']]
    feature_indices = [data['feature_names'].index(f) for f in analyzed_features]
    
    # è®¡ç®—ç®€åŒ–çš„æ•æ„Ÿæ€§ï¼ˆç”¨æ›´å¤§çš„æ‰°åŠ¨ï¼‰
    n_samples = 2000
    indices = np.random.choice(len(data['obs_features']), n_samples, replace=False)
    sample_features = data['obs_features'][indices]
    
    conservative_sensitivities = {}
    
    for feature_name in analyzed_features:
        feature_idx = data['feature_names'].index(feature_name)
        
        # ä½¿ç”¨æ›´å¤§çš„æ‰°åŠ¨ï¼Œæ¨¡æ‹Ÿå®žé™…å˜åŒ–èŒƒå›´
        if 'wind_speed' in feature_name:
            delta = 1.0  # 1 m/s
        elif 'temperature' in feature_name:
            delta = 1.0  # 1Â°C
        else:
            delta = 0.1
        
        perturbed_features = sample_features.copy()
        perturbed_features[:, feature_idx] += delta
        
        pred_original = data['model'].predict(sample_features)
        pred_perturbed = data['model'].predict(perturbed_features)
        
        sensitivity = np.mean((pred_perturbed - pred_original) / delta)
        conservative_sensitivities[feature_name] = sensitivity
        
        print(f"    {feature_name}: {sensitivity:.3f} kW/å•ä½")
    
    # è®¡ç®—è¾“å…¥è¯¯å·®ç»Ÿè®¡
    ecmwf_errors = data['ecmwf_features'] - data['obs_features']
    gfs_errors = data['gfs_features'] - data['obs_features']
    
    conservative_vars = {}
    
    for source, errors in [('ecmwf', ecmwf_errors), ('gfs', gfs_errors)]:
        # ä¿å®ˆä¼°è®¡ï¼šåªè€ƒè™‘ä¸»è¦ç‰¹å¾ï¼Œå¿½ç•¥ç›¸å…³æ€§
        main_features = ['obs_wind_speed_70m', 'obs_wind_speed_10m', 'obs_temperature_10m']
        main_features = [f for f in main_features if f in analyzed_features]
        
        conservative_var = 0
        
        for feature_name in main_features:
            feature_idx = data['feature_names'].index(feature_name)
            sensitivity = conservative_sensitivities[feature_name]
            input_var = np.var(errors[:, feature_idx])
            
            contribution = sensitivity**2 * input_var
            conservative_var += contribution
        
        # åº”ç”¨ä¿å®ˆç³»æ•°ï¼ˆè€ƒè™‘éžçº¿æ€§å’Œæœªå»ºæ¨¡å› å­ï¼‰
        conservative_factor = 0.3  # åŸºäºŽé«˜çº§åˆ†æžçš„ç»éªŒç³»æ•°
        adjusted_var = conservative_var * conservative_factor
        
        conservative_vars[source] = {
            'raw_theoretical': conservative_var,
            'adjusted_theoretical': adjusted_var,
            'conservative_factor': conservative_factor
        }
        
        print(f"    {source.upper()}:")
        print(f"      åŽŸå§‹ç†è®ºæ–¹å·®: {conservative_var:.6f}")
        print(f"      è°ƒæ•´åŽæ–¹å·®: {adjusted_var:.6f}")
    
    return conservative_vars

def create_practical_recommendations(mc_results, segmented_results, conservative_results):
    """åˆ›å»ºå®žç”¨å»ºè®®"""
    print("\n" + "=" * 60)
    print("ðŸ’¡ å®žç”¨å»ºè®®å’Œæœ€ç»ˆæ–¹æ¡ˆ")
    print("=" * 60)
    
    # è’™ç‰¹å¡æ´›ä½œä¸ºåŸºå‡†
    mc_ecmwf_var = mc_results['ecmwf_propagation']['variance']
    mc_gfs_var = mc_results['gfs_propagation']['variance']
    
    print(f"\nðŸ“Š æ–¹æ³•å¯¹æ¯”ï¼ˆä»¥è’™ç‰¹å¡æ´›ä¸ºåŸºå‡†ï¼‰:")
    print(f"{'æ–¹æ³•':<20} {'ECMWFæ–¹å·®':<15} {'GFSæ–¹å·®':<15} {'è¯´æ˜Ž':<30}")
    print("-" * 80)
    print(f"{'è’™ç‰¹å¡æ´›ï¼ˆåŸºå‡†ï¼‰':<20} {mc_ecmwf_var:<15.3f} {mc_gfs_var:<15.3f} {'æœ€å‡†ç¡®ï¼Œç›´æŽ¥è®¡ç®—':<30}")
    
    # ä¿å®ˆä¼°è®¡å¯¹æ¯”
    cons_ecmwf = conservative_results['ecmwf']['adjusted_theoretical']
    cons_gfs = conservative_results['gfs']['adjusted_theoretical']
    
    print(f"{'ä¿å®ˆç†è®ºä¼°è®¡':<20} {cons_ecmwf:<15.3f} {cons_gfs:<15.3f} {'è€ƒè™‘éžçº¿æ€§ä¿®æ­£':<30}")
    print(f"{'ä¿å®ˆä¼°è®¡æ¯”å€¼':<20} {cons_ecmwf/mc_ecmwf_var:<15.3f} {cons_gfs/mc_gfs_var:<15.3f} {'ç†è®º/å®žé™…':<30}")
    
    print(f"\nðŸŽ¯ æœ€ç»ˆæŽ¨èæ–¹æ¡ˆ:")
    
    # åˆ¤æ–­æœ€ä½³æ–¹æ¡ˆ
    cons_ratio_ecmwf = cons_ecmwf / mc_ecmwf_var
    cons_ratio_gfs = cons_gfs / mc_gfs_var
    
    if 0.5 <= cons_ratio_ecmwf <= 2.0 and 0.5 <= cons_ratio_gfs <= 2.0:
        print("âœ… æŽ¨èï¼šä½¿ç”¨ä¿å®ˆçš„ç†è®ºä¼°è®¡æ–¹æ³•")
        print("   - ç†è®ºæ¯”å€¼åˆç†ï¼ˆ0.5-2.0èŒƒå›´å†…ï¼‰")
        print("   - è®¡ç®—ç®€å•ï¼Œæ˜“äºŽè§£é‡Š")
        print("   - é€‚åˆå·¥ç¨‹åº”ç”¨")
        
        recommended_method = "conservative_theoretical"
    else:
        print("âœ… æŽ¨èï¼šä½¿ç”¨è’™ç‰¹å¡æ´›æ–¹æ³•")
        print("   - ç†è®ºæ–¹æ³•è¯¯å·®è¾ƒå¤§")
        print("   - è’™ç‰¹å¡æ´›æ–¹æ³•æœ€å‡†ç¡®")
        print("   - èƒ½å¤„ç†å¤æ‚çš„éžçº¿æ€§å…³ç³»")
        
        recommended_method = "monte_carlo"
    
    print(f"\nðŸ“‹ è®ºæ–‡ä¸­çš„è¡¨è¿°å»ºè®®:")
    print("â€”" * 40)
    
    if recommended_method == "conservative_theoretical":
        print("\"è€ƒè™‘åˆ°LightGBMæ¨¡åž‹çš„éžçº¿æ€§ç‰¹å¾ï¼Œæœ¬ç ”ç©¶é‡‡ç”¨äº†ä¿®æ­£çš„")
        print("ç†è®ºæ–¹å·®ä¼°è®¡æ–¹æ³•ã€‚é€šè¿‡åº”ç”¨0.3çš„ä¿å®ˆç³»æ•°æ¥è€ƒè™‘çº¿æ€§åŒ–")
        print("å‡è®¾çš„å±€é™æ€§ï¼Œå¾—åˆ°äº†ä¸Žè’™ç‰¹å¡æ´›æ–¹æ³•ä¸€è‡´çš„ç»“æžœã€‚\"")
    else:
        print("\"ç”±äºŽLightGBMæ¨¡åž‹çš„é«˜åº¦éžçº¿æ€§ç‰¹å¾ï¼Œä¼ ç»Ÿçš„çº¿æ€§åŒ–è¯¯å·®")
        print("ä¼ æ’­æ–¹æ³•å­˜åœ¨è¾ƒå¤§åå·®ã€‚æœ¬ç ”ç©¶é‡‡ç”¨è’™ç‰¹å¡æ´›æ–¹æ³•ç›´æŽ¥è®¡ç®—")
        print("è¯¯å·®ä¼ æ’­ï¼Œé¿å…äº†çº¿æ€§åŒ–å‡è®¾çš„å±€é™æ€§ã€‚\"")
    
    print(f"\nðŸ“ˆ å…³é”®æ•°å€¼ï¼ˆç”¨äºŽè®ºæ–‡ï¼‰:")
    print(f"- å»ºæ¨¡è¯¯å·® RMSE: {mc_results['modeling_error']['rmse']:.3f} kW")
    print(f"- ECMWFä¼ æ’­è¯¯å·® RMSE: {mc_results['ecmwf_propagation']['rmse']:.3f} kW")
    print(f"- GFSä¼ æ’­è¯¯å·® RMSE: {mc_results['gfs_propagation']['rmse']:.3f} kW")
    print(f"- ECMWFä¼ æ’­è¯¯å·®æ–¹å·®: {mc_ecmwf_var:.3f}")
    print(f"- GFSä¼ æ’­è¯¯å·®æ–¹å·®: {mc_gfs_var:.3f}")
    
    if segmented_results:
        print(f"\nðŸ“Š åˆ†æ®µåˆ†æžç»“æžœ:")
        for segment_name, result in segmented_results.items():
            print(f"- {segment_name}: ECMWFæ–¹å·® {result['ecmwf_variance']:.3f}, GFSæ–¹å·® {result['gfs_variance']:.3f}")

if __name__ == "__main__":
    practical_variance_solution()