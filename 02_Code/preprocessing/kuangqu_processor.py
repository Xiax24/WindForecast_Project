"""
çŸ¿åŒºæµ‹é£å¡”æ•°æ®å¤„ç†è„šæœ¬ï¼ˆä¿®å¤ç‰ˆï¼‰
ä¸“é—¨å¤„ç†çŸ¿åŒºæ•°æ®çš„ç‰¹æ®Šæ ¼å¼ï¼šæ—¥æœŸå’Œæ—¶é—´åˆ†ç¦»çš„æƒ…å†µ
"""

import pandas as pd
import numpy as np
import os
import glob
import re
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class KuangquDataProcessorFixed:
    def __init__(self, base_path):
        """
        åˆå§‹åŒ–çŸ¿åŒºæ•°æ®å¤„ç†å™¨
        
        å‚æ•°:
        base_path: çŸ¿åŒºæ•°æ®æ ¹ç›®å½•è·¯å¾„
        """
        self.base_path = base_path
        self.processed_path = os.path.join(base_path, '..', '..', 'processed', 'cleaned')
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.processed_path, exist_ok=True)
        
        # ç¼ºå¤±å€¼æ ‡è®°
        self.missing_values = [-99.0, -99, '-99.0', '-99', 'NULL', 'null', '', ' ', '\\N', 0.0]
        
        # çŸ¿åŒºæµ‹é£å¡”é«˜åº¦ï¼ˆä»æ–‡ä»¶åçœ‹ï¼Œæœ‰30m, 50m, 70mï¼‰
        self.available_heights = [30, 50, 70]

    def extract_height_from_filename(self, filename):
        """ä»çŸ¿åŒºæ–‡ä»¶åä¸­æå–é«˜åº¦ä¿¡æ¯"""
        pattern = r'æµ‹é£å¡”(\d+)ä¿¡æ¯æŠ¥è¡¨'
        match = re.search(pattern, filename)
        
        if match:
            height_str = match.group(1)
            try:
                height = int(height_str)
                if height in [30, 50, 70]:
                    return height
            except ValueError:
                pass
        
        return None

    def extract_date_from_filename(self, filename):
        """ä»çŸ¿åŒºæ–‡ä»¶åä¸­æå–æ—¥æœŸä¿¡æ¯"""
        date_pattern = r'(\d{4}-\d{2}-\d{2})-(\d{4}-\d{2}-\d{2})'
        match = re.search(date_pattern, filename)
        
        if match:
            start_date_str = match.group(1)
            end_date_str = match.group(2)
            
            try:
                start_date = datetime.strptime(start_date_str, '%Y-%m-%d')
                end_date = datetime.strptime(end_date_str, '%Y-%m-%d')
                return start_date, end_date
            except ValueError:
                pass
        
        return None, None

    def process_kuangqu_data(self, df):
        """å¤„ç†çŸ¿åŒºæ•°æ®çš„ç‰¹æ®Šæ ¼å¼"""
        if df.empty:
            return df
        
        df_processed = df.copy()
        
        print(f"      åŸå§‹åˆ—å: {df_processed.columns.tolist()}")
        
        # çŸ¿åŒºæ•°æ®ç‰¹æ®Šå¤„ç†ï¼šåˆå¹¶æ—¥æœŸå’Œæ—¶é—´åˆ—
        if 'æ—¥æœŸ' in df_processed.columns and 'æ—¶é—´' in df_processed.columns:
            print(f"      åˆå¹¶æ—¥æœŸå’Œæ—¶é—´åˆ—")
            
            # å¤„ç†æ—¥æœŸå’Œæ—¶é—´æ•°æ®
            dates = df_processed['æ—¥æœŸ'].astype(str)
            times = df_processed['æ—¶é—´'].astype(str)
            
            # ç»„åˆæˆå®Œæ•´çš„datetimeå­—ç¬¦ä¸²
            datetime_strings = dates + ' ' + times
            
            # è½¬æ¢ä¸ºdatetime
            try:
                df_processed['datetime'] = pd.to_datetime(datetime_strings, errors='coerce')
                print(f"      æˆåŠŸåˆ›å»ºdatetimeåˆ—")
                
                # åˆ é™¤åŸå§‹çš„æ—¥æœŸå’Œæ—¶é—´åˆ—
                df_processed = df_processed.drop(['æ—¥æœŸ', 'æ—¶é—´'], axis=1)
                
            except Exception as e:
                print(f"      datetimeè½¬æ¢å¤±è´¥: {e}")
                print(f"      æ—¥æœŸæ ·æœ¬: {dates.head().tolist()}")
                print(f"      æ—¶é—´æ ·æœ¬: {times.head().tolist()}")
                return pd.DataFrame()
        
        # æ ‡å‡†åŒ–å…¶ä»–åˆ—å
        column_mapping = {
            'å±‚é«˜': 'layer_height',
            'é£å‘': 'wind_direction',
            'é£é€Ÿ': 'wind_speed',
            'æ°”æ¸©': 'temperature',
            'æ°”å‹': 'pressure',
            'æ¹¿åº¦': 'humidity',
            'ç©ºæ°”å¯†åº¦': 'density'
        }
        
        for old_name, new_name in column_mapping.items():
            if old_name in df_processed.columns:
                df_processed = df_processed.rename(columns={old_name: new_name})
        
        print(f"      å¤„ç†ååˆ—å: {df_processed.columns.tolist()}")
        
        return df_processed

    def clean_kuangqu_data(self, df, height_value):
        """æ¸…ç†çŸ¿åŒºæ•°æ®"""
        if df.empty:
            return df
            
        df_clean = df.copy()
        
        # æ·»åŠ é«˜åº¦ä¿¡æ¯
        df_clean['height'] = height_value
        
        # å¤„ç†ç¼ºå¤±å€¼æ ‡è®°ï¼ˆçŸ¿åŒºæ•°æ®å¾ˆå¤šå˜é‡æ˜¾ç¤ºä¸º0.0ï¼Œå®é™…æ˜¯ç¼ºå¤±ï¼‰
        for col in ['temperature', 'pressure', 'humidity']:
            if col in df_clean.columns:
                # å°†0.0è§†ä¸ºç¼ºå¤±å€¼ï¼ˆå› ä¸ºæ°”æ¸©ã€æ°”å‹ã€æ¹¿åº¦ä¸å¯èƒ½ä¸º0ï¼‰
                df_clean[col] = df_clean[col].replace(self.missing_values, np.nan)
        
        # å¤„ç†å¯†åº¦æ•°æ®ï¼ˆ0.0ä¹Ÿè§†ä¸ºç¼ºå¤±ï¼‰
        if 'density' in df_clean.columns:
            df_clean['density'] = df_clean['density'].replace([0.0], np.nan)
        
        # é£é€Ÿå’Œé£å‘æ•°æ®æ£€æŸ¥
        if 'wind_speed' in df_clean.columns:
            mask_negative = df_clean['wind_speed'] < 0
            mask_extreme = df_clean['wind_speed'] > 50
            
            if mask_negative.sum() > 0:
                print(f"      å‘ç° {mask_negative.sum()} ä¸ªè´Ÿé£é€Ÿå€¼ï¼Œè®¾ä¸ºNaN")
                df_clean.loc[mask_negative, 'wind_speed'] = np.nan
            
            if mask_extreme.sum() > 0:
                print(f"      å‘ç° {mask_extreme.sum()} ä¸ªè¶…è¿‡50m/sçš„æç«¯é£é€Ÿå€¼ï¼Œè®¾ä¸ºNaN")
                df_clean.loc[mask_extreme, 'wind_speed'] = np.nan
        
        if 'wind_direction' in df_clean.columns:
            mask_wd_invalid = (df_clean['wind_direction'] < 0) | (df_clean['wind_direction'] > 360)
            if mask_wd_invalid.sum() > 0:
                print(f"      å‘ç° {mask_wd_invalid.sum()} ä¸ªæ— æ•ˆé£å‘å€¼ï¼Œè®¾ä¸ºNaN")
                df_clean.loc[mask_wd_invalid, 'wind_direction'] = np.nan
        
        # ç»Ÿè®¡æ•°æ®è´¨é‡
        key_vars = ['wind_speed', 'wind_direction', 'temperature', 'humidity', 'pressure', 'density']
        existing_vars = [v for v in key_vars if v in df_clean.columns]
        
        if existing_vars:
            print(f"      æ•°æ®è´¨é‡æ£€æŸ¥:")
            for var in existing_vars:
                missing_pct = df_clean[var].isnull().mean() * 100
                print(f"        {var}: {missing_pct:.1f}% ç¼ºå¤±")
        
        return df_clean

    def load_height_data(self, file_list, height_value):
        """åŠ è½½ç‰¹å®šé«˜åº¦çš„æ‰€æœ‰æ•°æ®æ–‡ä»¶"""
        print(f"  å¤„ç† {height_value}m é«˜åº¦æ•°æ®...")
        print(f"    æ–‡ä»¶æ•°é‡: {len(file_list)}")
        
        all_data = []
        
        for i, file_path in enumerate(file_list):
            filename = os.path.basename(file_path)
            print(f"    å¤„ç†æ–‡ä»¶ {i+1}/{len(file_list)}: {filename}")
            
            df = None
            # ä½¿ç”¨xlrdå¼•æ“è¯»å–.xlsæ–‡ä»¶
            try:
                df = pd.read_excel(file_path, engine='xlrd')
                print(f"      ä½¿ç”¨xlrdå¼•æ“æˆåŠŸè¯»å–")
                print(f"      åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
            except Exception as e:
                print(f"      è¯»å–å¤±è´¥: {e}")
                continue
            
            if df is not None and not df.empty:
                try:
                    # å¤„ç†æ•°æ®æ ¼å¼
                    df_processed = self.process_kuangqu_data(df)
                    
                    if df_processed.empty:
                        print(f"      æ•°æ®å¤„ç†åä¸ºç©º")
                        continue
                    
                    # æ¸…ç†æ•°æ®
                    df_cleaned = self.clean_kuangqu_data(df_processed, height_value)
                    
                    if not df_cleaned.empty and 'datetime' in df_cleaned.columns:
                        # æŒ‰æ—¶é—´æ’åº
                        df_cleaned = df_cleaned.sort_values('datetime')
                        df_cleaned = df_cleaned.reset_index(drop=True)
                        
                        print(f"      å¤„ç†åæ•°æ®å½¢çŠ¶: {df_cleaned.shape}")
                        print(f"      æ—¶é—´èŒƒå›´: {df_cleaned['datetime'].min()} åˆ° {df_cleaned['datetime'].max()}")
                        
                        all_data.append(df_cleaned)
                    else:
                        print(f"      æ•°æ®æ¸…ç†åä¸ºç©ºæˆ–ç¼ºå°‘æ—¶é—´åˆ—")
                        
                except Exception as e:
                    print(f"      æ•°æ®å¤„ç†é”™è¯¯: {e}")
        
        if all_data:
            # åˆå¹¶æ‰€æœ‰æ•°æ®
            combined_df = pd.concat(all_data, ignore_index=True)
            
            # æœ€ç»ˆæŒ‰æ—¶é—´æ’åº
            if 'datetime' in combined_df.columns:
                combined_df = combined_df.sort_values('datetime')
                combined_df = combined_df.reset_index(drop=True)
                
            print(f"    {height_value}m åˆå¹¶åæ•°æ®å½¢çŠ¶: {combined_df.shape}")
            return combined_df
        else:
            print(f"    {height_value}m æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
            return pd.DataFrame()

    def explore_kuangqu_structure(self):
        """æ¢ç´¢çŸ¿åŒºæ•°æ®çš„æ–‡ä»¶ç»“æ„"""
        print("æ¢ç´¢çŸ¿åŒºæµ‹é£å¡”æ•°æ®ç»“æ„...")
        print(f"åŸºç¡€è·¯å¾„: {self.base_path}")
        
        if not os.path.exists(self.base_path):
            print(f"é”™è¯¯ï¼šè·¯å¾„ä¸å­˜åœ¨ {self.base_path}")
            return {}
        
        # æŸ¥æ‰¾æ‰€æœ‰Excelæ–‡ä»¶
        excel_files = glob.glob(os.path.join(self.base_path, "*.xls*"))
        excel_files.sort()
        
        print(f"\næ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶")
        
        # æŒ‰é«˜åº¦åˆ†ç±»æ–‡ä»¶
        height_files = {30: [], 50: [], 70: []}
        
        for file_path in excel_files:
            filename = os.path.basename(file_path)
            height = self.extract_height_from_filename(filename)
            
            if height and height in height_files:
                height_files[height].append(file_path)
        
        # ç»Ÿè®¡å„é«˜åº¦æ–‡ä»¶æ•°é‡
        print(f"\næŒ‰é«˜åº¦åˆ†ç±»ç»Ÿè®¡:")
        for height in sorted(height_files.keys()):
            print(f"  {height}m: {len(height_files[height])} ä¸ªæ–‡ä»¶")
        
        return height_files

    def process_all_heights(self):
        """å¤„ç†æ‰€æœ‰é«˜åº¦çš„æ•°æ®"""
        print("å¼€å§‹å¤„ç†çŸ¿åŒºæµ‹é£å¡”çš„æ‰€æœ‰é«˜åº¦æ•°æ®...")
        
        # æ¢ç´¢æ–‡ä»¶ç»“æ„
        height_files = self.explore_kuangqu_structure()
        
        if not height_files:
            print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®æ–‡ä»¶")
            return {}
        
        height_data = {}
        
        for height in sorted(height_files.keys()):
            files = height_files[height]
            if files:
                print(f"\n{'='*50}")
                print(f"å¤„ç† {height}m é«˜åº¦æ•°æ®")
                print(f"{'='*50}")
                
                df = self.load_height_data(files, height)
                if not df.empty:
                    height_data[height] = df
                    print(f"âœ“ {height}m æ•°æ®å¤„ç†æˆåŠŸ")
                else:
                    print(f"âœ— {height}m æ•°æ®å¤„ç†å¤±è´¥")
            else:
                print(f"è·³è¿‡ {height}mï¼ˆæ— æ–‡ä»¶ï¼‰")
        
        return height_data

    def create_wide_format_data(self, height_data):
        """å°†ä¸åŒé«˜åº¦çš„æ•°æ®åˆå¹¶ä¸ºå®½æ ¼å¼"""
        print("\nåˆ›å»ºå®½æ ¼å¼æ•°æ®...")
        
        if not height_data:
            print("æ²¡æœ‰é«˜åº¦æ•°æ®å¯åˆå¹¶")
            return pd.DataFrame()
        
        # åˆ›å»ºç»Ÿä¸€æ—¶é—´åºåˆ—
        all_times = []
        for height, df in height_data.items():
            if 'datetime' in df.columns:
                times = df['datetime'].dropna().values
                all_times.extend(times)
                print(f"  {height}m: {len(times)} ä¸ªæœ‰æ•ˆæ—¶é—´ç‚¹")
        
        if not all_times:
            print("æ²¡æœ‰æœ‰æ•ˆçš„æ—¶é—´æ•°æ®")
            return pd.DataFrame()
        
        time_index = pd.DatetimeIndex(all_times).drop_duplicates().sort_values()
        print(f"ç»Ÿä¸€æ—¶é—´ç´¢å¼•: {len(time_index)} ä¸ªæ—¶é—´ç‚¹")
        print(f"æ—¶é—´èŒƒå›´: {time_index.min()} åˆ° {time_index.max()}")
        
        # åˆå§‹åŒ–å®½æ ¼å¼DataFrame
        df_wide = pd.DataFrame(index=time_index)
        
        # ä¸ºæ¯ä¸ªé«˜åº¦æ·»åŠ å˜é‡
        variables = ['wind_speed', 'wind_direction', 'temperature', 'humidity', 'pressure', 'density']
        
        for height in sorted(height_data.keys()):
            df_height = height_data[height]
            print(f"  æ·»åŠ  {height}m æ•°æ®...")
            
            # è®¾ç½®æ—¶é—´ä¸ºç´¢å¼•
            df_work = df_height.copy()
            df_work = df_work.set_index('datetime')
            
            # å¤„ç†é‡å¤æ—¶é—´
            if df_work.index.has_duplicates:
                print(f"    å‘ç°é‡å¤æ—¶é—´ï¼Œå–å¹³å‡å€¼")
                df_work = df_work.groupby(df_work.index).mean()
            
            for var in variables:
                if var in df_work.columns:
                    col_name = f"{var}_{height}m"
                    aligned_series = df_work[var].reindex(time_index)
                    df_wide[col_name] = aligned_series
                    
                    valid_count = df_wide[col_name].notna().sum()
                    valid_pct = valid_count / len(df_wide) * 100
                    print(f"    {col_name}: {valid_count} æœ‰æ•ˆå€¼ ({valid_pct:.1f}%)")
        
        print(f"\nå®½æ ¼å¼æ•°æ®åˆ›å»ºå®Œæˆ:")
        print(f"  å½¢çŠ¶: {df_wide.shape}")
        print(f"  åˆ—: {df_wide.columns.tolist()}")
        
        return df_wide

    def save_kuangqu_data(self, df_wide):
        """ä¿å­˜çŸ¿åŒºå¤„ç†åçš„æ•°æ®"""
        if df_wide.empty:
            print("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return None
        
        # ç”Ÿæˆæ–‡ä»¶å
        start_date = df_wide.index.min().strftime('%Y%m%d')
        end_date = df_wide.index.max().strftime('%Y%m%d')
        
        # ä¿å­˜CSVæ–‡ä»¶
        csv_filename = f"kuangqu_{start_date}_{end_date}_cleaned.csv"
        csv_filepath = os.path.join(self.processed_path, csv_filename)
        
        try:
            df_wide.to_csv(csv_filepath)
            print(f"\nâœ“ æ•°æ®å·²ä¿å­˜åˆ°: {csv_filepath}")
            
            file_size = os.path.getsize(csv_filepath) / 1024
            print(f"  æ–‡ä»¶å¤§å°: {file_size:.1f} KB")
            
        except Exception as e:
            print(f"\nâœ— ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")
            return None
        
        # ä¿å­˜æ‘˜è¦æ–‡ä»¶
        summary_filename = f"kuangqu_{start_date}_{end_date}_summary.txt"
        summary_filepath = os.path.join(self.processed_path, summary_filename)
        
        try:
            with open(summary_filepath, 'w', encoding='utf-8') as f:
                f.write("çŸ¿åŒºæµ‹é£å¡”æ•°æ®å¤„ç†æ‘˜è¦\n")
                f.write("="*50 + "\n\n")
                f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ•°æ®å½¢çŠ¶: {df_wide.shape}\n")
                f.write(f"æ—¶é—´èŒƒå›´: {df_wide.index.min()} åˆ° {df_wide.index.max()}\n")
                f.write(f"æ•°æ®æœŸé—´: {(df_wide.index.max() - df_wide.index.min()).days} å¤©\n\n")
                
                f.write("é«˜åº¦è¦†ç›–: 30m, 50m, 70mï¼ˆçŸ¿åŒºç«™æ— 10mæ•°æ®ï¼‰\n\n")
                
                f.write("å˜é‡åˆ—è¡¨:\n")
                for col in df_wide.columns:
                    valid_count = df_wide[col].notna().sum()
                    valid_pct = valid_count / len(df_wide) * 100
                    f.write(f"  {col}: {valid_count} æœ‰æ•ˆå€¼ ({valid_pct:.1f}%)\n")
                
                f.write("\nåŸºæœ¬ç»Ÿè®¡:\n")
                f.write(df_wide.describe().to_string())
            
            print(f"âœ“ æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_filepath}")
            
        except Exception as e:
            print(f"âœ— ä¿å­˜æ‘˜è¦æ–‡ä»¶å¤±è´¥: {e}")
        
        return csv_filepath

    def generate_data_summary(self, df_wide):
        """ç”Ÿæˆæ•°æ®æ‘˜è¦"""
        if df_wide.empty:
            print("æ²¡æœ‰æ•°æ®å¯ç”Ÿæˆæ‘˜è¦")
            return
        
        print("\n" + "="*60)
        print("çŸ¿åŒºæµ‹é£å¡”æ•°æ®æ‘˜è¦")
        print("="*60)
        
        print(f"æ•°æ®å½¢çŠ¶: {df_wide.shape}")
        print(f"æ—¶é—´èŒƒå›´: {df_wide.index.min()} åˆ° {df_wide.index.max()}")
        print(f"æ•°æ®æœŸé—´: {(df_wide.index.max() - df_wide.index.min()).days} å¤©")
        print(f"é«˜åº¦è¦†ç›–: 30m, 50m, 70m")
        
        # å˜é‡ç»Ÿè®¡
        print(f"\nå¯ç”¨å˜é‡:")
        for col in df_wide.columns:
            valid_count = df_wide[col].notna().sum()
            valid_pct = valid_count / len(df_wide) * 100
            if valid_count > 0:
                mean_val = df_wide[col].mean()
                print(f"  {col}: {valid_count} æœ‰æ•ˆå€¼ ({valid_pct:.1f}%), å‡å€¼: {mean_val:.2f}")
            else:
                print(f"  {col}: {valid_count} æœ‰æ•ˆå€¼ ({valid_pct:.1f}%), æ— æœ‰æ•ˆæ•°æ®")
        
        # é£é€Ÿç»Ÿè®¡
        wind_speed_cols = [col for col in df_wide.columns if 'wind_speed' in col]
        if wind_speed_cols:
            print(f"\né£é€Ÿç»Ÿè®¡:")
            for col in sorted(wind_speed_cols):
                valid_data = df_wide[col].dropna()
                if len(valid_data) > 0:
                    stats = valid_data.describe()
                    print(f"  {col}:")
                    print(f"    å¹³å‡: {stats['mean']:.2f} m/s")
                    print(f"    æœ€å¤§: {stats['max']:.2f} m/s")
                    print(f"    æœ€å°: {stats['min']:.2f} m/s")
                    print(f"    æ ‡å‡†å·®: {stats['std']:.2f} m/s")

def main():
    """ä¸»å‡½æ•° - å¤„ç†çŸ¿åŒºæµ‹é£å¡”æ•°æ®"""
    # è®¾ç½®çŸ¿åŒºæ•°æ®è·¯å¾„
    kuangqu_path = "/Users/xiaxin/work/WindForecast_Project/01_Data/raw/obs/kuangqu"
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = KuangquDataProcessorFixed(kuangqu_path)
    
    print("="*60)
    print("å¼€å§‹çŸ¿åŒºæµ‹é£å¡”æ•°æ®å¤„ç†ï¼ˆä¿®å¤ç‰ˆï¼‰")
    print("="*60)
    
    # å¤„ç†æ‰€æœ‰é«˜åº¦æ•°æ®
    height_data = processor.process_all_heights()
    
    if height_data:
        print(f"\næˆåŠŸå¤„ç† {len(height_data)} ä¸ªé«˜åº¦çš„æ•°æ®")
        
        # åˆ›å»ºå®½æ ¼å¼æ•°æ®
        df_wide = processor.create_wide_format_data(height_data)
        
        if not df_wide.empty:
            # ç”Ÿæˆæ‘˜è¦
            processor.generate_data_summary(df_wide)
            
            # ä¿å­˜æ•°æ®
            output_file = processor.save_kuangqu_data(df_wide)
            
            if output_file:
                print(f"\nğŸ‰ çŸ¿åŒºæµ‹é£å¡”æ•°æ®å¤„ç†æˆåŠŸå®Œæˆï¼")
                print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
                
                # å¿«é€ŸéªŒè¯
                print(f"\nå¿«é€ŸéªŒè¯:")
                try:
                    test_df = pd.read_csv(output_file, index_col=0, parse_dates=True, nrows=5)
                    print(f"  âœ“ æ–‡ä»¶å¯æ­£å¸¸è¯»å–")
                    print(f"  âœ“ æ•°æ®å½¢çŠ¶: {test_df.shape}")
                    print(f"  âœ“ ä¸»è¦åˆ—: {[col for col in test_df.columns if 'wind_speed' in col]}")
                except Exception as e:
                    print(f"  âœ— æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            else:
                print(f"\nâŒ æ•°æ®ä¿å­˜å¤±è´¥")
        else:
            print("âŒ å®½æ ¼å¼æ•°æ®åˆ›å»ºå¤±è´¥")
    else:
        print("âŒ æœªèƒ½åŠ è½½ä»»ä½•é«˜åº¦æ•°æ®")

if __name__ == "__main__":
    main()