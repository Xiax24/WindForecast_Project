import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
import os
from pathlib import Path

warnings.filterwarnings('ignore')

class ObsWRFMatcher:
    """è§‚æµ‹æ•°æ®ä¸WRFæ¨¡æ‹Ÿæ•°æ®å®Œæ•´åŒ¹é…åˆ†æç³»ç»Ÿ - ä¿®æ­£ç‰ˆ"""
    
    def __init__(self, project_root="/Users/xiaxin/work/WindForecast_Project"):
        self.project_root = Path(project_root)
        self.data_base_path = self.project_root / "01_Data"
        
        # åŸºäºå®é™…è§‚æµ‹æ•°æ®ç»“æ„çš„ç«™ç‚¹é…ç½®
        self.station_configs = {
            'changma': {
                'obs_file': 'raw/processed/cleaned-15min/changma_20210501_20221031_15min.csv',
                'ec_wrf_file': 'raw/wrf/ec_driven/changma.csv',
                'gfs_wrf_file': 'raw/wrf/gfs_driven/changma.csv',
                'time_range': ('2021-05-01', '2022-10-31'),
                'obs_variables': {
                    'wind_speed_10m': 'wind_speed_10m',
                    'wind_speed_30m': 'wind_speed_30m', 
                    'wind_speed_50m': 'wind_speed_50m',
                    'wind_speed_70m': 'wind_speed_70m',
                    'wind_direction_10m': 'wind_direction_10m',
                    'wind_direction_30m': 'wind_direction_30m',
                    'wind_direction_50m': 'wind_direction_50m', 
                    'wind_direction_70m': 'wind_direction_70m',
                    'temperature_10m': 'temperature_10m',
                    'humidity_10m': 'humidity_10m',
                    'density_10m': 'density_10m'
                }
            },
            'kuangqu': {
                'obs_file': 'raw/processed/cleaned-15min/kuangqu_20210501_20220601_15min.csv',
                'ec_wrf_file': 'raw/wrf/ec_driven/kuangqu.csv',
                'gfs_wrf_file': 'raw/wrf/gfs_driven/kuangqu.csv',
                'time_range': ('2021-05-01', '2022-06-01'),
                'obs_variables': {
                    'wind_speed_30m': 'wind_speed_30m',
                    'wind_speed_50m': 'wind_speed_50m',
                    'wind_speed_70m': 'wind_speed_70m',
                    'wind_direction_30m': 'wind_direction_30m',
                    'wind_direction_50m': 'wind_direction_50m',
                    'wind_direction_70m': 'wind_direction_70m'
                }
            },
            'sanlijijingzi': {
                'obs_file': 'raw/processed/cleaned-15min/sanlijijingzi_20210601_20220616_15min.csv',
                'ec_wrf_file': 'raw/wrf/ec_driven/sanlijijingzi.csv', 
                'gfs_wrf_file': 'raw/wrf/gfs_driven/sanlijijingzi.csv',
                'time_range': ('2021-06-01', '2022-06-16'),
                'obs_variables': {
                    'wind_speed_10m': 'wind_speed_10m',
                    'wind_speed_30m': 'wind_speed_30m',
                    'wind_speed_50m': 'wind_speed_50m', 
                    'wind_speed_70m': 'wind_speed_70m',
                    'wind_direction_10m': 'wind_direction_10m',
                    'wind_direction_30m': 'wind_direction_30m',
                    'wind_direction_50m': 'wind_direction_50m',
                    'wind_direction_70m': 'wind_direction_70m',
                    'wind_speed_max_10m': 'wind_speed_max_10m',
                    'wind_speed_max_30m': 'wind_speed_max_30m',
                    'wind_speed_max_50m': 'wind_speed_max_50m',
                    'wind_speed_max_70m': 'wind_speed_max_70m',
                    'wind_speed_std_10m': 'wind_speed_std_10m',
                    'wind_speed_std_30m': 'wind_speed_std_30m',
                    'wind_speed_std_50m': 'wind_speed_std_50m',
                    'wind_speed_std_70m': 'wind_speed_std_70m'
                }
            }
        }
        
        # WRFå˜é‡æ˜ å°„å’Œè®¡ç®—è§„åˆ™ - ä¿®æ­£ç‰ˆ
        self.wrf_mapping_rules = {
            'wind_speed_10m': {'wrf_var': 'wind_speed_10m', 'calc_method': 'direct'},
            'wind_speed_30m': {'wrf_var': 'ws_30m', 'calc_method': 'direct'},
            'wind_speed_50m': {'wrf_var': 'ws_50m', 'calc_method': 'direct'}, 
            'wind_speed_70m': {'wrf_var': 'ws_70m', 'calc_method': 'direct'},
            'wind_direction_10m': {'wrf_var': 'wind_direction_10m', 'calc_method': 'direct'},
            'wind_direction_70m': {'wrf_var': 'wind_direction_70m', 'calc_method': 'direct'},
            'wind_direction_30m': {'wrf_var': ['u_30m', 'v_30m'], 'calc_method': 'wind_direction'},
            'wind_direction_50m': {'wrf_var': ['u_50m', 'v_50m'], 'calc_method': 'wind_direction'},
            'temperature_10m': {'wrf_var': 'tk_30m', 'calc_method': 'temp_convert_and_extrapolate'},
            'humidity_10m': {'wrf_var': None, 'calc_method': 'nan'},
            'density_10m': {'wrf_var': ['tk_30m', 'p_30m'], 'calc_method': 'density_calculate'},
            'wind_speed_max_10m': {'wrf_var': None, 'calc_method': 'nan'},
            'wind_speed_max_30m': {'wrf_var': None, 'calc_method': 'nan'},
            'wind_speed_max_50m': {'wrf_var': None, 'calc_method': 'nan'},
            'wind_speed_max_70m': {'wrf_var': None, 'calc_method': 'nan'},
            'wind_speed_std_10m': {'wrf_var': None, 'calc_method': 'nan'},
            'wind_speed_std_30m': {'wrf_var': None, 'calc_method': 'nan'},
            'wind_speed_std_50m': {'wrf_var': None, 'calc_method': 'nan'},
            'wind_speed_std_70m': {'wrf_var': None, 'calc_method': 'nan'}
        }
        
        self.matched_datasets = {}
        self.R_specific = 287.05  # J/(kgÂ·K) å¹²ç©ºæ°”æ¯”æ°”ä½“å¸¸æ•°
    
    def load_observation_data(self, station_name):
        """åŠ è½½è§‚æµ‹æ•°æ®"""
        print(f"æ­£åœ¨åŠ è½½ {station_name} è§‚æµ‹æ•°æ®...")
        
        obs_file = self.data_base_path / self.station_configs[station_name]['obs_file']
        
        try:
            obs_df = pd.read_csv(obs_file)
            obs_df['datetime'] = pd.to_datetime(obs_df['datetime'])
            obs_df.set_index('datetime', inplace=True)
            
            config_vars = self.station_configs[station_name]['obs_variables']
            available_vars = []
            missing_vars = []
            
            for var_name, col_name in config_vars.items():
                if col_name in obs_df.columns:
                    available_vars.append(var_name)
                else:
                    missing_vars.append(var_name)
            
            print(f"  - è§‚æµ‹æ•°æ®åŠ è½½æˆåŠŸ: {obs_df.shape[0]} ä¸ªæ—¶é—´ç‚¹")
            print(f"  - æ—¶é—´èŒƒå›´: {obs_df.index.min()} åˆ° {obs_df.index.max()}")
            print(f"  - å¯ç”¨å˜é‡: {len(available_vars)} ä¸ª")
            if missing_vars:
                print(f"  - ç¼ºå¤±å˜é‡: {len(missing_vars)} ä¸ª: {missing_vars}")
            
            return obs_df
            
        except Exception as e:
            print(f"  - è§‚æµ‹æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None
    
    def load_wrf_data(self, station_name, model_type='ec'):
        """åŠ è½½WRFæ•°æ®"""
        print(f"æ­£åœ¨åŠ è½½ {station_name} {model_type.upper()}-WRFæ•°æ®...")
        
        wrf_file_key = f'{model_type}_wrf_file'
        wrf_file = self.data_base_path / self.station_configs[station_name][wrf_file_key]
        
        try:
            wrf_df = pd.read_csv(wrf_file)
            
            print(f"  - åŸå§‹WRFæ•°æ®å½¢çŠ¶: {wrf_df.shape}")
            
            possible_time_cols = ['datetime', 'date', 'time', 'Date', 'DateTime']
            time_column = None
            
            for col in possible_time_cols:
                if col in wrf_df.columns:
                    time_column = col
                    break
            
            if time_column is None:
                print(f"  - âŒ åœ¨WRFæ•°æ®ä¸­æ‰¾ä¸åˆ°æ—¶é—´åˆ—!")
                return None
            
            print(f"  - ä½¿ç”¨æ—¶é—´åˆ—: {time_column}")
            
            wrf_df['datetime'] = pd.to_datetime(wrf_df[time_column])
            wrf_df.set_index('datetime', inplace=True)
            
            if time_column != 'datetime' and time_column in wrf_df.columns:
                wrf_df.drop(columns=[time_column], inplace=True)
            
            print(f"  - {model_type.upper()}-WRFæ•°æ®åŠ è½½æˆåŠŸ: {wrf_df.shape[0]} ä¸ªæ—¶é—´ç‚¹")
            print(f"  - æ—¶é—´èŒƒå›´: {wrf_df.index.min()} åˆ° {wrf_df.index.max()}")
            
            return wrf_df
            
        except Exception as e:
            print(f"  - {model_type.upper()}-WRFæ•°æ®åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def calculate_wind_direction(self, u_component, v_component):
        """ä»u, våˆ†é‡è®¡ç®—é£å‘"""
        wind_dir = (270 - np.arctan2(v_component, u_component) * 180 / np.pi) % 360
        return wind_dir
    
    def calculate_density_from_temp_pressure(self, temperature_k, pressure_pa):
        """æ ¹æ®ç†æƒ³æ°”ä½“å®šå¾‹è®¡ç®—ç©ºæ°”å¯†åº¦ Ï = P/(R*T)"""
        density = pressure_pa / (self.R_specific * temperature_k)
        return density
    
    def convert_kelvin_to_celsius(self, temp_kelvin):
        """å¼€å°”æ–‡è½¬æ‘„æ°åº¦"""
        return temp_kelvin - 273.15
    
    def extrapolate_temp_to_10m(self, temp_30m_celsius):
        """ä»30mæ¸©åº¦å¤–æ¨10mæ¸©åº¦"""
        lapse_rate = 0.0065  # K/m
        temp_10m = temp_30m_celsius + lapse_rate * (30 - 10)
        return temp_10m
    
    def calculate_wrf_variable(self, wrf_df, obs_var_name):
        """æ ¹æ®è§„åˆ™è®¡ç®—WRFä¸­çš„å¯¹åº”å˜é‡ - ä¿®æ­£ç‰ˆ"""
        
        if obs_var_name not in self.wrf_mapping_rules:
            print(f"    ! æœªçŸ¥å˜é‡ {obs_var_name}ï¼Œè®¾ä¸º NaN")
            return np.full(len(wrf_df), np.nan)
        
        rule = self.wrf_mapping_rules[obs_var_name]
        calc_method = rule['calc_method']
        wrf_var = rule['wrf_var']
        
        if calc_method == 'direct':
            if wrf_var in wrf_df.columns:
                return wrf_df[wrf_var]
            else:
                print(f"    ! WRFå˜é‡ {wrf_var} ä¸å­˜åœ¨ï¼Œè®¾ä¸º NaN")
                return np.full(len(wrf_df), np.nan)
        
        elif calc_method == 'wind_direction':
            u_var, v_var = wrf_var
            if u_var in wrf_df.columns and v_var in wrf_df.columns:
                calculated = self.calculate_wind_direction(wrf_df[u_var], wrf_df[v_var])
                print(f"    âœ“ ä» {u_var}, {v_var} è®¡ç®—äº† {obs_var_name}")
                return calculated
            else:
                print(f"    ! u/våˆ†é‡ {u_var}, {v_var} ä¸å­˜åœ¨ï¼Œè®¾ä¸º NaN")
                return np.full(len(wrf_df), np.nan)
        
        elif calc_method == 'temp_convert_and_extrapolate':
            if wrf_var in wrf_df.columns:
                temp_celsius_30m = self.convert_kelvin_to_celsius(wrf_df[wrf_var])
                temp_celsius_10m = self.extrapolate_temp_to_10m(temp_celsius_30m)
                print(f"    âœ“ ä» {wrf_var} è½¬æ¢å¹¶å¤–æ¨äº† {obs_var_name}")
                return temp_celsius_10m
            else:
                print(f"    ! ç”¨äºæ¸©åº¦è®¡ç®—çš„å˜é‡ {wrf_var} ä¸å­˜åœ¨ï¼Œè®¾ä¸º NaN")
                return np.full(len(wrf_df), np.nan)
        
        elif calc_method == 'density_calculate':
            temp_var, pres_var = wrf_var
            if temp_var in wrf_df.columns and pres_var in wrf_df.columns:
                temp_kelvin = wrf_df[temp_var]
                pressure = wrf_df[pres_var]
                
                mean_pressure = pressure.mean()
                if mean_pressure > 50000:
                    pressure_pa = pressure
                elif 500 < mean_pressure < 1200:
                    pressure_pa = pressure * 100
                else:
                    print(f"    ! æ°”å‹å•ä½æœªçŸ¥ (å‡å€¼: {mean_pressure:.1f})ï¼Œè®¾ä¸º NaN")
                    return np.full(len(wrf_df), np.nan)
                
                calculated_density = self.calculate_density_from_temp_pressure(temp_kelvin, pressure_pa)
                
                mean_density = calculated_density.mean()
                if 0.5 < mean_density < 2.0:
                    print(f"    âœ“ ä» {temp_var}, {pres_var} è®¡ç®—äº† {obs_var_name} (å‡å€¼: {mean_density:.3f} kg/mÂ³)")
                    return calculated_density
                else:
                    print(f"    ! å¯†åº¦è®¡ç®—ç»“æœå¼‚å¸¸ (å‡å€¼: {mean_density:.3f})ï¼Œè®¾ä¸º NaN")
                    return np.full(len(wrf_df), np.nan)
            else:
                print(f"    ! æ¸©åº¦/æ°”å‹å˜é‡ {temp_var}, {pres_var} ä¸å­˜åœ¨ï¼Œè®¾ä¸º NaN")
                return np.full(len(wrf_df), np.nan)
        
        elif calc_method == 'nan':
            print(f"    - {obs_var_name} è®¾ä¸º NaN (WRFæ— æ³•æä¾›)")
            return np.full(len(wrf_df), np.nan)
        
        else:
            print(f"    ! æœªçŸ¥è®¡ç®—æ–¹æ³• {calc_method}ï¼Œè®¾ä¸º NaN")
            return np.full(len(wrf_df), np.nan)
    
    def align_time_series(self, obs_df, ec_wrf_df, gfs_wrf_df):
        """å¯¹é½ä¸‰ä¸ªæ•°æ®é›†çš„æ—¶é—´åºåˆ—"""
        print("  - æ­£åœ¨å¯¹é½æ—¶é—´åºåˆ—...")
        
        common_start = max(obs_df.index.min(), ec_wrf_df.index.min(), gfs_wrf_df.index.min())
        common_end = min(obs_df.index.max(), ec_wrf_df.index.max(), gfs_wrf_df.index.max())
        
        print(f"    å…±åŒæ—¶é—´èŒƒå›´: {common_start} åˆ° {common_end}")
        
        obs_aligned = obs_df.loc[common_start:common_end]
        ec_wrf_aligned = ec_wrf_df.loc[common_start:common_end]
        gfs_wrf_aligned = gfs_wrf_df.loc[common_start:common_end]
        
        common_times = obs_aligned.index.intersection(ec_wrf_aligned.index).intersection(gfs_wrf_aligned.index)
        
        print(f"    å…±åŒæ—¶é—´ç‚¹æ•°é‡: {len(common_times)}")
        
        return (obs_aligned.loc[common_times], 
                ec_wrf_aligned.loc[common_times], 
                gfs_wrf_aligned.loc[common_times])
    
    def create_matched_dataset(self, station_name):
        """ä¸ºæŒ‡å®šç«™ç‚¹åˆ›å»ºåŒ¹é…çš„æ•°æ®é›†"""
        print(f"\n=== å¤„ç† {station_name} ç«™ç‚¹ ===")
        
        obs_df = self.load_observation_data(station_name)
        if obs_df is None:
            return None
            
        ec_wrf_df = self.load_wrf_data(station_name, 'ec')
        if ec_wrf_df is None:
            return None
            
        gfs_wrf_df = self.load_wrf_data(station_name, 'gfs')
        if gfs_wrf_df is None:
            return None
        
        obs_aligned, ec_aligned, gfs_aligned = self.align_time_series(obs_df, ec_wrf_df, gfs_wrf_df)
        
        matched_data = pd.DataFrame(index=obs_aligned.index)
        
        print("\n  è®¡ç®—WRFå¯¹åº”å˜é‡:")
        
        obs_vars = self.station_configs[station_name]['obs_variables']
        
        for obs_var_name, obs_col_name in obs_vars.items():
            
            if obs_col_name in obs_aligned.columns:
                matched_data[f'obs_{obs_var_name}'] = obs_aligned[obs_col_name]
            else:
                matched_data[f'obs_{obs_var_name}'] = np.nan
                print(f"    ! è§‚æµ‹å˜é‡ {obs_col_name} ä¸å­˜åœ¨")
            
            print(f"  å¤„ç† {obs_var_name} (EC-WRF):")
            ec_values = self.calculate_wrf_variable(ec_aligned, obs_var_name)
            matched_data[f'ec_{obs_var_name}'] = ec_values
            
            print(f"  å¤„ç† {obs_var_name} (GFS-WRF):")
            gfs_values = self.calculate_wrf_variable(gfs_aligned, obs_var_name)
            matched_data[f'gfs_{obs_var_name}'] = gfs_values
        
        print(f"\n  - åŒ¹é…æ•°æ®é›†åˆ›å»ºå®Œæˆ: {matched_data.shape}")
        print(f"  - å˜é‡æ•°é‡: {matched_data.shape[1]} ä¸ª")
        
        self.print_data_quality_summary(matched_data, station_name)
        
        return matched_data
    
    def print_data_quality_summary(self, matched_data, station_name):
        """è¾“å‡ºæ•°æ®è´¨é‡æ‘˜è¦"""
        print(f"\n  --- {station_name} æ•°æ®è´¨é‡æ‘˜è¦ ---")
        
        obs_vars = [col for col in matched_data.columns if col.startswith('obs_')]
        
        for obs_var in obs_vars:
            var_name = obs_var.replace('obs_', '')
            ec_var = f'ec_{var_name}'
            gfs_var = f'gfs_{var_name}'
            
            obs_valid = matched_data[obs_var].notna().sum()
            ec_valid = matched_data[ec_var].notna().sum()
            gfs_valid = matched_data[gfs_var].notna().sum()
            total = len(matched_data)
            
            all_valid = matched_data[[obs_var, ec_var, gfs_var]].notna().all(axis=1).sum()
            
            print(f"  {var_name}:")
            print(f"    OBS: {obs_valid}/{total} ({obs_valid/total*100:.1f}%)")
            print(f"    EC:  {ec_valid}/{total} ({ec_valid/total*100:.1f}%)")
            print(f"    GFS: {gfs_valid}/{total} ({gfs_valid/total*100:.1f}%)")
            print(f"    å…¨éƒ¨æœ‰æ•ˆ: {all_valid}/{total} ({all_valid/total*100:.1f}%)")
    
    def calculate_basic_statistics(self, matched_data, station_name):
        """è®¡ç®—åŸºæœ¬ç»Ÿè®¡æŒ‡æ ‡"""
        print(f"\n--- {station_name} ç»Ÿè®¡æŒ‡æ ‡ ---")
        
        stats_results = {}
        obs_vars = [col for col in matched_data.columns if col.startswith('obs_')]
        
        for obs_var in obs_vars:
            var_name = obs_var.replace('obs_', '')
            ec_var = f'ec_{var_name}'
            gfs_var = f'gfs_{var_name}'
            
            if ec_var in matched_data.columns and gfs_var in matched_data.columns:
                mask = matched_data[[obs_var, ec_var, gfs_var]].notna().all(axis=1)
                
                if mask.sum() > 10:
                    obs_valid = matched_data.loc[mask, obs_var]
                    ec_valid = matched_data.loc[mask, ec_var]
                    gfs_valid = matched_data.loc[mask, gfs_var]
                    
                    ec_bias = np.mean(ec_valid - obs_valid)
                    gfs_bias = np.mean(gfs_valid - obs_valid)
                    
                    ec_rmse = np.sqrt(np.mean((ec_valid - obs_valid)**2))
                    gfs_rmse = np.sqrt(np.mean((gfs_valid - obs_valid)**2))
                    
                    ec_mae = np.mean(np.abs(ec_valid - obs_valid))
                    gfs_mae = np.mean(np.abs(gfs_valid - obs_valid))
                    
                    ec_corr = np.corrcoef(obs_valid, ec_valid)[0, 1] if len(obs_valid) > 1 else np.nan
                    gfs_corr = np.corrcoef(obs_valid, gfs_valid)[0, 1] if len(obs_valid) > 1 else np.nan
                    
                    better_model = 'EC' if ec_rmse < gfs_rmse else 'GFS'
                    improvement = abs(ec_rmse - gfs_rmse) / max(ec_rmse, gfs_rmse) * 100
                    
                    stats_results[var_name] = {
                        'n_samples': mask.sum(),
                        'ec_bias': ec_bias,
                        'gfs_bias': gfs_bias,
                        'ec_rmse': ec_rmse,
                        'gfs_rmse': gfs_rmse,
                        'ec_mae': ec_mae,
                        'gfs_mae': gfs_mae,
                        'ec_corr': ec_corr,
                        'gfs_corr': gfs_corr,
                        'better_model': better_model,
                        'improvement_pct': improvement
                    }
                    
                    print(f"{var_name} ({mask.sum()} æ ·æœ¬):")
                    print(f"  EC  - BIAS: {ec_bias:6.3f}, RMSE: {ec_rmse:6.3f}, MAE: {ec_mae:6.3f}, CORR: {ec_corr:6.3f}")
                    print(f"  GFS - BIAS: {gfs_bias:6.3f}, RMSE: {gfs_rmse:6.3f}, MAE: {gfs_mae:6.3f}, CORR: {gfs_corr:6.3f}")
                    print(f"  æ›´ä¼˜: {better_model} (æ”¹å–„ {improvement:.1f}%)")
                    print()
                else:
                    print(f"{var_name}: æœ‰æ•ˆæ ·æœ¬ä¸è¶³ ({mask.sum()} < 10)")
        
        return stats_results
    
    def create_validation_plots(self, matched_data, station_name, output_dir=None):
        """åˆ›å»ºéªŒè¯å›¾è¡¨"""
        if output_dir is None:
            output_dir = self.project_root / "03_Results" / "validation_plots"
        else:
            output_dir = Path(output_dir)
            
        output_dir.mkdir(parents=True, exist_ok=True)
        
        wind_speed_vars = [col for col in matched_data.columns 
                          if col.startswith('obs_wind_speed') and 'std' not in col and 'max' not in col]
        
        n_vars = len(wind_speed_vars)
        if n_vars == 0:
            print("æ²¡æœ‰æ‰¾åˆ°é£é€Ÿå˜é‡ç”¨äºå¯è§†åŒ–")
            return
        
        fig, axes = plt.subplots(n_vars, 3, figsize=(18, 6*n_vars))
        if n_vars == 1:
            axes = axes.reshape(1, -1)
        
        for i, obs_var in enumerate(wind_speed_vars):
            var_name = obs_var.replace('obs_', '')
            ec_var = f'ec_{var_name}'
            gfs_var = f'gfs_{var_name}'
            
            mask = matched_data[[obs_var, ec_var, gfs_var]].notna().all(axis=1)
            
            if mask.sum() > 10:
                plot_data = matched_data.loc[mask]
                
                obs_plot = plot_data[obs_var]
                ec_plot = plot_data[ec_var]
                gfs_plot = plot_data[gfs_var]
                
                sample_size = min(1000, len(plot_data))
                sample_idx = np.linspace(0, len(plot_data)-1, sample_size, dtype=int)
                
                axes[i, 0].plot(plot_data.index[sample_idx], obs_plot.iloc[sample_idx], 'k-', 
                               label='OBS', alpha=0.7, linewidth=1)
                axes[i, 0].plot(plot_data.index[sample_idx], ec_plot.iloc[sample_idx], 'r-', 
                               label='EC-WRF', alpha=0.7, linewidth=1)
                axes[i, 0].plot(plot_data.index[sample_idx], gfs_plot.iloc[sample_idx], 'b-', 
                               label='GFS-WRF', alpha=0.7, linewidth=1)
                axes[i, 0].set_title(f'{station_name} - {var_name} Time Series')
                axes[i, 0].set_ylabel('Wind Speed (m/s)')
                axes[i, 0].legend()
                axes[i, 0].grid(True, alpha=0.3)
                
                max_val = max(obs_plot.max(), ec_plot.max(), gfs_plot.max())
                
                axes[i, 1].scatter(obs_plot, ec_plot, alpha=0.4, s=8, label='EC-WRF', color='red')
                axes[i, 1].scatter(obs_plot, gfs_plot, alpha=0.4, s=8, label='GFS-WRF', color='blue')
                axes[i, 1].plot([0, max_val], [0, max_val], 'k--', alpha=0.5)
                axes[i, 1].set_xlabel('Observed Wind Speed (m/s)')
                axes[i, 1].set_ylabel('Predicted Wind Speed (m/s)')
                axes[i, 1].set_title(f'{var_name} Scatter Plot')
                axes[i, 1].legend()
                axes[i, 1].grid(True, alpha=0.3)
                
                ec_error = ec_plot - obs_plot
                gfs_error = gfs_plot - obs_plot
                
                axes[i, 2].hist(ec_error, bins=30, alpha=0.6, label='EC-WRF Error', 
                               color='red', density=True)
                axes[i, 2].hist(gfs_error, bins=30, alpha=0.6, label='GFS-WRF Error', 
                               color='blue', density=True)
                axes[i, 2].axvline(0, color='k', linestyle='--', alpha=0.5)
                axes[i, 2].set_xlabel('Error (m/s)')
                axes[i, 2].set_ylabel('Density')
                axes[i, 2].set_title(f'{var_name} Error Distribution')
                axes[i, 2].legend()
                axes[i, 2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        output_file = output_dir / f'{station_name}_validation.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"éªŒè¯å›¾è¡¨å·²ä¿å­˜åˆ°: {output_file}")
    
    def save_matched_data(self, matched_data, station_name, output_dir=None):
        """ä¿å­˜åŒ¹é…æ•°æ®åˆ°æ–‡ä»¶"""
        if output_dir is None:
            output_dir = self.project_root / "01_Data" / "processed" / "matched_data"
        else:
            output_dir = Path(output_dir)
            
        output_dir.mkdir(parents=True, exist_ok=True)
        
        output_file = output_dir / f'{station_name}_matched.csv'
        matched_data.to_csv(output_file)
        
        # ç”Ÿæˆæ•°æ®æè¿°æ–‡ä»¶
        desc_file = output_dir / f'{station_name}_matched_description.txt'
        with open(desc_file, 'w', encoding='utf-8') as f:
            f.write(f"{station_name} åŒ¹é…æ•°æ®æè¿° (ä¿®æ­£ç‰ˆ)\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"æ•°æ®å½¢çŠ¶: {matched_data.shape}\n")
            f.write(f"æ—¶é—´èŒƒå›´: {matched_data.index.min()} åˆ° {matched_data.index.max()}\n")
            f.write(f"æ•°æ®æœŸé—´: {(matched_data.index.max() - matched_data.index.min()).days} å¤©\n\n")
            
            f.write("æ•°æ®å•ä½è¯´æ˜:\n")
            f.write("  é£é€Ÿ: m/s\n")
            f.write("  é£å‘: åº¦ (Â°)\n") 
            f.write("  æ¸©åº¦: æ‘„æ°åº¦ (Â°C) - å·²ä»å¼€å°”æ–‡è½¬æ¢\n")
            f.write("  å¯†åº¦: kg/mÂ³ - ä»æ¸©åº¦å’Œæ°”å‹é‡æ–°è®¡ç®—\n")
            f.write("  æ¹¿åº¦: % (ä»…è§‚æµ‹æ•°æ®)\n\n")
            
            f.write("WRFæ•°æ®å¤„ç†è¯´æ˜:\n")
            f.write("  - æ¸©åº¦: ä»tk_30mè½¬æ¢Kâ†’Â°Cå¹¶å¤–æ¨è‡³10m\n")
            f.write("  - å¯†åº¦: ä»tk_30må’Œp_30mç”¨ç†æƒ³æ°”ä½“å®šå¾‹è®¡ç®—\n")
            f.write("  - é£å‘: 30må’Œ50mä»u/våˆ†é‡è®¡ç®—\n")
            f.write("  - æ¹æµæŒ‡æ ‡: WRFæ— æ³•æä¾›ï¼Œè®¾ä¸ºNaN\n\n")
            
            f.write("å˜é‡å®Œæ•´æ€§:\n")
            for col in matched_data.columns:
                valid_count = matched_data[col].notna().sum()
                valid_pct = valid_count / len(matched_data) * 100
                f.write(f"  {col}: {valid_count}/{len(matched_data)} ({valid_pct:.1f}%)\n")
            
            f.write(f"\nåŸºæœ¬ç»Ÿè®¡:\n")
            f.write(matched_data.describe().to_string())
        
        print(f"åŒ¹é…æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
        print(f"æ•°æ®æè¿°å·²ä¿å­˜åˆ°: {desc_file}")
    
    def process_single_station(self, station_name):
        """å¤„ç†å•ä¸ªç«™ç‚¹"""
        print(f"å¼€å§‹å¤„ç† {station_name} ç«™ç‚¹...")
        
        try:
            matched_data = self.create_matched_dataset(station_name)
            
            if matched_data is not None:
                self.matched_datasets[station_name] = matched_data
                
                stats = self.calculate_basic_statistics(matched_data, station_name)
                
                self.create_validation_plots(matched_data, station_name)
                
                self.save_matched_data(matched_data, station_name)
                
                print(f"\nâœ… {station_name} ç«™ç‚¹å¤„ç†å®Œæˆ!")
                return stats
            else:
                print(f"\nâŒ {station_name} ç«™ç‚¹å¤„ç†å¤±è´¥!")
                return None
                
        except Exception as e:
            print(f"âŒ å¤„ç† {station_name} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def process_all_stations(self):
        """å¤„ç†æ‰€æœ‰ç«™ç‚¹"""
        print("å¼€å§‹å¤„ç†æ‰€æœ‰ç«™ç‚¹çš„æ•°æ®åŒ¹é…...")
        
        all_stats = {}
        
        for station_name in self.station_configs.keys():
            stats = self.process_single_station(station_name)
            if stats:
                all_stats[station_name] = stats
        
        self.generate_summary_report(all_stats)
        
        print("\nğŸ‰ æ‰€æœ‰ç«™ç‚¹å¤„ç†å®Œæˆ!")
        return all_stats
    
    def generate_summary_report(self, all_stats, output_file=None):
        """ç”Ÿæˆæ€»ä½“ç»“æœæ‘˜è¦æŠ¥å‘Š"""
        if output_file is None:
            output_file = self.project_root / "03_Results" / "obs_wrf_comparison_summary.txt"
        else:
            output_file = Path(output_file)
            
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("è§‚æµ‹-WRFæ•°æ®åŒ¹é…åˆ†ææ€»ä½“æŠ¥å‘Š (ä¿®æ­£ç‰ˆ)\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å¤„ç†ç«™ç‚¹æ•°: {len(all_stats)}\n\n")
            
            f.write("æ•°æ®å¤„ç†è¯´æ˜:\n")
            f.write("  - æ¸©åº¦å•ä½: å¼€å°”æ–‡(K) â†’ æ‘„æ°åº¦(Â°C)\n")
            f.write("  - å¯†åº¦è®¡ç®—: ä»WRFæ¸©åº¦å’Œæ°”å‹é‡æ–°è®¡ç®—\n")
            f.write("  - é£å‘è®¡ç®—: ä»u/våˆ†é‡è®¡ç®—\n")
            f.write("  - æ—¶é—´å¯¹é½: è§‚æµ‹ä¸WRFæ•°æ®ç²¾ç¡®åŒ¹é…\n\n")
            
            for station_name, stats in all_stats.items():
                f.write(f"=== {station_name} ç«™ç‚¹ç»“æœæ‘˜è¦ ===\n")
                
                if stats:
                    wind_speed_vars = [var for var in stats.keys() if 'wind_speed' in var and 'std' not in var and 'max' not in var]
                    
                    if wind_speed_vars:
                        f.write("ä¸»è¦é£é€Ÿå˜é‡:\n")
                        for var in wind_speed_vars:
                            metrics = stats[var]
                            f.write(f"  {var}:\n")
                            f.write(f"    æ ·æœ¬æ•°: {metrics['n_samples']}\n")
                            f.write(f"    EC  - RMSE: {metrics['ec_rmse']:.3f}, CORR: {metrics['ec_corr']:.3f}\n")
                            f.write(f"    GFS - RMSE: {metrics['gfs_rmse']:.3f}, CORR: {metrics['gfs_corr']:.3f}\n")
                            f.write(f"    æ›´ä¼˜æ¨¡å¼: {metrics['better_model']} (æ”¹å–„ {metrics['improvement_pct']:.1f}%)\n\n")
                    
                    other_vars = [var for var in stats.keys() if var not in wind_speed_vars]
                    if other_vars:
                        f.write("å…¶ä»–å˜é‡:\n")
                        for var in other_vars:
                            metrics = stats[var]
                            f.write(f"  {var}: {metrics['better_model']} æ›´ä¼˜ (RMSEæ”¹å–„ {metrics['improvement_pct']:.1f}%)\n")
                        f.write("\n")
                    
                    ec_better_count = sum(1 for v in stats.values() if v['better_model'] == 'EC')
                    gfs_better_count = sum(1 for v in stats.values() if v['better_model'] == 'GFS')
                    total_vars = len(stats)
                    
                    f.write(f"æ€»ä½“è¡¨ç°:\n")
                    f.write(f"  ECæ›´ä¼˜å˜é‡æ•°: {ec_better_count}/{total_vars} ({ec_better_count/total_vars*100:.1f}%)\n")
                    f.write(f"  GFSæ›´ä¼˜å˜é‡æ•°: {gfs_better_count}/{total_vars} ({gfs_better_count/total_vars*100:.1f}%)\n")
                    
                    if ec_better_count > gfs_better_count:
                        f.write(f"  æ¨è: è¯¥ç«™ç‚¹ä¼˜å…ˆä½¿ç”¨ EC-WRF\n")
                    elif gfs_better_count > ec_better_count:
                        f.write(f"  æ¨è: è¯¥ç«™ç‚¹ä¼˜å…ˆä½¿ç”¨ GFS-WRF\n")
                    else:
                        f.write(f"  æ¨è: ä¸¤ç§æ¨¡å¼è¡¨ç°ç›¸å½“ï¼Œå¯ç»“åˆä½¿ç”¨\n")
                
                f.write("\n" + "-" * 40 + "\n")
        
        print(f"\nğŸ“Š æ€»ä½“æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")

# ä½¿ç”¨ç¤ºä¾‹å’Œå¿«é€Ÿæµ‹è¯•å‡½æ•°
def quick_test_changma():
    """å¿«é€Ÿæµ‹è¯•æ˜Œé©¬ç«™ç‚¹"""
    print("ğŸ§ª å¿«é€Ÿæµ‹è¯•æ˜Œé©¬ç«™ç‚¹...")
    
    matcher = ObsWRFMatcher()
    stats = matcher.process_single_station('changma')
    
    if stats:
        print("\nâœ… æ˜Œé©¬ç«™ç‚¹æµ‹è¯•æˆåŠŸ!")
        return matcher, stats
    else:
        print("\nâŒ æ˜Œé©¬ç«™ç‚¹æµ‹è¯•å¤±è´¥!")
        return None, None

def quick_test_all():
    """å¿«é€Ÿæµ‹è¯•æ‰€æœ‰ç«™ç‚¹"""
    print("ğŸ§ª æµ‹è¯•æ‰€æœ‰ç«™ç‚¹...")
    
    matcher = ObsWRFMatcher()
    all_stats = matcher.process_all_stations()
    
    return matcher, all_stats

# ä¸»æ‰§è¡Œå‡½æ•°
if __name__ == "__main__":
    print("ğŸš€ è§‚æµ‹-WRFæ•°æ®åŒ¹é…ç³»ç»Ÿå¯åŠ¨ (ä¿®æ­£ç‰ˆ)")
    print("=" * 60)
    
    # æ–¹æ¡ˆ1: ä»…æµ‹è¯•æ˜Œé©¬ç«™ç‚¹ï¼ˆæ¨èå¼€å§‹ï¼‰
    # matcher, stats = quick_test_changma()
    
    # æ–¹æ¡ˆ2: æµ‹è¯•æ‰€æœ‰ç«™ç‚¹
    matcher, all_stats = quick_test_all()
    
    if matcher:
        print("\nğŸ“ˆ åŒ¹é…æ•°æ®å¯é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¿é—®:")
        print("   matcher.matched_datasets['changma']  # æ˜Œé©¬ç«™åŒ¹é…æ•°æ®")
        print("   matcher.matched_datasets['kuangqu']  # çŸ¿åŒºç«™åŒ¹é…æ•°æ®") 
        print("   matcher.matched_datasets['sanlijijingzi']  # ä¸‰åé‡Œäº•å­ç«™åŒ¹é…æ•°æ®")
        
        print("\nğŸ“‚ è¾“å‡ºæ–‡ä»¶ä½ç½®:")
        print("   01_Data/processed/matched_data/     # åŒ¹é…æ•°æ®CSVæ–‡ä»¶")
        print("   03_Results/validation_plots/        # éªŒè¯å›¾è¡¨")
        print("   03_Results/obs_wrf_comparison_summary.txt # æ€»ä½“æŠ¥å‘Š")
        
        print("\nğŸ”§ ä¿®æ­£å†…å®¹:")
        print("   âœ… æ¸©åº¦å•ä½: K â†’ Â°C è½¬æ¢å’Œå¤–æ¨")
        print("   âœ… å¯†åº¦è®¡ç®—: ä»æ¸©åº¦æ°”å‹é‡æ–°è®¡ç®—") 
        print("   âœ… é£å‘è®¡ç®—: ä»u/våˆ†é‡è®¡ç®—")
        print("   âœ… æ•°æ®æè¿°: åŒ…å«å•ä½å’Œå¤„ç†è¯´æ˜")