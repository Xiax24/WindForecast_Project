"""
10m Wind Speed Correction using LightGBM + SHAP
ä½¿ç”¨LightGBMå’ŒSHAPè¿›è¡Œ10mé£é€Ÿè®¢æ­£
å¢å¼ºç‰ˆæœ¬ï¼šæ·»åŠ ec_gfs_diffå˜é‡ + è¾“å‡ºå®Œæ•´é¢„æµ‹æ•°æ®ç”¨äºä¸‹ä¸€æ­¥EOFåˆ†æ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from scipy.stats import pearsonr
import lightgbm as lgb
import shap
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ç»˜å›¾å‚æ•°
plt.rcParams['figure.dpi'] = 100
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 10

def load_and_prepare_data(file_path):
    """Load and prepare data for modeling"""
    print("ğŸ”„ Loading and preparing data...")
    
    # Load data
    df = pd.read_csv(file_path)
    df['datetime'] = pd.to_datetime(df['datetime'])
    
    print(f"ğŸ“Š Data loaded: {len(df)} records")
    print(f"ğŸ“… Time range: {df['datetime'].min()} to {df['datetime'].max()}")
    
    # Focus on 10m wind speed + å¤šé«˜åº¦è§‚æµ‹æ•°æ®
    target_col = 'obs_wind_speed_10m'
    feature_cols = ['ec_wind_speed_10m', 'gfs_wind_speed_10m']
    
    # æ£€æŸ¥å¤šé«˜åº¦è§‚æµ‹æ•°æ®ï¼ˆç”¨äºä¸‹ä¸€æ­¥EOFåˆ†æï¼‰
    profile_cols = ['obs_wind_speed_10m', 'obs_wind_speed_30m', 
                   'obs_wind_speed_50m', 'obs_wind_speed_70m']
    
    # Check for required columns
    required_cols = [target_col] + feature_cols
    missing_cols = [col for col in required_cols if col not in df.columns]
    
    if missing_cols:
        print(f"âŒ Missing columns: {missing_cols}")
        return None
    
    # æ£€æŸ¥é£å»“çº¿æ•°æ®å®Œæ•´æ€§
    profile_available = all(col in df.columns for col in profile_cols)
    print(f"ğŸ” Wind profile data availability: {profile_available}")
    if profile_available:
        print(f"   Available heights: {profile_cols}")
    else:
        missing_profile = [col for col in profile_cols if col not in df.columns]
        print(f"   Missing profile data: {missing_profile}")
    
    # Clean data (ä¿ç•™æ‰€æœ‰åˆ—ç”¨äºåç»­åˆ†æ)
    all_cols = ['datetime'] + required_cols
    if profile_available:
        all_cols.extend([col for col in profile_cols if col not in all_cols])
    
    df_clean = df[all_cols].dropna(subset=required_cols)
    print(f"âœ… Clean data: {len(df_clean)} records ({len(df_clean)/len(df)*100:.1f}%)")
    
    # Basic statistics
    print(f"\nğŸ“ˆ Basic Statistics:")
    print(f"Observed 10m: mean={df_clean[target_col].mean():.2f}, std={df_clean[target_col].std():.2f}")
    print(f"EC 10m: mean={df_clean['ec_wind_speed_10m'].mean():.2f}, std={df_clean['ec_wind_speed_10m'].std():.2f}")
    print(f"GFS 10m: mean={df_clean['gfs_wind_speed_10m'].mean():.2f}, std={df_clean['gfs_wind_speed_10m'].std():.2f}")
    
    if profile_available:
        print(f"\nğŸŒªï¸ Wind Profile Statistics:")
        for col in profile_cols:
            if col in df_clean.columns:
                print(f"{col}: mean={df_clean[col].mean():.2f}, std={df_clean[col].std():.2f}")
    
    return df_clean

def create_features(df):
    """Create enhanced core features for the model including ec_gfs_diff"""
    print("ğŸ”§ Creating enhanced core features...")
    
    df_features = df.copy()
    
    # Time-based features (only the ones we need)
    df_features['hour'] = df_features['datetime'].dt.hour
    df_features['day_of_year'] = df_features['datetime'].dt.dayofyear
    
    # Cyclical encoding for time features (only the ones we need)
    df_features['hour_sin'] = np.sin(2 * np.pi * df_features['hour'] / 24)
    df_features['day_sin'] = np.sin(2 * np.pi * df_features['day_of_year'] / 365)
    
    # Model combination features
    df_features['ec_gfs_mean'] = (df_features['ec_wind_speed_10m'] + df_features['gfs_wind_speed_10m']) / 2
    df_features['ec_gfs_diff'] = abs(df_features['ec_wind_speed_10m'] - df_features['gfs_wind_speed_10m'])  # æ–°å¢å˜é‡
    
    print(f"âœ… Enhanced core features created: {df_features.shape[1]-2} features, {len(df_features)} samples")
    
    # Feature list (ç°åœ¨æœ‰6ä¸ªç‰¹å¾)
    feature_names = [
        'ec_gfs_mean',          # ECå’ŒGFSçš„å¹³å‡å€¼ (æœ€é‡è¦)
        'ec_gfs_diff',          # ECå’ŒGFSçš„å·®å€¼ (æ–°å¢ï¼šæ¨¡å¼åˆ†æ­§åº¦)
        'hour_sin',             # å°æ—¶çš„æ­£å¼¦ç¼–ç  (æ—¥å˜åŒ–)
        'day_sin',              # æ—¥æœŸçš„æ­£å¼¦ç¼–ç  (å­£èŠ‚å˜åŒ–)
        'ec_wind_speed_10m',    # ECåŸå§‹é¢„æŠ¥
        'gfs_wind_speed_10m'    # GFSåŸå§‹é¢„æŠ¥
    ]
    
    print(f"ğŸ“‹ Selected features: {feature_names}")
    
    # åˆ†ææ–°å¢å˜é‡çš„ç»Ÿè®¡ç‰¹æ€§
    print(f"\nğŸ“Š æ–°å¢å˜é‡ ec_gfs_diff ç»Ÿè®¡:")
    print(f"  å¹³å‡å€¼: {df_features['ec_gfs_diff'].mean():.3f} m/s")
    print(f"  æ ‡å‡†å·®: {df_features['ec_gfs_diff'].std():.3f} m/s")
    print(f"  æœ€å°å€¼: {df_features['ec_gfs_diff'].min():.3f} m/s")
    print(f"  æœ€å¤§å€¼: {df_features['ec_gfs_diff'].max():.3f} m/s")
    print(f"  ä¸­ä½æ•°: {df_features['ec_gfs_diff'].median():.3f} m/s")
    
    # åˆ†ææ¨¡å¼åˆ†æ­§åº¦çš„åˆ†å¸ƒ
    print(f"\nğŸ” æ¨¡å¼åˆ†æ­§åº¦åˆ†æ:")
    low_diff = (df_features['ec_gfs_diff'] < 0.5).sum()
    med_diff = ((df_features['ec_gfs_diff'] >= 0.5) & (df_features['ec_gfs_diff'] < 2.0)).sum()
    high_diff = (df_features['ec_gfs_diff'] >= 2.0).sum()
    
    total = len(df_features)
    print(f"  ä½åˆ†æ­§ (<0.5 m/s): {low_diff} ({low_diff/total*100:.1f}%)")
    print(f"  ä¸­åˆ†æ­§ (0.5-2.0 m/s): {med_diff} ({med_diff/total*100:.1f}%)")
    print(f"  é«˜åˆ†æ­§ (>2.0 m/s): {high_diff} ({high_diff/total*100:.1f}%)")
    
    return df_features, feature_names

def split_data(df, feature_names, target_col='obs_wind_speed_10m', test_size=0.2):
    """Split data into train and test sets with time series consideration"""
    print(f"âœ‚ï¸ Splitting data (test_size={test_size})...")
    
    # Sort by datetime to maintain temporal order
    df_sorted = df.sort_values('datetime').reset_index(drop=True)
    
    # Time-based split (more realistic for time series)
    split_index = int(len(df_sorted) * (1 - test_size))
    
    train_df = df_sorted[:split_index]
    test_df = df_sorted[split_index:]
    
    # Prepare features and target
    X_train = train_df[feature_names]
    y_train = train_df[target_col]
    X_test = test_df[feature_names]
    y_test = test_df[target_col]
    
    print(f"ğŸ“Š Train set: {len(X_train)} samples ({train_df['datetime'].min()} to {train_df['datetime'].max()})")
    print(f"ğŸ“Š Test set: {len(X_test)} samples ({test_df['datetime'].min()} to {test_df['datetime'].max()})")
    
    # åˆ†æè®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­ec_gfs_diffçš„åˆ†å¸ƒ
    print(f"\nğŸ“ˆ å„æ•°æ®é›†ä¸­ ec_gfs_diff åˆ†å¸ƒ:")
    print(f"è®­ç»ƒé›†: å‡å€¼={X_train['ec_gfs_diff'].mean():.3f}, æ ‡å‡†å·®={X_train['ec_gfs_diff'].std():.3f}")
    print(f"æµ‹è¯•é›†: å‡å€¼={X_test['ec_gfs_diff'].mean():.3f}, æ ‡å‡†å·®={X_test['ec_gfs_diff'].std():.3f}")
    
    return X_train, X_test, y_train, y_test, train_df, test_df, df_sorted, split_index

def train_lightgbm_model(X_train, y_train, X_test, y_test):
    """Train LightGBM model with hyperparameter tuning"""
    print("ğŸš€ Training LightGBM model...")
    
    # LightGBM parameters
    params = {
        'objective': 'regression',
        'metric': 'rmse',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.9,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'verbose': -1,
        'random_state': 42
    }
    
    # Create datasets
    train_data = lgb.Dataset(X_train, label=y_train)
    valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)
    
    # Train model
    model = lgb.train(
        params,
        train_data,
        valid_sets=[train_data, valid_data],
        valid_names=['train', 'valid'],
        num_boost_round=1000,
        callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(0)]
    )
    
    print(f"âœ… Model trained with {model.num_trees()} trees")
    
    return model

def predict_full_dataset(model, df_sorted, feature_names, split_index, target_col='obs_wind_speed_10m'):
    """å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œé¢„æµ‹å¹¶è¾“å‡ºå®Œæ•´ç»“æœ"""
    print("ğŸ”® Predicting on full dataset for next step...")
    
    # å‡†å¤‡å…¨æ•°æ®é›†ç‰¹å¾
    X_all = df_sorted[feature_names]
    
    # é¢„æµ‹å…¨æ•°æ®é›†
    corrected_10m_all = model.predict(X_all, num_iteration=model.best_iteration)
    
    # åˆ›å»ºè¾“å‡ºæ•°æ®æ¡†
    df_output = df_sorted[['datetime']].copy()
    df_output['obs_wind_speed_10m'] = df_sorted[target_col]
    df_output['corrected_wind_speed_10m'] = corrected_10m_all
    df_output['ec_wind_speed_10m'] = df_sorted['ec_wind_speed_10m']
    df_output['gfs_wind_speed_10m'] = df_sorted['gfs_wind_speed_10m']
    df_output['ec_gfs_mean'] = df_sorted['ec_gfs_mean']
    df_output['ec_gfs_diff'] = df_sorted['ec_gfs_diff']
    
    # æ·»åŠ è®­ç»ƒ/æµ‹è¯•æ ‡è®°
    df_output['data_split'] = 'train'
    df_output.loc[split_index:, 'data_split'] = 'test'
    
    # å¦‚æœæœ‰é£å»“çº¿æ•°æ®ï¼Œä¹Ÿæ·»åŠ è¿›å»
    profile_cols = ['obs_wind_speed_30m', 'obs_wind_speed_50m', 'obs_wind_speed_70m']
    for col in profile_cols:
        if col in df_sorted.columns:
            df_output[col] = df_sorted[col]
    
    print(f"âœ… Full dataset prediction completed: {len(df_output)} records")
    print(f"ğŸ“Š Training period: {(df_output['data_split']=='train').sum()} records")
    print(f"ğŸ“Š Testing period: {(df_output['data_split']=='test').sum()} records")
    
    # è®¡ç®—è®­ç»ƒæœŸå’Œæµ‹è¯•æœŸçš„ç»Ÿè®¡ä¿¡æ¯
    train_mask = df_output['data_split'] == 'train'
    test_mask = df_output['data_split'] == 'test'
    
    print(f"\nğŸ“ˆ å…¨æ•°æ®é›†è®¢æ­£æ•ˆæœç»Ÿè®¡:")
    print(f"è®­ç»ƒæœŸ - è§‚æµ‹å‡å€¼: {df_output.loc[train_mask, 'obs_wind_speed_10m'].mean():.3f}, è®¢æ­£å‡å€¼: {df_output.loc[train_mask, 'corrected_wind_speed_10m'].mean():.3f}")
    print(f"æµ‹è¯•æœŸ - è§‚æµ‹å‡å€¼: {df_output.loc[test_mask, 'obs_wind_speed_10m'].mean():.3f}, è®¢æ­£å‡å€¼: {df_output.loc[test_mask, 'corrected_wind_speed_10m'].mean():.3f}")
    
    # æ£€æŸ¥é£å»“çº¿æ•°æ®å¯ç”¨æ€§ï¼ˆç”¨äºä¸‹ä¸€æ­¥EOFåˆ†æï¼‰
    available_profile_cols = [col for col in profile_cols if col in df_output.columns]
    if available_profile_cols:
        print(f"\nğŸŒªï¸ å¯ç”¨é£å»“çº¿æ•°æ®: {available_profile_cols}")
        print(f"   è®­ç»ƒæœŸå®Œæ•´é£å»“çº¿æ•°æ®: {df_output.loc[train_mask, available_profile_cols].dropna().shape[0]} æ¡")
        print(f"   å…¨æœŸå®Œæ•´é£å»“çº¿æ•°æ®: {df_output[['obs_wind_speed_10m'] + available_profile_cols].dropna().shape[0]} æ¡")
    else:
        print(f"âš ï¸  æ— å¯ç”¨é£å»“çº¿æ•°æ®ï¼Œä¸‹ä¸€æ­¥EOFåˆ†æå¯èƒ½å—é™")
    
    return df_output

def evaluate_model(model, X_train, y_train, X_test, y_test, feature_names):
    """Evaluate model performance and calculate metrics"""
    print("ğŸ“Š Evaluating model performance...")
    
    # Predictions
    y_train_pred = model.predict(X_train, num_iteration=model.best_iteration)
    y_test_pred = model.predict(X_test, num_iteration=model.best_iteration)
    
    # Calculate metrics
    def calculate_metrics(y_true, y_pred, set_name):
        corr, _ = pearsonr(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)
        bias = np.mean(y_pred - y_true)
        
        print(f"\n{set_name} Metrics:")
        print(f"  Correlation: {corr:.4f}")
        print(f"  RMSE: {rmse:.4f}")
        print(f"  MAE: {mae:.4f}")
        print(f"  RÂ²: {r2:.4f}")
        print(f"  Bias: {bias:.4f}")
        
        return {
            'correlation': corr,
            'rmse': rmse,
            'mae': mae,
            'r2': r2,
            'bias': bias
        }
    
    # Calculate metrics for both sets
    train_metrics = calculate_metrics(y_train, y_train_pred, "ğŸ”µ Training")
    test_metrics = calculate_metrics(y_test, y_test_pred, "ğŸ”´ Testing")
    
    return {
        'train_metrics': train_metrics,
        'test_metrics': test_metrics,
        'y_train_pred': y_train_pred,
        'y_test_pred': y_test_pred
    }

def save_full_dataset_output(df_output, output_dir):
    """ä¿å­˜å®Œæ•´æ•°æ®é›†è¾“å‡ºç”¨äºä¸‹ä¸€æ­¥åˆ†æ"""
    print("ğŸ’¾ Saving full dataset output for next step...")
    
    import os
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜å®Œæ•´çš„è®¢æ­£æ•°æ®
    full_output_path = f"{output_dir}/corrected_10m_wind_full_dataset.csv"
    df_output.to_csv(full_output_path, index=False)
    print(f"âœ… Full corrected dataset saved: {full_output_path}")
    
    # ä¿å­˜ä»…è®­ç»ƒæœŸæ•°æ®ï¼ˆç”¨äºEOFåˆ†è§£ï¼‰
    train_output = df_output[df_output['data_split'] == 'train'].copy()
    train_output_path = f"{output_dir}/corrected_10m_wind_training_period.csv"
    train_output.to_csv(train_output_path, index=False)
    print(f"âœ… Training period data saved: {train_output_path}")
    
    # ä¿å­˜æ•°æ®æè¿°æ–‡ä»¶
    description = f"""
10mé£é€Ÿè®¢æ­£å®Œæ•´æ•°æ®é›†è¯´æ˜
=========================

æ•°æ®æ–‡ä»¶:
1. corrected_10m_wind_full_dataset.csv - å®Œæ•´æ•°æ®é›†(100%)
2. corrected_10m_wind_training_period.csv - è®­ç»ƒæœŸæ•°æ®(80%)

ä¸»è¦åˆ—è¯´æ˜:
- datetime: æ—¶é—´
- obs_wind_speed_10m: è§‚æµ‹10mé£é€Ÿ
- corrected_wind_speed_10m: è®¢æ­£å10mé£é€Ÿï¼ˆç”¨äºä¸‹ä¸€æ­¥EOFåˆ†æï¼‰
- ec_wind_speed_10m: ECåŸå§‹é¢„æŠ¥
- gfs_wind_speed_10m: GFSåŸå§‹é¢„æŠ¥
- ec_gfs_mean: ECå’ŒGFSå¹³å‡å€¼
- ec_gfs_diff: ECå’ŒGFSå·®å€¼ï¼ˆæ¨¡å¼åˆ†æ­§åº¦ï¼‰
- data_split: train/test æ•°æ®åˆ’åˆ†æ ‡è®°
- obs_wind_speed_30m/50m/70m: å¤šé«˜åº¦è§‚æµ‹æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰

ä¸‹ä¸€æ­¥ä½¿ç”¨è¯´æ˜:
- ä½¿ç”¨ corrected_wind_speed_10m ä½œä¸ºEOF1é¢„æµ‹çš„è¾“å…¥ç‰¹å¾
- ä½¿ç”¨è®­ç»ƒæœŸçš„é£å»“çº¿æ•°æ®è¿›è¡ŒEOFåˆ†è§£
- è®­ç»ƒæœŸæ•°æ®: {len(train_output)} æ¡è®°å½•
- å®Œæ•´æ•°æ®é›†: {len(df_output)} æ¡è®°å½•
- æ—¶é—´èŒƒå›´: {df_output['datetime'].min()} åˆ° {df_output['datetime'].max()}

æ•°æ®è´¨é‡æ£€æŸ¥:
- 10mè®¢æ­£ç›¸å…³æ€§: åœ¨æµ‹è¯•é›†ä¸Šéœ€è¦éªŒè¯
- é£å»“çº¿å®Œæ•´æ€§: æ£€æŸ¥30m/50m/70mæ•°æ®å¯ç”¨æ€§
"""
    
    desc_path = f"{output_dir}/dataset_description.txt"
    with open(desc_path, 'w', encoding='utf-8') as f:
        f.write(description)
    print(f"âœ… Dataset description saved: {desc_path}")
    
    # æ•°æ®è´¨é‡æŠ¥å‘Š
    print(f"\nğŸ“‹ è¾“å‡ºæ•°æ®è´¨é‡æŠ¥å‘Š:")
    print(f"   æ€»è®°å½•æ•°: {len(df_output)}")
    print(f"   è®­ç»ƒæœŸè®°å½•: {len(train_output)}")
    print(f"   æµ‹è¯•æœŸè®°å½•: {len(df_output) - len(train_output)}")
    print(f"   æ—¶é—´è·¨åº¦: {df_output['datetime'].max() - df_output['datetime'].min()}")
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    missing_summary = df_output.isnull().sum()
    print(f"   ç¼ºå¤±å€¼æ£€æŸ¥:")
    for col, missing_count in missing_summary.items():
        if missing_count > 0:
            print(f"     {col}: {missing_count} ({missing_count/len(df_output)*100:.1f}%)")
        else:
            print(f"     {col}: å®Œæ•´")
    
    return full_output_path, train_output_path

def create_output_visualization(df_output, output_dir):
    """åˆ›å»ºè¾“å‡ºæ•°æ®çš„å¯è§†åŒ–"""
    print("ğŸ“Š Creating output data visualization...")
    
    # åˆ›å»ºå¯è§†åŒ–
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. æ—¶é—´åºåˆ—å¯¹æ¯”ï¼ˆé‡‡æ ·æ˜¾ç¤ºï¼‰
    ax1 = axes[0, 0]
    sample_size = min(2000, len(df_output))
    sample_indices = np.linspace(0, len(df_output)-1, sample_size, dtype=int)
    sample_data = df_output.iloc[sample_indices]
    
    ax1.plot(sample_data['datetime'], sample_data['obs_wind_speed_10m'], 
             'k-', linewidth=0.8, alpha=0.7, label='Observed 10m')
    ax1.plot(sample_data['datetime'], sample_data['corrected_wind_speed_10m'], 
             'r-', linewidth=0.8, alpha=0.7, label='Corrected 10m')
    ax1.plot(sample_data['datetime'], sample_data['ec_wind_speed_10m'], 
             'b-', linewidth=0.6, alpha=0.5, label='EC Original')
    
    ax1.set_xlabel('Time')
    ax1.set_ylabel('Wind Speed (m/s)')
    ax1.set_title('10m Wind Speed Correction Time Series')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
    
    # 2. æ•£ç‚¹å›¾å¯¹æ¯”
    ax2 = axes[0, 1]
    ax2.scatter(df_output['obs_wind_speed_10m'], df_output['corrected_wind_speed_10m'], 
                alpha=0.3, s=1, color='red', label='Corrected vs Observed')
    ax2.scatter(df_output['obs_wind_speed_10m'], df_output['ec_wind_speed_10m'], 
                alpha=0.2, s=1, color='blue', label='EC vs Observed')
    
    min_val, max_val = df_output['obs_wind_speed_10m'].min(), df_output['obs_wind_speed_10m'].max()
    ax2.plot([min_val, max_val], [min_val, max_val], 'k--', linewidth=2, label='Perfect')
    
    ax2.set_xlabel('Observed Wind Speed (m/s)')
    ax2.set_ylabel('Predicted Wind Speed (m/s)')
    ax2.set_title('Scatter Plot: Corrected vs Original')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. è¯¯å·®åˆ†å¸ƒ
    ax3 = axes[1, 0]
    corrected_error = df_output['corrected_wind_speed_10m'] - df_output['obs_wind_speed_10m']
    ec_error = df_output['ec_wind_speed_10m'] - df_output['obs_wind_speed_10m']
    
    ax3.hist(corrected_error, bins=50, alpha=0.6, color='red', label='Corrected Error', density=True)
    ax3.hist(ec_error, bins=50, alpha=0.6, color='blue', label='EC Error', density=True)
    ax3.axvline(0, color='black', linestyle='--', linewidth=2)
    
    ax3.set_xlabel('Prediction Error (m/s)')
    ax3.set_ylabel('Density')
    ax3.set_title('Error Distribution')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. EC-GFSåˆ†æ­§åº¦åˆ†æ
    ax4 = axes[1, 1]
    ax4.hist(df_output['ec_gfs_diff'], bins=50, alpha=0.7, color='green', edgecolor='black')
    ax4.axvline(df_output['ec_gfs_diff'].mean(), color='red', linestyle='--', linewidth=2,
                label=f"Mean: {df_output['ec_gfs_diff'].mean():.3f}")
    
    ax4.set_xlabel('EC-GFS Difference (m/s)')
    ax4.set_ylabel('Frequency')
    ax4.set_title('Model Disagreement Distribution')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    viz_path = f"{output_dir}/full_dataset_output_visualization.png"
    plt.savefig(viz_path, dpi=300, bbox_inches='tight')
    print(f"âœ… Output visualization saved: {viz_path}")
    plt.show()
    
    return fig

def comprehensive_comparison_analysis(y_test, y_test_pred, X_test, test_df, output_dir):
    """Comprehensive comparison analysis on the same test dataset"""
    print("\nğŸ“Š ========== COMPREHENSIVE COMPARISON ANALYSIS ==========")
    print("Comparing performance on the SAME test dataset:")
    
    # Get baseline predictions
    ec_baseline = X_test['ec_wind_speed_10m'].values
    gfs_baseline = X_test['gfs_wind_speed_10m'].values
    lgb_corrected = y_test_pred
    observed = y_test.values
    
    def calculate_comprehensive_metrics(y_true, y_pred, model_name):
        """Calculate all performance metrics"""
        corr, _ = pearsonr(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)
        bias = np.mean(y_pred - y_true)
        
        # Additional metrics
        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # Mean Absolute Percentage Error
        std_residuals = np.std(y_pred - y_true)
        
        return {
            'Model': model_name,
            'Correlation': corr,
            'RMSE': rmse,
            'MAE': mae,
            'RÂ²': r2,
            'Bias': bias,
            'MAPE(%)': mape,
            'Std_Residuals': std_residuals,
            'Sample_Size': len(y_true)
        }
    
    # Calculate metrics for all models
    ec_metrics = calculate_comprehensive_metrics(observed, ec_baseline, 'EC_Original')
    gfs_metrics = calculate_comprehensive_metrics(observed, gfs_baseline, 'GFS_Original')  
    lgb_metrics = calculate_comprehensive_metrics(observed, lgb_corrected, 'LightGBM_Enhanced')
    
    # Create comparison dataframe
    comparison_df = pd.DataFrame([ec_metrics, gfs_metrics, lgb_metrics])
    
    print("\nğŸ¯ PERFORMANCE COMPARISON ON SAME TEST DATASET:")
    print("=" * 100)
    print(comparison_df.round(4).to_string(index=False))
    
    # Calculate improvements
    print(f"\nğŸ“ˆ IMPROVEMENTS vs EC Original:")
    print("-" * 50)
    
    corr_improvement = (lgb_metrics['Correlation'] - ec_metrics['Correlation']) / ec_metrics['Correlation'] * 100
    rmse_improvement = (ec_metrics['RMSE'] - lgb_metrics['RMSE']) / ec_metrics['RMSE'] * 100
    mae_improvement = (ec_metrics['MAE'] - lgb_metrics['MAE']) / ec_metrics['MAE'] * 100
    r2_improvement = (lgb_metrics['RÂ²'] - ec_metrics['RÂ²']) / abs(ec_metrics['RÂ²']) * 100
    
    print(f"âœ… Correlation:     {lgb_metrics['Correlation']:.4f} vs {ec_metrics['Correlation']:.4f} = +{corr_improvement:+.1f}%")
    print(f"âœ… RMSE:           {lgb_metrics['RMSE']:.4f} vs {ec_metrics['RMSE']:.4f} = {rmse_improvement:+.1f}%")
    print(f"âœ… MAE:            {lgb_metrics['MAE']:.4f} vs {ec_metrics['MAE']:.4f} = {mae_improvement:+.1f}%")
    print(f"âœ… RÂ²:             {lgb_metrics['RÂ²']:.4f} vs {ec_metrics['RÂ²']:.4f} = +{r2_improvement:+.1f}%")
    
    return comparison_df, {
        'ec_improvement': {
            'correlation': corr_improvement,
            'rmse': rmse_improvement,
            'mae': mae_improvement,
            'r2': r2_improvement
        }
    }

def create_shap_analysis(model, X_train, X_test, feature_names, output_dir):
    """Create SHAP analysis for model interpretability"""
    print("ğŸ” Creating SHAP analysis...")
    
    # Create SHAP explainer
    explainer = shap.TreeExplainer(model)
    
    # Calculate SHAP values for test set (sample for speed)
    sample_size = min(1000, len(X_test))
    X_sample = X_test.sample(n=sample_size, random_state=42)
    shap_values = explainer.shap_values(X_sample)
    
    # Feature importance plot
    plt.figure(figsize=(10, 8))
    shap.summary_plot(shap_values, X_sample, feature_names=feature_names, show=False)
    plt.title('SHAP Feature Importance Summary (Enhanced Model)', fontsize=14, fontweight='bold')
    plt.tight_layout()
    
    shap_summary_path = f"{output_dir}/shap_summary_plot.png"
    plt.savefig(shap_summary_path, dpi=300, bbox_inches='tight')
    print(f"âœ… SHAP summary plot saved: {shap_summary_path}")
    plt.show()
    
    # Feature importance bar plot
    plt.figure(figsize=(10, 6))
    shap.summary_plot(shap_values, X_sample, feature_names=feature_names, plot_type="bar", show=False)
    plt.title('SHAP Feature Importance (Mean |SHAP value|)', fontsize=14, fontweight='bold')
    plt.tight_layout()
    
    shap_bar_path = f"{output_dir}/shap_importance_bar.png"
    plt.savefig(shap_bar_path, dpi=300, bbox_inches='tight')
    print(f"âœ… SHAP bar plot saved: {shap_bar_path}")
    plt.show()
    
    # Calculate feature importance
    feature_importance = np.abs(shap_values).mean(0)
    importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': feature_importance
    }).sort_values('importance', ascending=False)
    
    print("\nğŸ† Enhanced Model - Top Feature Importance:")
    print(importance_df.round(4))
    
    # åˆ†æec_gfs_diffçš„é‡è¦æ€§æ’å
    ec_gfs_diff_rank = importance_df[importance_df['feature'] == 'ec_gfs_diff'].index[0] + 1
    print(f"\nğŸ“Š ec_gfs_diff é‡è¦æ€§æ’å: ç¬¬ {ec_gfs_diff_rank} ä½ (å…± {len(feature_names)} ä¸ªç‰¹å¾)")
    
    return importance_df, shap_values

def save_results(model, evaluation_results, comparison_df, importance_df, output_dir):
    """Save all results to files"""
    print("ğŸ’¾ Saving results...")
    
    import os
    os.makedirs(output_dir, exist_ok=True)
    
    # Save model
    model_path = f"{output_dir}/enhanced_lightgbm_model.txt"
    model.save_model(model_path)
    print(f"âœ… Enhanced model saved: {model_path}")
    
    # Save metrics
    metrics_data = {
        'train_metrics': evaluation_results['train_metrics'],
        'test_metrics': evaluation_results['test_metrics']
    }
    
    metrics_df = pd.DataFrame(metrics_data).T
    metrics_path = f"{output_dir}/enhanced_model_metrics.csv"
    metrics_df.to_csv(metrics_path)
    print(f"âœ… Enhanced metrics saved: {metrics_path}")
    
    # Save comparison
    comparison_path = f"{output_dir}/enhanced_model_comparison.csv"
    comparison_df.to_csv(comparison_path, index=False)
    print(f"âœ… Enhanced comparison saved: {comparison_path}")
    
    # Save feature importance
    importance_path = f"{output_dir}/enhanced_feature_importance.csv"
    importance_df.to_csv(importance_path, index=False)
    print(f"âœ… Enhanced feature importance saved: {importance_path}")

def main():
    """Main execution function"""
    # Paths
    data_path = '/Users/xiaxin/work/WindForecast_Project/01_Data/processed/imputed_data/changma_clean.csv'
    output_dir = '/Users/xiaxin/work/WindForecast_Project/03_Results/å»ºæ¨¡/10mé£é€Ÿå»ºæ¨¡/LightGBM_å¢å¼ºç‰ˆ/'
    
    try:
        print("ğŸš€ Starting Enhanced 10m Wind Speed Correction with LightGBM...")
        print("âœ¨ æ–°å¢ç‰¹å¾: ec_gfs_diff (ECå’ŒGFSçš„åˆ†æ­§åº¦)")
        print("ğŸ¯ ç›®æ ‡: è¾“å‡ºå®Œæ•´é¢„æµ‹æ•°æ®ç”¨äºä¸‹ä¸€æ­¥EOFåˆ†æ")
        
        # 0. Create output directory first
        import os
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“ Output directory created: {output_dir}")
        
        # 1. Load and prepare data
        df = load_and_prepare_data(data_path)
        if df is None:
            return
        
        # 2. Create enhanced features (including ec_gfs_diff)
        df_features, feature_names = create_features(df)
        
        # 3. Split data (è¿”å›å®Œæ•´æ’åºæ•°æ®å’Œåˆ†å‰²ç´¢å¼•)
        X_train, X_test, y_train, y_test, train_df, test_df, df_sorted, split_index = split_data(df_features, feature_names)
        
        # 4. Train model
        model = train_lightgbm_model(X_train, y_train, X_test, y_test)
        
        # 5. Evaluate model
        evaluation_results = evaluate_model(model, X_train, y_train, X_test, y_test, feature_names)
        
        # 6. ğŸ”¥ NEW: é¢„æµ‹å®Œæ•´æ•°æ®é›†å¹¶è¾“å‡ºï¼ˆå…³é”®æ­¥éª¤ï¼ï¼‰
        df_output = predict_full_dataset(model, df_features, feature_names, split_index)
        
        # 7. ğŸ”¥ NEW: ä¿å­˜å®Œæ•´æ•°æ®é›†è¾“å‡ºç”¨äºä¸‹ä¸€æ­¥EOFåˆ†æ
        full_output_path, train_output_path = save_full_dataset_output(df_output, output_dir)
        
        # 8. ğŸ”¥ NEW: åˆ›å»ºè¾“å‡ºæ•°æ®å¯è§†åŒ–
        output_fig = create_output_visualization(df_output, output_dir)
        
        # 9. COMPREHENSIVE COMPARISON ANALYSIS
        comparison_df, improvements = comprehensive_comparison_analysis(
            y_test, evaluation_results['y_test_pred'], X_test, test_df, output_dir)
        
        # 10. SHAP analysis
        importance_df, shap_values = create_shap_analysis(model, X_train, X_test, feature_names, output_dir)
        
        # 11. Save results
        save_results(model, evaluation_results, comparison_df, importance_df, output_dir)
        
        # 12. FINAL SUMMARY WITH NEXT STEP GUIDANCE
        print("\n" + "="*80)
        print("ğŸ‰ ENHANCED 10m WIND SPEED CORRECTION COMPLETED SUCCESSFULLY!")
        print("ğŸ¯ æ•°æ®å·²å‡†å¤‡å¥½ç”¨äºä¸‹ä¸€æ­¥EOFåˆ†æ")
        print("="*80)
        
        # Extract key metrics for final summary
        lgb_corr = comparison_df.loc[comparison_df['Model'] == 'LightGBM_Enhanced', 'Correlation'].iloc[0]
        ec_corr = comparison_df.loc[comparison_df['Model'] == 'EC_Original', 'Correlation'].iloc[0]
        lgb_rmse = comparison_df.loc[comparison_df['Model'] == 'LightGBM_Enhanced', 'RMSE'].iloc[0]
        ec_rmse = comparison_df.loc[comparison_df['Model'] == 'EC_Original', 'RMSE'].iloc[0]
        
        print(f"ğŸ“Š STEP 1 å®Œæˆæƒ…å†µ - 10mé£é€Ÿè®¢æ­£:")
        print(f"   â€¢ æ¨¡å‹è®­ç»ƒ: âœ… LightGBM + ec_gfs_diffç‰¹å¾")
        print(f"   â€¢ æµ‹è¯•é›†æ€§èƒ½: ç›¸å…³æ€§ {lgb_corr:.4f} (æå‡ {improvements['ec_improvement']['correlation']:.1f}%)")
        print(f"   â€¢ å…¨æ•°æ®é›†é¢„æµ‹: âœ… {len(df_output)} æ¡è®°å½•")
        print(f"   â€¢ æ•°æ®è¾“å‡º: âœ… å·²ä¿å­˜ç”¨äºEOFåˆ†æ")
        
        print(f"\nğŸ“ ä¸‹ä¸€æ­¥EOFåˆ†ææ‰€éœ€æ–‡ä»¶:")
        print(f"   ğŸ¯ ä¸»è¦è¾“å…¥æ–‡ä»¶: {full_output_path}")
        print(f"   ğŸ“‹ è®­ç»ƒæœŸæ•°æ®: {train_output_path}")
        print(f"   ğŸ“Š æ ¸å¿ƒåˆ—: corrected_wind_speed_10m (è®¢æ­£åçš„10mé£é€Ÿ)")
        
        # æ£€æŸ¥é£å»“çº¿æ•°æ®
        profile_cols = ['obs_wind_speed_30m', 'obs_wind_speed_50m', 'obs_wind_speed_70m']
        available_profile = [col for col in profile_cols if col in df_output.columns]
        
        if available_profile:
            print(f"\nğŸŒªï¸ é£å»“çº¿æ•°æ®æ£€æŸ¥:")
            print(f"   âœ… å¯ç”¨é«˜åº¦: {available_profile}")
            
            # æ£€æŸ¥è®­ç»ƒæœŸå®Œæ•´æ•°æ®
            train_data = df_output[df_output['data_split'] == 'train']
            complete_profile = train_data[['obs_wind_speed_10m'] + available_profile].dropna()
            print(f"   ğŸ“Š è®­ç»ƒæœŸå®Œæ•´é£å»“çº¿: {len(complete_profile)} æ¡ ({len(complete_profile)/len(train_data)*100:.1f}%)")
            
            if len(complete_profile) > 100:
                print(f"   ğŸ¯ æ•°æ®å……è¶³ï¼Œå¯ä»¥è¿›è¡ŒEOFåˆ†è§£")
            else:
                print(f"   âš ï¸  æ•°æ®ä¸è¶³ï¼ŒEOFåˆ†æå¯èƒ½å—é™")
        else:
            print(f"   âŒ æ— é£å»“çº¿æ•°æ®ï¼Œæ— æ³•è¿›è¡ŒEOFåˆ†æ")
        
        print(f"\nğŸ’¡ STEP 2 - EOFåˆ†æå»ºè®®:")
        print(f"   1. ä½¿ç”¨è®­ç»ƒæœŸæ•°æ® ({train_output_path}) è¿›è¡ŒEOFåˆ†è§£")
        print(f"   2. æå–é£å»“çº¿ä¸»æ¨¡æ€ (EOF1) ä½œä¸ºç›®æ ‡å˜é‡")
        print(f"   3. ç”¨ corrected_wind_speed_10m é¢„æµ‹ EOF1 æ—¶é—´ç³»æ•°")
        print(f"   4. é‡æ„70mé£é€Ÿç”¨äºåŠŸç‡é¢„æµ‹")
        
        success_indicator = "ğŸŸ¢ READY FOR STEP 2" if available_profile and len(complete_profile) > 100 else "ğŸŸ¡ LIMITED DATA" if available_profile else "ğŸ”´ MISSING PROFILE DATA"
        print(f"\nğŸ¯ STEP 2 å‡†å¤‡çŠ¶æ€: {success_indicator}")
        
        return model, evaluation_results, comparison_df, importance_df, df_output, full_output_path
        
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return None, None, None, None, None, None

if __name__ == "__main__":
    model, evaluation_results, comparison_df, importance_df, df_output, full_output_path = main()