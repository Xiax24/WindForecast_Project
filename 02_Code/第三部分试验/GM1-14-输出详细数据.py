#!/usr/bin/env python3
"""
ç®€åŒ–å‘½åç‰ˆå¢žå¼ºè¯•éªŒç³»ç»Ÿ
ä½¿ç”¨ç®€æ´çš„è¯•éªŒåç§°ï¼šX-M2-10m, X-M3-10m, G-M4-Dualç­‰
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.metrics import mean_squared_error
import os
import json
import warnings
warnings.filterwarnings('ignore')

RANDOM_STATE = 42

def create_train_test_split_if_needed(data_path, indices_path, test_ratio=0.2):
    """å¦‚æžœåˆ’åˆ†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºå®ƒ"""
    
    if os.path.exists(indices_path):
        print(f"  ðŸ“‹ ä½¿ç”¨å·²å­˜åœ¨çš„åˆ’åˆ†æ–‡ä»¶: {indices_path}")
        return
    
    print(f"  ðŸ“‹ åˆ›å»ºè®­ç»ƒæµ‹è¯•é›†åˆ’åˆ†æ–‡ä»¶...")
    
    # åŠ è½½æ•°æ®
    data = pd.read_csv(data_path)
    data['datetime'] = pd.to_datetime(data['datetime'])
    
    # åŸºç¡€æ¸…ç†
    data = data.dropna(subset=['power'])
    data = data[data['power'] >= 0]
    data = data.sort_values('datetime').reset_index(drop=True)
    
    # æŒ‰æ—¶é—´é¡ºåºåˆ’åˆ†
    total_samples = len(data)
    test_size = int(total_samples * test_ratio)
    train_size = total_samples - test_size
    
    # è®­ç»ƒé›†ï¼šå‰80%ï¼Œæµ‹è¯•é›†ï¼šåŽ20%
    train_indices = list(range(train_size))
    test_indices = list(range(train_size, total_samples))
    
    # ä¿å­˜åˆ’åˆ†
    split_data = {
        'train_indices': train_indices,
        'test_indices': test_indices,
        'total_samples': total_samples,
        'train_size': len(train_indices),
        'test_size': len(test_indices),
        'test_ratio': test_ratio,
        'split_method': 'time_based'
    }
    
    # åˆ›å»ºç›®å½•
    os.makedirs(os.path.dirname(indices_path), exist_ok=True)
    
    # ä¿å­˜
    with open(indices_path, 'w') as f:
        json.dump(split_data, f, indent=2)
    
    print(f"  âœ… åˆ’åˆ†æ–‡ä»¶åˆ›å»ºå®Œæˆ: {len(train_indices)} è®­ç»ƒ, {len(test_indices)} æµ‹è¯•")

class WindCorrectionModel:
    """é£Žé€Ÿæ ¡æ­£æ¨¡åž‹"""
    
    def __init__(self, target_height='10m', source='gfs'):
        self.target_height = target_height
        self.source = source
        self.model = None
        self.feature_names = None
        
    def prepare_correction_features(self, data):
        """å‡†å¤‡é£Žé€Ÿæ ¡æ­£çš„ç‰¹å¾"""
        
        features = pd.DataFrame()
        
        # ä¸»è¦é¢„æŠ¥é£Žé€Ÿ
        main_wind_col = f'{self.source}_wind_speed_{self.target_height}'
        features['forecast_wind'] = data[main_wind_col]
        features['forecast_wind_2'] = data[main_wind_col] ** 2
        
        # å…¶ä»–é«˜åº¦çš„é£Žé€Ÿ
        other_height = '70m' if self.target_height == '10m' else '10m'
        other_wind_col = f'{self.source}_wind_speed_{other_height}'
        if other_wind_col in data.columns:
            features['other_height_wind'] = data[other_wind_col]
            features['wind_shear'] = np.log(data[other_wind_col] / (data[main_wind_col] + 0.1))
        
        # æ¸©åº¦ç‰¹å¾
        if f'{self.source}_temperature_10m' in data.columns:
            features['temperature'] = data[f'{self.source}_temperature_10m']
        
        # æ—¶é—´ç‰¹å¾
        features['hour'] = data['datetime'].dt.hour
        features['month'] = data['datetime'].dt.month
        features['is_daytime'] = ((data['datetime'].dt.hour >= 6) & 
                                 (data['datetime'].dt.hour < 18)).astype(int)
        
        # æ»žåŽç‰¹å¾
        features['wind_lag_1h'] = data[main_wind_col].shift(1)
        features['wind_lag_24h'] = data[main_wind_col].shift(24)
        
        # æ»šåŠ¨ç»Ÿè®¡
        features['wind_24h_mean'] = data[main_wind_col].rolling(window=24, min_periods=1).mean()
        
        # å¡«å……NaN
        features = features.fillna(method='bfill').fillna(method='ffill')
        
        self.feature_names = features.columns.tolist()
        return features
    
    def train(self, data, train_indices):
        """è®­ç»ƒé£Žé€Ÿæ ¡æ­£æ¨¡åž‹"""
        
        features = self.prepare_correction_features(data)
        target_col = f'obs_wind_speed_{self.target_height}'
        target = data[target_col].values
        
        # åˆ’åˆ†è®­ç»ƒéªŒè¯é›†
        val_size = int(len(train_indices) * 0.2)
        train_only_indices = train_indices[:-val_size]
        val_indices = train_indices[-val_size:]
        
        X_train = features.iloc[train_only_indices]
        y_train = target[train_only_indices]
        X_val = features.iloc[val_indices]
        y_val = target[val_indices]
        
        # è®­ç»ƒLightGBM
        params = {
            'objective': 'regression',
            'metric': 'rmse',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.1,
            'feature_fraction': 0.9,
            'verbose': -1,
            'random_state': RANDOM_STATE
        }
        
        train_data = lgb.Dataset(X_train, label=y_train)
        valid_data = lgb.Dataset(X_val, label=y_val, reference=train_data)
        
        self.model = lgb.train(
            params,
            train_data,
            valid_sets=[valid_data],
            num_boost_round=100,
            callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(0)]
        )
        
        # è¯„ä¼°æ ¡æ­£æ•ˆæžœ
        y_pred = self.model.predict(features.iloc[train_indices], num_iteration=self.model.best_iteration)
        y_true = target[train_indices]
        
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        corr = np.corrcoef(y_true, y_pred)[0, 1]
        
        return {'rmse': rmse, 'correlation': corr}
    
    def predict(self, data):
        """é¢„æµ‹æ ¡æ­£åŽçš„é£Žé€Ÿ"""
        features = self.prepare_correction_features(data)
        return self.model.predict(features, num_iteration=self.model.best_iteration)

class PowerPredictionModel:
    """åŠŸçŽ‡é¢„æµ‹æ¨¡åž‹"""
    
    def __init__(self):
        self.model = None
        self.feature_names = None
    
    def prepare_power_features(self, wind_data, original_data):
        """å‡†å¤‡åŠŸçŽ‡é¢„æµ‹ç‰¹å¾"""
        
        features = pd.DataFrame()
        
        # é£Žé€Ÿç‰¹å¾
        if isinstance(wind_data, dict):
            # å¤šé£Žé€Ÿæƒ…å†µ
            for key, wind_values in wind_data.items():
                features[f'wind_{key}'] = wind_values
                features[f'wind_{key}_2'] = wind_values ** 2
                features[f'wind_{key}_3'] = wind_values ** 3
        else:
            # å•é£Žé€Ÿæƒ…å†µ
            features['wind'] = wind_data
            features['wind_2'] = wind_data ** 2
            features['wind_3'] = wind_data ** 3
        
        # æ—¶é—´ç‰¹å¾
        features['hour'] = original_data['datetime'].dt.hour
        features['month'] = original_data['datetime'].dt.month
        features['is_daytime'] = ((original_data['datetime'].dt.hour >= 6) & 
                                 (original_data['datetime'].dt.hour < 18)).astype(int)
        
        # æ»žåŽç‰¹å¾
        main_wind = list(wind_data.values())[0] if isinstance(wind_data, dict) else wind_data
        features['wind_lag_1h'] = pd.Series(main_wind).shift(1)
        features['wind_lag_24h'] = pd.Series(main_wind).shift(24)
        
        # å¡«å……NaN
        features = features.fillna(method='bfill').fillna(method='ffill')
        
        self.feature_names = features.columns.tolist()
        return features
    
    def train(self, wind_data, original_data, train_indices, test_indices):
        """è®­ç»ƒåŠŸçŽ‡é¢„æµ‹æ¨¡åž‹"""
        
        features = self.prepare_power_features(wind_data, original_data)
        target = original_data['power'].values
        
        X_train = features.iloc[train_indices]
        y_train = target[train_indices]

        # Use X_train for validation if test_indices are not available for proper validation set
        # For simplicity and consistency with current code, keep X_test for validation here
        # X_test below is specifically for final evaluation, not validation during training for this LGBM setup
        
        X_val_for_lgbm = features.iloc[test_indices] # LGBM uses this for early stopping
        y_val_for_lgbm = target[test_indices] # LGBM uses this for early stopping

        self.model = None # Reset model for each training call

        # Train LightGBM
        params = {
            'objective': 'regression',
            'metric': 'rmse',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.1,
            'feature_fraction': 0.9,
            'verbose': -1,
            'random_state': RANDOM_STATE
        }
        
        train_data = lgb.Dataset(X_train, label=y_train)
        valid_data = lgb.Dataset(X_val_for_lgbm, label=y_val_for_lgbm, reference=train_data) # Use test set as validation
        
        self.model = lgb.train(
            params,
            train_data,
            valid_sets=[valid_data],
            num_boost_round=100,
            callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(0)]
        )
        
        # Evaluate on the actual test set
        X_test = features.iloc[test_indices] # This is the X_test used for final prediction
        y_test = target[test_indices] # This is the y_test used for final prediction

        y_pred = self.model.predict(X_test, num_iteration=self.model.best_iteration)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        corr = np.corrcoef(y_test, y_pred)[0, 1]
        
        return {
            'rmse': rmse,
            'correlation': corr,
            'predictions': y_pred,
            'actual': y_test,
            'features_test': X_test # Return the X_test DataFrame for detailed logging
        }

class AverageWindCorrectionModel:
    """å¹³å‡é£Žé€Ÿæ ¡æ­£æ¨¡åž‹ï¼ˆç”¨äºŽX-M3ç³»åˆ—ï¼‰"""
    
    def __init__(self, target_height='10m', source_name='average'):
        self.target_height = target_height
        self.source_name = source_name
        self.model = None
        self.feature_names = None
        
    def prepare_correction_features(self, data, avg_wind_col):
        """å‡†å¤‡å¹³å‡é£Žé€Ÿæ ¡æ­£çš„ç‰¹å¾"""
        
        features = pd.DataFrame()
        
        # ä¸»è¦å¹³å‡é£Žé€Ÿç‰¹å¾
        features['forecast_wind'] = data[avg_wind_col]
        features['forecast_wind_2'] = data[avg_wind_col] ** 2
        
        # æ—¶é—´ç‰¹å¾
        features['hour'] = data['datetime'].dt.hour
        features['month'] = data['datetime'].dt.month
        features['is_daytime'] = ((data['datetime'].dt.hour >= 6) & 
                                 (data['datetime'].dt.hour < 18)).astype(int)
        
        # æ»žåŽç‰¹å¾
        features['wind_lag_1h'] = data[avg_wind_col].shift(1)
        features['wind_lag_24h'] = data[avg_wind_col].shift(24)
        
        # æ»šåŠ¨ç»Ÿè®¡
        features['wind_24h_mean'] = data[avg_wind_col].rolling(window=24, min_periods=1).mean()
        
        # å¡«å……NaN
        features = features.fillna(method='bfill').fillna(method='ffill')
        
        self.feature_names = features.columns.tolist()
        return features
    
    def train(self, data, train_indices): # Removed avg_wind_col from train signature as it's added to data internally
        """è®­ç»ƒå¹³å‡é£Žé€Ÿæ ¡æ­£æ¨¡åž‹"""
        
        # avg_wind_col must be present in data before calling this
        # The correct way to handle this is to pass `data` with `avg_wind_col` already set
        # Or, make prepare_correction_features get it directly from data_cleaned_for_exp
        
        # Corrected: avg_wind_col is used within prepare_correction_features
        # so it must be passed there. But train method itself doesn't need it.
        # The external caller needs to ensure `data` has `avg_wind_col`
        
        # This is for M3, which needs avg_wind_col during feature preparation
        # I'll modify the train method to take avg_wind_col directly for clarity
        # No, the `data` in `train` is `data_cleaned_for_exp` which has `avg_wind_col`
        # So I only need to pass avg_wind_col to `prepare_correction_features` when it's called
        
        avg_wind_col_in_data = [col for col in data.columns if 'avg_wind_speed' in col]
        if not avg_wind_col_in_data:
            raise ValueError("Average wind speed column not found in data for AverageWindCorrectionModel training.")
        
        features = self.prepare_correction_features(data, avg_wind_col_in_data[0])
        target_col = f'obs_wind_speed_{self.target_height}'
        target = data[target_col].values
        
        # åˆ’åˆ†è®­ç»ƒéªŒè¯é›†
        val_size = int(len(train_indices) * 0.2)
        train_only_indices = train_indices[:-val_size]
        val_indices = train_indices[-val_size:]
        
        X_train = features.iloc[train_only_indices]
        y_train = target[train_only_indices]
        X_val = features.iloc[val_indices]
        y_val = target[val_indices]
        
        # è®­ç»ƒLightGBM
        params = {
            'objective': 'regression',
            'metric': 'rmse',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.1,
            'feature_fraction': 0.9,
            'verbose': -1,
            'random_state': RANDOM_STATE
        }
        
        train_data = lgb.Dataset(X_train, label=y_train)
        valid_data = lgb.Dataset(X_val, label=y_val, reference=train_data)
        
        self.model = lgb.train(
            params,
            train_data,
            valid_sets=[valid_data],
            num_boost_round=100,
            callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(0)]
        )
        
        # è¯„ä¼°æ ¡æ­£æ•ˆæžœ
        y_pred = self.model.predict(features.iloc[train_indices], num_iteration=self.model.best_iteration)
        y_true = target[train_indices]
        
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        corr = np.corrcoef(y_true, y_pred)[0, 1]
        
        return {'rmse': rmse, 'correlation': corr}
    
    def predict(self, data, avg_wind_col):
        """é¢„æµ‹æ ¡æ­£åŽçš„å¹³å‡é£Žé€Ÿ"""
        features = self.prepare_correction_features(data, avg_wind_col)
        return self.model.predict(features, num_iteration=self.model.best_iteration)

def load_train_test_split(indices_path):
    """åŠ è½½è®­ç»ƒæµ‹è¯•é›†åˆ’åˆ†"""
    with open(indices_path, 'r') as f:
        indices = json.load(f)
    return indices['train_indices'], indices['test_indices']

def prepare_simple_features(data, wind_col):
    """ä¸ºM1ç³»åˆ—å‡†å¤‡ç®€å•ç‰¹å¾ï¼ˆç›´æŽ¥é¢„æµ‹ï¼‰"""
    features = pd.DataFrame()
    
    features['wind_speed'] = data[wind_col]
    features['wind_speed_2'] = data[wind_col] ** 2
    features['wind_speed_3'] = data[wind_col] ** 3
    
    features['hour'] = data['datetime'].dt.hour
    features['month'] = data['datetime'].dt.month
    features['is_daytime'] = ((data['datetime'].dt.hour >= 6) & 
                             (data['datetime'].dt.hour < 18)).astype(int)
    
    features['wind_lag_1h'] = data[wind_col].shift(1)
    features['wind_lag_24h'] = data[wind_col].shift(24)
    
    features = features.fillna(method='bfill').fillna(method='ffill')
    
    return features

def train_simple_lightgbm(X_train, y_train, X_test, y_test):
    """è®­ç»ƒç®€å•LightGBMæ¨¡åž‹ï¼ˆM1ç³»åˆ—ç”¨ï¼‰"""
    params = {
        'objective': 'regression',
        'metric': 'rmse',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.1,
        'verbose': -1,
        'random_state': RANDOM_STATE
    }
    
    train_data = lgb.Dataset(X_train, label=y_train)
    valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)
    
    model = lgb.train(
        params,
        train_data,
        valid_sets=[valid_data],
        num_boost_round=100,
        callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(0)]
    )
    
    return model

def run_experiment(data_path, save_dir, indices_path, exp_config):
    """è¿è¡ŒåŽŸæœ‰ç±»åž‹çš„å•ä¸ªè¯•éªŒ"""
    
    print(f"\n{'='*60}")
    print(f"ðŸ”¬ è¯•éªŒ: {exp_config['name']}")
    print(f"ðŸ“ {exp_config['description']}")
    print(f"{'='*60}")
    
    os.makedirs(save_dir, exist_ok=True)
    
    # åŠ è½½æ•°æ®
    print("  ðŸ“‚ åŠ è½½æ•°æ®...")
    data = pd.read_csv(data_path)
    data['datetime'] = pd.to_datetime(data['datetime'])
    
    # åŸºç¡€æ•°æ®æ¸…ç†
    data = data.dropna(subset=['power'])
    data = data[data['power'] >= 0]
    data = data.sort_values('datetime').reset_index(drop=True)
    
    processing_log = []
    processing_log.append(f"è¯•éªŒç±»åž‹: {exp_config['type']}")
    processing_log.append(f"åˆå§‹æ¸…ç†åŽæ•°æ®å¤§å°: {len(data)} (åœ¨ç‰¹å®šè¯•éªŒæ¸…ç†å‰)") # Log 1: Initial data size
    
    # èŽ·å–è®­ç»ƒæµ‹è¯•é›†åˆ’åˆ†
    train_indices, test_indices = load_train_test_split(indices_path)
    
    try:
        if exp_config['type'] == 'direct':
            # M1ç³»åˆ—ï¼šç›´æŽ¥é¢„æµ‹
            wind_col = exp_config['wind_col']
            processing_log.append(f"ç›´æŽ¥é¢„æµ‹é£Žé€Ÿåˆ—: {wind_col}")
            
            # æ¸…ç†é£Žé€Ÿæ•°æ®
            data_cleaned_for_exp = data.dropna(subset=[wind_col])
            data_cleaned_for_exp = data_cleaned_for_exp[(data_cleaned_for_exp[wind_col] >= 0) & (data_cleaned_for_exp[wind_col] <= 50)]
            
            # é‡æ–°èŽ·å–æœ‰æ•ˆç´¢å¼•
            valid_indices = data_cleaned_for_exp.index.tolist()
            train_indices_filtered = [i for i in train_indices if i in valid_indices]
            test_indices_filtered = [i for i in test_indices if i in valid_indices]
            
            processing_log.append(f"'{exp_config['name']}' è¯•éªŒç‰¹å®šæ¸…ç†åŽæ•°æ®å¤§å°: {len(data_cleaned_for_exp)}") # Log 2: Data size after specific cleaning
            
            # å‡†å¤‡ç‰¹å¾å’Œè®­ç»ƒæ¨¡åž‹
            features = prepare_simple_features(data_cleaned_for_exp, wind_col)
            target = data_cleaned_for_exp['power'].values
            
            processing_log.append(f"åŠŸçŽ‡é¢„æµ‹æ¨¡åž‹è¾“å…¥ç‰¹å¾ (M1): {features.columns.tolist()}") # Log 3: Features for M1 power prediction
            
            X_train = features.iloc[train_indices_filtered]
            X_test = features.iloc[test_indices_filtered]
            y_train = target[train_indices_filtered]
            y_test = target[test_indices_filtered]
            
            print("  ðŸš€ è®­ç»ƒç›´æŽ¥é¢„æµ‹æ¨¡åž‹...")
            model = train_simple_lightgbm(X_train, y_train, X_test, y_test)
            
            y_pred = model.predict(X_test, num_iteration=model.best_iteration)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            corr = np.corrcoef(y_test, y_pred)[0, 1]
            
            processing_log.append(f"ç›´æŽ¥é¢„æµ‹æ€§èƒ½: RMSE={rmse:.4f}, ç›¸å…³ç³»æ•°={corr:.4f}")
            
            # Prepare detailed results DataFrame for splitting
            detailed_results = pd.DataFrame({
                'datetime': data_cleaned_for_exp.iloc[test_indices_filtered]['datetime'].reset_index(drop=True),
                'actual_power': pd.Series(y_test).reset_index(drop=True),
                'predicted_power': pd.Series(y_pred).reset_index(drop=True),
            })
            
            X_test_reset = X_test.reset_index(drop=True)
            detailed_results = pd.concat([detailed_results, X_test_reset], axis=1)
            
            detailed_results['error'] = detailed_results['predicted_power'] - detailed_results['actual_power']
            detailed_results['abs_error'] = np.abs(detailed_results['error'])
            
            # Add original wind column if it's not already in X_test (unlikely)
            if wind_col not in X_test.columns: # unlikely, as it's a base feature
                 detailed_results[f'original_{wind_col}'] = data_cleaned_for_exp.iloc[test_indices_filtered][wind_col].reset_index(drop=True)

            # Split and save the results into two CSVs
            predictions_and_errors_df = detailed_results[[
                'datetime', 'actual_power', 'predicted_power', 'error', 'abs_error'
            ]]
            test_features_df = detailed_results.drop(columns=[
                'actual_power', 'predicted_power', 'error', 'abs_error'
            ])

            predictions_and_errors_df.to_csv(
                os.path.join(save_dir, f'{exp_config["name"]}_predictions_and_errors.csv'),
                index=False
            )
            test_features_df.to_csv(
                os.path.join(save_dir, f'{exp_config["name"]}_test_features.csv'),
                index=False
            )
            
        elif exp_config['type'] == 'two_step':
            # M2ç³»åˆ—ï¼šä¸¤æ­¥æ³•æ ¡æ­£
            wind_source = exp_config['wind_source']
            wind_height = exp_config['wind_height']
            
            processing_log.append(f"ä¸¤æ­¥æ³•æ ¡æ­£: {wind_source.upper()}-{wind_height}")
            
            # æ¸…ç†æ•°æ®
            required_cols = [f'{wind_source}_wind_speed_{wind_height}', f'obs_wind_speed_{wind_height}']
            data_cleaned_for_exp = data.dropna(subset=required_cols)
            for col in required_cols:
                data_cleaned_for_exp = data_cleaned_for_exp[(data_cleaned_for_exp[col] >= 0) & (data_cleaned_for_exp[col] <= 50)]
            
            # é‡æ–°èŽ·å–æœ‰æ•ˆç´¢å¼•
            valid_indices = data_cleaned_for_exp.index.tolist()
            train_indices_filtered = [i for i in train_indices if i in valid_indices]
            test_indices_filtered = [i for i in test_indices if i in valid_indices]
            
            processing_log.append(f"'{exp_config['name']}' è¯•éªŒç‰¹å®šæ¸…ç†åŽæ•°æ®å¤§å°: {len(data_cleaned_for_exp)}") # Log 2: Data size after specific cleaning
            
            # ç¬¬ä¸€æ­¥ï¼šé£Žé€Ÿæ ¡æ­£
            print("  ðŸŽ¯ ç¬¬ä¸€æ­¥ï¼šé£Žé€Ÿæ ¡æ­£...")
            wind_corrector = WindCorrectionModel(target_height=wind_height, source=wind_source)
            correction_stats = wind_corrector.train(data_cleaned_for_exp, train_indices_filtered)
            
            processing_log.append(f"é£Žé€Ÿæ ¡æ­£æ¨¡åž‹è¾“å…¥ç‰¹å¾ (M2): {wind_corrector.feature_names}") # Log 3: Features for wind correction model
            
            corrected_wind = wind_corrector.predict(data_cleaned_for_exp)
            processing_log.append(f"é£Žé€Ÿæ ¡æ­£æ€§èƒ½: RMSE={correction_stats['rmse']:.4f}")
            
            # ç¬¬äºŒæ­¥ï¼šåŠŸçŽ‡é¢„æµ‹
            print("  âš¡ ç¬¬äºŒæ­¥ï¼šåŠŸçŽ‡é¢„æµ‹...")
            power_predictor = PowerPredictionModel()
            power_results = power_predictor.train(corrected_wind, data_cleaned_for_exp, train_indices_filtered, test_indices_filtered)
            
            processing_log.append(f"åŠŸçŽ‡é¢„æµ‹æ¨¡åž‹è¾“å…¥ç‰¹å¾ (M2): {power_predictor.feature_names}") # Log 4: Features for power prediction model
            
            processing_log.append(f"åŠŸçŽ‡é¢„æµ‹æ€§èƒ½: RMSE={power_results['rmse']:.4f}")
            
            rmse = power_results['rmse']
            corr = power_results['correlation']
            y_pred = power_results['predictions']
            y_test = power_results['actual']
            X_test_features = power_results['features_test']
            
            # Prepare detailed results DataFrame for splitting
            detailed_results = pd.DataFrame({
                'datetime': data_cleaned_for_exp.iloc[test_indices_filtered]['datetime'].reset_index(drop=True),
                'actual_power': pd.Series(y_test).reset_index(drop=True),
                'predicted_power': pd.Series(y_pred).reset_index(drop=True),
            })
            
            X_test_features_reset = X_test_features.reset_index(drop=True)
            detailed_results = pd.concat([detailed_results, X_test_features_reset], axis=1)

            # Add original/corrected wind columns that are not necessarily in X_test_features but important for overview
            detailed_results['original_forecast_wind'] = data_cleaned_for_exp.iloc[test_indices_filtered][f'{wind_source}_wind_speed_{wind_height}'].reset_index(drop=True)
            detailed_results['observed_wind'] = data_cleaned_for_exp.iloc[test_indices_filtered][f'obs_wind_speed_{wind_height}'].reset_index(drop=True)
            detailed_results['corrected_wind_speed'] = pd.Series(corrected_wind[test_indices_filtered]).reset_index(drop=True) # Ensure correct shape

            detailed_results['error'] = detailed_results['predicted_power'] - detailed_results['actual_power']
            detailed_results['abs_error'] = np.abs(detailed_results['error'])

            # Split and save the results into two CSVs
            predictions_and_errors_df = detailed_results[[
                'datetime', 'actual_power', 'predicted_power', 'error', 'abs_error'
            ]]
            test_features_df = detailed_results.drop(columns=[
                'actual_power', 'predicted_power', 'error', 'abs_error'
            ])

            predictions_and_errors_df.to_csv(
                os.path.join(save_dir, f'{exp_config["name"]}_predictions_and_errors.csv'),
                index=False
            )
            test_features_df.to_csv(
                os.path.join(save_dir, f'{exp_config["name"]}_test_features.csv'),
                index=False
            )
            
        elif exp_config['type'] == 'fusion':
            # Fusionç³»åˆ—ï¼šå¤šé£Žé€Ÿèžåˆ
            wind_configs = exp_config['wind_configs']
            fusion_strategy = exp_config['fusion_strategy']
            
            processing_log.append(f"èžåˆç­–ç•¥: {fusion_strategy}")
            processing_log.append(f"é£Žé€Ÿé…ç½®: {wind_configs}")
            
            # æ¸…ç†æ‰€æœ‰éœ€è¦çš„é£Žé€Ÿæ•°æ®
            all_required_cols = ['power']
            for config in wind_configs:
                source = config['source']
                height = config['height']
                all_required_cols.extend([f'{source}_wind_speed_{height}'])
                if fusion_strategy != 'direct':
                    all_required_cols.append(f'obs_wind_speed_{height}')
            
            data_cleaned_for_exp = data.dropna(subset=all_required_cols)
            for col in all_required_cols:
                if 'wind_speed' in col:
                    data_cleaned_for_exp = data_cleaned_for_exp[(data_cleaned_for_exp[col] >= 0) & (data_cleaned_for_exp[col] <= 50)]
            
            # é‡æ–°èŽ·å–æœ‰æ•ˆç´¢å¼•
            valid_indices = data_cleaned_for_exp.index.tolist()
            train_indices_filtered = [i for i in train_indices if i in valid_indices]
            test_indices_filtered = [i for i in test_indices if i in valid_indices]
            
            processing_log.append(f"'{exp_config['name']}' è¯•éªŒç‰¹å®šæ¸…ç†åŽæ•°æ®å¤§å°: {len(data_cleaned_for_exp)}") # Log 2: Data size after specific cleaning
            
            # æ ¡æ­£åŽèžåˆ
            print("  ðŸŽ¯ å¤šé£Žé€Ÿæ ¡æ­£...")
            
            corrected_winds = {}
            correction_stats_all = {}
            
            # åˆ†åˆ«æ ¡æ­£æ¯ä¸ªé£Žé€Ÿ
            for config in wind_configs:
                source = config['source']
                height = config['height']
                key = f"{source}_{height}"
                
                wind_corrector = WindCorrectionModel(target_height=height, source=source)
                correction_stat = wind_corrector.train(data_cleaned_for_exp, train_indices_filtered)
                correction_stats_all[key] = correction_stat
                
                corrected_winds[key] = wind_corrector.predict(data_cleaned_for_exp)
                
                processing_log.append(f"{key} é£Žé€Ÿæ ¡æ­£æ¨¡åž‹è¾“å…¥ç‰¹å¾: {wind_corrector.feature_names}") # Log 3: Features for wind correction model for each source
                processing_log.append(f"{key}æ ¡æ­£æ€§èƒ½: RMSE={correction_stat['rmse']:.4f}")
            
            # èžåˆæ ¡æ­£åŽçš„é£Žé€Ÿ
            print("  ðŸ”— èžåˆæ ¡æ­£åŽé£Žé€Ÿ...")
            
            weights = exp_config.get('weights', [0.25, 0.25, 0.25, 0.25])
            fused_wind = np.zeros(len(data_cleaned_for_exp))
            for i, key in enumerate(corrected_winds.keys()):
                fused_wind += weights[i] * corrected_winds[key]
            
            # åŠŸçŽ‡é¢„æµ‹
            print("  âš¡ åŠŸçŽ‡é¢„æµ‹...")
            power_predictor = PowerPredictionModel()
            power_results = power_predictor.train(fused_wind, data_cleaned_for_exp, train_indices_filtered, test_indices_filtered)
            
            processing_log.append(f"èžåˆåŠŸçŽ‡é¢„æµ‹æ¨¡åž‹è¾“å…¥ç‰¹å¾: {power_predictor.feature_names}") # Log 4: Features for power prediction model
            
            rmse = power_results['rmse']
            corr = power_results['correlation']
            y_pred = power_results['predictions']
            y_test = power_results['actual']
            X_test_features = power_results['features_test']
            
            # Prepare detailed results DataFrame for splitting
            detailed_results = pd.DataFrame({
                'datetime': data_cleaned_for_exp.iloc[test_indices_filtered]['datetime'].reset_index(drop=True),
                'actual_power': pd.Series(y_test).reset_index(drop=True),
                'predicted_power': pd.Series(y_pred).reset_index(drop=True),
            })
            
            X_test_features_reset = X_test_features.reset_index(drop=True)
            detailed_results = pd.concat([detailed_results, X_test_features_reset], axis=1)

            # Add original/corrected wind columns that are not necessarily in X_test_features but important for overview
            detailed_results['fused_corrected_wind_speed'] = pd.Series(fused_wind[test_indices_filtered]).reset_index(drop=True)
            for key, wind_values in corrected_winds.items():
                detailed_results[f'corrected_wind_{key}'] = pd.Series(wind_values[test_indices_filtered]).reset_index(drop=True)
            
            # Also add original winds for fusion to see what went in
            for config in wind_configs:
                source = config['source']
                height = config['height']
                detailed_results[f'original_{source}_wind_speed_{height}'] = data_cleaned_for_exp.iloc[test_indices_filtered][f'{source}_wind_speed_{height}'].reset_index(drop=True)

            detailed_results['error'] = detailed_results['predicted_power'] - detailed_results['actual_power']
            detailed_results['abs_error'] = np.abs(detailed_results['error'])
            
            # Split and save the results into two CSVs
            predictions_and_errors_df = detailed_results[[
                'datetime', 'actual_power', 'predicted_power', 'error', 'abs_error'
            ]]
            test_features_df = detailed_results.drop(columns=[
                'actual_power', 'predicted_power', 'error', 'abs_error'
            ])

            predictions_and_errors_df.to_csv(
                os.path.join(save_dir, f'{exp_config["name"]}_predictions_and_errors.csv'),
                index=False
            )
            test_features_df.to_csv(
                os.path.join(save_dir, f'{exp_config["name"]}_test_features.csv'),
                index=False
            )
        
        print(f"  âœ… å®Œæˆ! RMSE: {rmse:.4f}, ç›¸å…³ç³»æ•°: {corr:.4f}")
        
        # ä¿å­˜å¤„ç†æ—¥å¿—
        process_log = {
            'experiment_name': exp_config['name'],
            'experiment_config': exp_config,
            'processing_log': processing_log,
            'final_performance': {'rmse': rmse, 'correlation': corr}
        }
        
        with open(os.path.join(save_dir, f'{exp_config["name"]}_process_log.json'), 'w') as f:
            json.dump(process_log, f, indent=2, default=str)
        
        # ä¿å­˜æŒ‡æ ‡
        metrics = {'RMSE': rmse, 'Correlation': corr}
        with open(os.path.join(save_dir, f'{exp_config["name"]}_metrics.json'), 'w') as f:
            json.dump(metrics, f, indent=2)
        
        return metrics
        
    except Exception as e:
        print(f"  âŒ å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc() # Print full traceback for debugging
        return {'RMSE': None, 'Correlation': None, 'error': str(e)}

def run_dual_height_corrected_fusion_experiment(data_path, save_dir, indices_path, exp_config):
    """è¿è¡ŒåŒé«˜åº¦æ ¡æ­£åŽèžåˆè¯•éªŒï¼ˆG-M4-Dual, E-M4-Dualï¼‰"""
    
    print(f"ðŸ”¬ åŒé«˜åº¦æ ¡æ­£èžåˆè¯•éªŒ: {exp_config['name']}")
    
    os.makedirs(save_dir, exist_ok=True)
    
    # åŠ è½½æ•°æ®
    data = pd.read_csv(data_path)
    data['datetime'] = pd.to_datetime(data['datetime'])
    
    source = exp_config['source']
    heights = exp_config['heights']
    
    # æ•°æ®æ¸…ç†
    required_cols = ['power']
    for height in heights:
        required_cols.extend([
            f'{source}_wind_speed_{height}',
            f'obs_wind_speed_{height}'
        ])
    
    data_cleaned_for_exp = data.dropna(subset=required_cols)
    for col in required_cols:
        if 'wind_speed' in col:
            data_cleaned_for_exp = data_cleaned_for_exp[(data_cleaned_for_exp[col] >= 0) & (data_cleaned_for_exp[col] <= 50)]
    
    data_cleaned_for_exp = data_cleaned_for_exp.sort_values('datetime').reset_index(drop=True)
    
    # èŽ·å–è®­ç»ƒæµ‹è¯•åˆ’åˆ†
    train_indices, test_indices = load_train_test_split(indices_path)
    
    # é‡æ–°èŽ·å–æœ‰æ•ˆç´¢å¼•
    valid_indices = data_cleaned_for_exp.index.tolist()
    train_indices_filtered = [i for i in train_indices if i in valid_indices]
    test_indices_filtered = [i for i in test_indices if i in valid_indices]
    
    processing_log = []
    processing_log.append(f"åŒé«˜åº¦æ ¡æ­£èžåˆè¯•éªŒ: {exp_config['name']}")
    processing_log.append(f"'{exp_config['name']}' è¯•éªŒç‰¹å®šæ¸…ç†åŽæ•°æ®å¤§å°: {len(data_cleaned_for_exp)}") # Log 2: Data size after specific cleaning
    
    # ç¬¬ä¸€æ­¥ï¼šåˆ†åˆ«æ ¡æ­£ä¸¤ä¸ªé«˜åº¦çš„é£Žé€Ÿ
    print(f"  ðŸŽ¯ ç¬¬ä¸€æ­¥ï¼šåˆ†åˆ«æ ¡æ­£{heights}é£Žé€Ÿ...")
    
    corrected_winds = {}
    correction_stats = {}
    
    for height in heights:
        print(f"    æ ¡æ­£{source.upper()}-{height}...")
        
        wind_corrector = WindCorrectionModel(target_height=height, source=source)
        correction_stat = wind_corrector.train(data_cleaned_for_exp, train_indices_filtered)
        correction_stats[f'{source}_{height}'] = correction_stat
        
        corrected_winds[f'{source}_{height}'] = wind_corrector.predict(data_cleaned_for_exp)
        
        processing_log.append(f"{source}_{height} é£Žé€Ÿæ ¡æ­£æ¨¡åž‹è¾“å…¥ç‰¹å¾: {wind_corrector.feature_names}") # Log 3: Features for each wind correction model
        print(f"    {source.upper()}-{height}æ ¡æ­£RMSE: {correction_stat['rmse']:.4f}")
        processing_log.append(f"{source}_{height}æ ¡æ­£æ€§èƒ½: RMSE={correction_stat['rmse']:.4f}")
    
    # ç¬¬äºŒæ­¥ï¼šèžåˆæ ¡æ­£åŽçš„é£Žé€Ÿ
    print(f"  ðŸ”— ç¬¬äºŒæ­¥ï¼šèžåˆæ ¡æ­£åŽé£Žé€Ÿ...")
    
    weights = exp_config['fusion_weights']
    fused_corrected_wind = np.zeros(len(data_cleaned_for_exp))
    
    for i, height in enumerate(heights):
        key = f'{source}_{height}'
        fused_corrected_wind += weights[i] * corrected_winds[key]
        print(f"    {key}æƒé‡: {weights[i]}")
        processing_log.append(f"{key}æƒé‡: {weights[i]}")
    
    # ç¬¬ä¸‰æ­¥ï¼šç”¨èžåˆé£Žé€Ÿé¢„æµ‹åŠŸçŽ‡
    print(f"  âš¡ ç¬¬ä¸‰æ­¥ï¼šåŠŸçŽ‡é¢„æµ‹...")
    
    power_predictor = PowerPredictionModel()
    power_results = power_predictor.train(
        fused_corrected_wind, data_cleaned_for_exp, train_indices_filtered, test_indices_filtered
    )
    
    processing_log.append(f"åŒé«˜åº¦èžåˆåŠŸçŽ‡é¢„æµ‹æ¨¡åž‹è¾“å…¥ç‰¹å¾: {power_predictor.feature_names}") # Log 4: Features for power prediction model
    
    rmse = power_results['rmse']
    corr = power_results['correlation']
    y_pred = power_results['predictions']
    y_test = power_results['actual']
    X_test_features = power_results['features_test']
    
    processing_log.append(f"æœ€ç»ˆæµ‹è¯•æ€§èƒ½: RMSE={rmse:.4f}, ç›¸å…³ç³»æ•°={corr:.4f}")
    
    print(f"  âœ… å®Œæˆ! RMSE: {rmse:.4f}, ç›¸å…³ç³»æ•°: {corr:.4f}")
    
    # Prepare detailed results DataFrame for splitting
    test_datetimes = data_cleaned_for_exp.iloc[test_indices_filtered]['datetime'].reset_index(drop=True)
    test_actual_powers = data_cleaned_for_exp.iloc[test_indices_filtered]['power'].reset_index(drop=True)
    y_pred_series = pd.Series(y_pred).reset_index(drop=True)
    X_test_features_reset = X_test_features.reset_index(drop=True)

    detailed_results = pd.concat([
        test_datetimes.rename('datetime'),
        test_actual_powers.rename('actual_power'),
        y_pred_series.rename('predicted_power'),
        X_test_features_reset
    ], axis=1)

    detailed_results['fused_corrected_wind_speed'] = pd.Series(fused_corrected_wind[test_indices_filtered]).reset_index(drop=True)
    for height in heights:
        key = f'{source}_{height}'
        detailed_results[f'corrected_wind_{key}'] = pd.Series(corrected_winds[key][test_indices_filtered]).reset_index(drop=True)
        detailed_results[f'original_{source}_wind_speed_{height}'] = data_cleaned_for_exp.iloc[test_indices_filtered][f'{source}_wind_speed_{height}'].reset_index(drop=True)

    detailed_results['error'] = detailed_results['predicted_power'] - detailed_results['actual_power']
    detailed_results['abs_error'] = np.abs(detailed_results['error'])
    
    # Split and save the results into two CSVs
    predictions_and_errors_df = detailed_results[[
        'datetime', 'actual_power', 'predicted_power', 'error', 'abs_error'
    ]]
    test_features_df = detailed_results.drop(columns=[
        'actual_power', 'predicted_power', 'error', 'abs_error'
    ])

    predictions_and_errors_df.to_csv(
        os.path.join(save_dir, f'{exp_config["name"]}_predictions_and_errors.csv'),
        index=False
    )
    test_features_df.to_csv(
        os.path.join(save_dir, f'{exp_config["name"]}_test_features.csv'),
        index=False
    )
    
    # ä¿å­˜å¤„ç†æ—¥å¿—
    process_log = {
        'experiment_name': exp_config['name'],
        'experiment_config': exp_config,
        'correction_stats': correction_stats,
        'fusion_weights': weights,
        'processing_log': processing_log,
        'final_performance': {'rmse': rmse, 'correlation': corr}
    }
    
    with open(os.path.join(save_dir, f'{exp_config["name"]}_process_log.json'), 'w') as f:
        json.dump(process_log, f, indent=2, default=str)
    
    # ä¿å­˜æŒ‡æ ‡
    metrics = {'RMSE': rmse, 'Correlation': corr}
    with open(os.path.join(save_dir, f'{exp_config["name"]}_metrics.json'), 'w') as f:
        json.dump(metrics, f, indent=2)
    
    return metrics

def run_cross_source_corrected_fusion_experiment(data_path, save_dir, indices_path, exp_config):
    """è¿è¡Œè·¨æºæ ¡æ­£èžåˆè¯•éªŒï¼ˆX-M2-10m, X-M2-70mï¼‰"""
    
    print(f"ðŸ”¬ è·¨æºæ ¡æ­£èžåˆè¯•éªŒ: {exp_config['name']}")
    
    os.makedirs(save_dir, exist_ok=True)
    
    # åŠ è½½æ•°æ®
    data = pd.read_csv(data_path)
    data['datetime'] = pd.to_datetime(data['datetime'])
    
    height = exp_config['height']
    sources = exp_config['sources']
    
    # æ•°æ®æ¸…ç†
    required_cols = ['power', f'obs_wind_speed_{height}']
    for source in sources:
        required_cols.append(f'{source}_wind_speed_{height}')
    
    data_cleaned_for_exp = data.dropna(subset=required_cols)
    for col in required_cols:
        if 'wind_speed' in col:
            data_cleaned_for_exp = data_cleaned_for_exp[(data_cleaned_for_exp[col] >= 0) & (data_cleaned_for_exp[col] <= 50)]
    
    data_cleaned_for_exp = data_cleaned_for_exp.sort_values('datetime').reset_index(drop=True)
    
    # èŽ·å–è®­ç»ƒæµ‹è¯•åˆ’åˆ†
    train_indices, test_indices = load_train_test_split(indices_path)
    
    # é‡æ–°èŽ·å–æœ‰æ•ˆç´¢å¼•
    valid_indices = data_cleaned_for_exp.index.tolist()
    train_indices_filtered = [i for i in train_indices if i in valid_indices]
    test_indices_filtered = [i for i in test_indices if i in valid_indices]
    
    processing_log = []
    processing_log.append(f"è·¨æºæ ¡æ­£èžåˆè¯•éªŒ: {exp_config['name']}")
    processing_log.append(f"'{exp_config['name']}' è¯•éªŒç‰¹å®šæ¸…ç†åŽæ•°æ®å¤§å°: {len(data_cleaned_for_exp)}") # Log 2: Data size after specific cleaning
    
    # ç¬¬ä¸€æ­¥ï¼šåˆ†åˆ«æ ¡æ­£æ¯ä¸ªæºçš„é£Žé€Ÿ
    print(f"  ðŸŽ¯ ç¬¬ä¸€æ­¥ï¼šåˆ†åˆ«æ ¡æ­£{sources}çš„{height}é£Žé€Ÿ...")
    
    corrected_winds = {}
    correction_stats = {}
    
    for source in sources:
        print(f"    æ ¡æ­£{source.upper()}-{height}...")
        
        wind_corrector = WindCorrectionModel(target_height=height, source=source)
        correction_stat = wind_corrector.train(data_cleaned_for_exp, train_indices_filtered)
        correction_stats[f'{source}_{height}'] = correction_stat
        
        corrected_winds[f'{source}_{height}'] = wind_corrector.predict(data_cleaned_for_exp)
        
        processing_log.append(f"{source}_{height} é£Žé€Ÿæ ¡æ­£æ¨¡åž‹è¾“å…¥ç‰¹å¾: {wind_corrector.feature_names}") # Log 3: Features for each wind correction model
        print(f"    {source.upper()}-{height}æ ¡æ­£RMSE: {correction_stat['rmse']:.4f}")
        processing_log.append(f"{source}_{height}æ ¡æ­£æ€§èƒ½: RMSE={correction_stat['rmse']:.4f}")
    
    # ç¬¬äºŒæ­¥ï¼šèžåˆæ ¡æ­£åŽçš„é£Žé€Ÿ
    print(f"  ðŸ”— ç¬¬äºŒæ­¥ï¼šèžåˆæ ¡æ­£åŽé£Žé€Ÿ...")
    
    weights = exp_config['fusion_weights']
    fused_corrected_wind = np.zeros(len(data_cleaned_for_exp))
    
    for i, source in enumerate(sources):
        key = f'{source}_{height}'
        fused_corrected_wind += weights[i] * corrected_winds[key]
        print(f"    {key}æƒé‡: {weights[i]}")
        processing_log.append(f"{key}æƒé‡: {weights[i]}")
    
    # ç¬¬ä¸‰æ­¥ï¼šç”¨èžåˆé£Žé€Ÿé¢„æµ‹åŠŸçŽ‡
    print(f"  âš¡ ç¬¬ä¸‰æ­¥ï¼šåŠŸçŽ‡é¢„æµ‹...")
    
    power_predictor = PowerPredictionModel()
    power_results = power_predictor.train(
        fused_corrected_wind, data_cleaned_for_exp, train_indices_filtered, test_indices_filtered
    )
    
    processing_log.append(f"è·¨æºèžåˆåŠŸçŽ‡é¢„æµ‹æ¨¡åž‹è¾“å…¥ç‰¹å¾: {power_predictor.feature_names}") # Log 4: Features for power prediction model
    
    rmse = power_results['rmse']
    corr = power_results['correlation']
    y_pred = power_results['predictions']
    y_test = power_results['actual']
    X_test_features = power_results['features_test']
    
    processing_log.append(f"æœ€ç»ˆæµ‹è¯•æ€§èƒ½: RMSE={rmse:.4f}, ç›¸å…³ç³»æ•°={corr:.4f}")
    
    print(f"  âœ… å®Œæˆ! RMSE: {rmse:.4f}, ç›¸å…³ç³»æ•°: {corr:.4f}")
    
    # Prepare detailed results DataFrame for splitting
    test_datetimes = data_cleaned_for_exp.iloc[test_indices_filtered]['datetime'].reset_index(drop=True)
    test_actual_powers = data_cleaned_for_exp.iloc[test_indices_filtered]['power'].reset_index(drop=True)
    y_pred_series = pd.Series(y_pred).reset_index(drop=True)
    X_test_features_reset = X_test_features.reset_index(drop=True)

    detailed_results = pd.concat([
        test_datetimes.rename('datetime'),
        test_actual_powers.rename('actual_power'),
        y_pred_series.rename('predicted_power'),
        X_test_features_reset
    ], axis=1)

    detailed_results['fused_corrected_wind_speed'] = pd.Series(fused_corrected_wind[test_indices_filtered]).reset_index(drop=True)
    for source in sources:
        key = f'{source}_{height}'
        detailed_results[f'corrected_wind_{key}'] = pd.Series(corrected_winds[key][test_indices_filtered]).reset_index(drop=True)
        detailed_results[f'original_{source}_wind_speed_{height}'] = data_cleaned_for_exp.iloc[test_indices_filtered][f'{source}_wind_speed_{height}'].reset_index(drop=True)

    detailed_results['error'] = detailed_results['predicted_power'] - detailed_results['actual_power']
    detailed_results['abs_error'] = np.abs(detailed_results['error'])
    
    # Split and save the results into two CSVs
    predictions_and_errors_df = detailed_results[[
        'datetime', 'actual_power', 'predicted_power', 'error', 'abs_error'
    ]]
    test_features_df = detailed_results.drop(columns=[
        'actual_power', 'predicted_power', 'error', 'abs_error'
    ])

    predictions_and_errors_df.to_csv(
        os.path.join(save_dir, f'{exp_config["name"]}_predictions_and_errors.csv'),
        index=False
    )
    test_features_df.to_csv(
        os.path.join(save_dir, f'{exp_config["name"]}_test_features.csv'),
        index=False
    )
    
    # ä¿å­˜å¤„ç†æ—¥å¿—
    process_log = {
        'experiment_name': exp_config['name'],
        'experiment_config': exp_config,
        'correction_stats': correction_stats,
        'fusion_weights': weights,
        'processing_log': processing_log,
        'final_performance': {'rmse': rmse, 'correlation': corr}
    }
    
    with open(os.path.join(save_dir, f'{exp_config["name"]}_process_log.json'), 'w') as f:
        json.dump(process_log, f, indent=2, default=str)
    
    # ä¿å­˜æŒ‡æ ‡
    metrics = {'RMSE': rmse, 'Correlation': corr}
    with open(os.path.join(save_dir, f'{exp_config["name"]}_metrics.json'), 'w') as f:
        json.dump(metrics, f, indent=2)
    
    return metrics

def run_cross_source_average_corrected_experiment(data_path, save_dir, indices_path, exp_config):
    """è¿è¡Œè·¨æºå¹³å‡æ ¡æ­£è¯•éªŒï¼ˆX-M3-10m, X-M3-70mï¼‰- ä½ çš„åˆ›æ–°æ–¹æ³•"""
    
    print(f"ðŸ”¬ è·¨æºå¹³å‡æ ¡æ­£è¯•éªŒ: {exp_config['name']} â­")
    
    os.makedirs(save_dir, exist_ok=True)
    
    # åŠ è½½æ•°æ®
    data = pd.read_csv(data_path)
    data['datetime'] = pd.to_datetime(data['datetime'])
    
    height = exp_config['height']
    sources = exp_config['sources']
    
    # æ•°æ®æ¸…ç†
    required_cols = ['power', f'obs_wind_speed_{height}']
    for source in sources:
        required_cols.append(f'{source}_wind_speed_{height}')
    
    data_cleaned_for_exp = data.dropna(subset=required_cols)
    for col in required_cols:
        if 'wind_speed' in col:
            data_cleaned_for_exp = data_cleaned_for_exp[(data_cleaned_for_exp[col] >= 0) & (data_cleaned_for_exp[col] <= 50)]
    
    data_cleaned_for_exp = data_cleaned_for_exp.sort_values('datetime').reset_index(drop=True)
    
    # èŽ·å–è®­ç»ƒæµ‹è¯•åˆ’åˆ†
    train_indices, test_indices = load_train_test_split(indices_path)
    
    # é‡æ–°èŽ·å–æœ‰æ•ˆç´¢å¼•
    valid_indices = data_cleaned_for_exp.index.tolist()
    train_indices_filtered = [i for i in train_indices if i in valid_indices]
    test_indices_filtered = [i for i in test_indices if i in valid_indices]
    
    processing_log = []
    processing_log.append(f"è·¨æºå¹³å‡æ ¡æ­£è¯•éªŒ: {exp_config['name']} (åˆ›æ–°æ–¹æ³•)")
    processing_log.append(f"'{exp_config['name']}' è¯•éªŒç‰¹å®šæ¸…ç†åŽæ•°æ®å¤§å°: {len(data_cleaned_for_exp)}") # Log 2: Data size after specific cleaning
    
    # ç¬¬ä¸€æ­¥ï¼šè®¡ç®—è·¨æºå¹³å‡é£Žé€Ÿ
    print(f"  ðŸ“Š ç¬¬ä¸€æ­¥ï¼šè®¡ç®—{sources}åœ¨{height}çš„å¹³å‡é£Žé€Ÿ...")
    
    wind_values = []
    for source in sources:
        wind_col = f'{source}_wind_speed_{height}'
        wind_values.append(data_cleaned_for_exp[wind_col].values)
    
    # è®¡ç®—å¹³å‡å€¼
    average_wind = np.mean(wind_values, axis=0)
    
    print(f"    åŽŸå§‹é£Žé€ŸèŒƒå›´: {np.min(wind_values):.2f} - {np.max(wind_values):.2f}")
    print(f"    å¹³å‡é£Žé€ŸèŒƒå›´: {np.min(average_wind):.2f} - {np.max(average_wind):.2f}")
    
    processing_log.append(f"è®¡ç®—{sources}å¹³å‡é£Žé€Ÿï¼ŒèŒƒå›´: {np.min(average_wind):.2f} - {np.max(average_wind):.2f}")
    
    # ç¬¬äºŒæ­¥ï¼šè®­ç»ƒå¹³å‡é£Žé€Ÿçš„æ ¡æ­£æ¨¡åž‹
    print(f"  ðŸŽ¯ ç¬¬äºŒæ­¥ï¼šè®­ç»ƒå¹³å‡é£Žé€Ÿæ ¡æ­£æ¨¡åž‹...")
    
    # æ·»åŠ å¹³å‡é£Žé€Ÿåˆ—åˆ°æ•°æ®ä¸­
    avg_wind_col = f'avg_wind_speed_{height}'
    data_cleaned_for_exp[avg_wind_col] = average_wind
    
    avg_corrector = AverageWindCorrectionModel(target_height=height, source_name='average')
    correction_stats = avg_corrector.train(data_cleaned_for_exp, train_indices_filtered)
    
    processing_log.append(f"å¹³å‡é£Žé€Ÿæ ¡æ­£æ¨¡åž‹è¾“å…¥ç‰¹å¾: {avg_corrector.feature_names}") # Log 3: Features for average wind correction model
    print(f"    å¹³å‡é£Žé€Ÿæ ¡æ­£RMSE: {correction_stats['rmse']:.4f}")
    processing_log.append(f"å¹³å‡é£Žé€Ÿæ ¡æ­£æ€§èƒ½: RMSE={correction_stats['rmse']:.4f}")
    
    # ç¬¬ä¸‰æ­¥ï¼šèŽ·å–æ ¡æ­£åŽçš„å¹³å‡é£Žé€Ÿ
    print(f"  ðŸ”§ ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆæ ¡æ­£åŽçš„å¹³å‡é£Žé€Ÿ...")
    
    corrected_average_wind = avg_corrector.predict(data_cleaned_for_exp, avg_wind_col)
    
    # ç¬¬å››æ­¥ï¼šç”¨æ ¡æ­£åŽçš„å¹³å‡é£Žé€Ÿé¢„æµ‹åŠŸçŽ‡
    print(f"  âš¡ ç¬¬å››æ­¥ï¼šåŠŸçŽ‡é¢„æµ‹...")
    
    power_predictor = PowerPredictionModel()
    power_results = power_predictor.train(
        corrected_average_wind, data_cleaned_for_exp, train_indices_filtered, test_indices_filtered
    )
    
    processing_log.append(f"å¹³å‡é£Žé€ŸåŠŸçŽ‡é¢„æµ‹æ¨¡åž‹è¾“å…¥ç‰¹å¾: {power_predictor.feature_names}") # Log 4: Features for power prediction model
    
    rmse = power_results['rmse']
    corr = power_results['correlation']
    y_pred = power_results['predictions']
    y_test = power_results['actual']
    X_test_features = power_results['features_test']
    
    processing_log.append(f"æœ€ç»ˆæµ‹è¯•æ€§èƒ½: RMSE={rmse:.4f}, ç›¸å…³ç³»æ•°={corr:.4f}")
    
    print(f"  âœ… å®Œæˆ! RMSE: {rmse:.4f}, ç›¸å…³ç³»æ•°: {corr:.4f}")
    
    # Prepare detailed results DataFrame for splitting
    test_datetimes = data_cleaned_for_exp.iloc[test_indices_filtered]['datetime'].reset_index(drop=True)
    test_actual_powers = data_cleaned_for_exp.iloc[test_indices_filtered]['power'].reset_index(drop=True)
    y_pred_series = pd.Series(y_pred).reset_index(drop=True)
    X_test_features_reset = X_test_features.reset_index(drop=True)

    detailed_results = pd.concat([
        test_datetimes.rename('datetime'),
        test_actual_powers.rename('actual_power'),
        y_pred_series.rename('predicted_power'),
        X_test_features_reset
    ], axis=1)

    detailed_results['corrected_average_wind_speed'] = pd.Series(corrected_average_wind[test_indices_filtered]).reset_index(drop=True)
    detailed_results['original_average_wind_speed'] = pd.Series(average_wind[test_indices_filtered]).reset_index(drop=True)
    
    # æ·»åŠ å„ä¸ªæºçš„åŽŸå§‹é£Žé€Ÿ
    for source in sources:
        wind_col = f'{source}_wind_speed_{height}'
        detailed_results[f'original_{source}_wind_speed_{height}'] = data_cleaned_for_exp.iloc[test_indices_filtered][wind_col].reset_index(drop=True)

    detailed_results['error'] = detailed_results['predicted_power'] - detailed_results['actual_power']
    detailed_results['abs_error'] = np.abs(detailed_results['error'])
    
    # Split and save the results into two CSVs
    predictions_and_errors_df = detailed_results[[
        'datetime', 'actual_power', 'predicted_power', 'error', 'abs_error'
    ]]
    test_features_df = detailed_results.drop(columns=[
        'actual_power', 'predicted_power', 'error', 'abs_error'
    ])

    predictions_and_errors_df.to_csv(
        os.path.join(save_dir, f'{exp_config["name"]}_predictions_and_errors.csv'),
        index=False
    )
    test_features_df.to_csv(
        os.path.join(save_dir, f'{exp_config["name"]}_test_features.csv'),
        index=False
    )
    
    # ä¿å­˜å¤„ç†æ—¥å¿—
    process_log = {
        'experiment_name': exp_config['name'],
        'experiment_config': exp_config,
        'sources_averaged': sources,
        'height': height,
        'correction_stats': correction_stats,
        'processing_log': processing_log,
        'final_performance': {'rmse': rmse, 'correlation': corr}
    }
    
    with open(os.path.join(save_dir, f'{exp_config["name"]}_process_log.json'), 'w') as f:
        json.dump(process_log, f, indent=2, default=str)
    
    # ä¿å­˜æŒ‡æ ‡
    metrics = {'RMSE': rmse, 'Correlation': corr}
    with open(os.path.join(save_dir, f'{exp_config["name"]}_metrics.json'), 'w') as f:
        json.dump(metrics, f, indent=2)
    
    return metrics

def run_enhanced_experiment(data_path, save_dir, indices_path, exp_config):
    """è¿è¡Œå¢žå¼ºç‰ˆå•ä¸ªè¯•éªŒï¼ˆæ”¯æŒæ–°çš„è¯•éªŒç±»åž‹ï¼‰"""
    
    try:
        # æ ¹æ®è¯•éªŒç±»åž‹è°ƒç”¨ä¸åŒçš„å‡½æ•°
        if exp_config['type'] == 'dual_height_corrected_fusion':
            return run_dual_height_corrected_fusion_experiment(data_path, save_dir, indices_path, exp_config)
        
        elif exp_config['type'] == 'cross_source_corrected_fusion':
            return run_cross_source_corrected_fusion_experiment(data_path, save_dir, indices_path, exp_config)
        
        elif exp_config['type'] == 'cross_source_average_corrected':
            return run_cross_source_average_corrected_experiment(data_path, save_dir, indices_path, exp_config)
        
        else:
            # å¯¹äºŽåŽŸæœ‰ç±»åž‹ï¼Œä½¿ç”¨åŽŸæ¥çš„run_experimentå‡½æ•°
            return run_experiment(data_path, save_dir, indices_path, exp_config)
            
    except Exception as e:
        print(f"  âŒ å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc() # Print full traceback for debugging
        return {'RMSE': None, 'Correlation': None, 'error': str(e)}

def run_enhanced_experiments(data_path, base_save_dir, indices_path):
    """è¿è¡Œç®€åŒ–å‘½åç‰ˆå¢žå¼ºè¯•éªŒç³»ç»Ÿ"""
    
    print("=" * 80)
    print("ðŸš€ è¿è¡Œç®€åŒ–å‘½åç‰ˆå¢žå¼ºè¯•éªŒç³»ç»Ÿ")
    print("=" * 80)
    
    # ç¡®ä¿è®­ç»ƒæµ‹è¯•é›†åˆ’åˆ†æ–‡ä»¶å­˜åœ¨
    create_train_test_split_if_needed(data_path, indices_path)
    
    # å®šä¹‰ç®€åŒ–å‘½åçš„è¯•éªŒé…ç½®
    experiments = [
        # M1ç³»åˆ—ï¼šç›´æŽ¥é¢„æµ‹ï¼ˆä¿ç•™4ä¸ªï¼‰
        {
            'name': 'G-M1-10m',
            'description': 'GFSåŽŸå§‹10mé£Žé€Ÿç›´æŽ¥é¢„æµ‹åŠŸçŽ‡',
            'type': 'direct',
            'wind_col': 'gfs_wind_speed_10m'
        },
        {
            'name': 'G-M1-70m', 
            'description': 'GFSåŽŸå§‹70mé£Žé€Ÿç›´æŽ¥é¢„æµ‹åŠŸçŽ‡',
            'type': 'direct',
            'wind_col': 'gfs_wind_speed_70m'
        },
        {
            'name': 'E-M1-10m',
            'description': 'ECåŽŸå§‹10mé£Žé€Ÿç›´æŽ¥é¢„æµ‹åŠŸçŽ‡', 
            'type': 'direct',
            'wind_col': 'ec_wind_speed_10m'
        },
        {
            'name': 'E-M1-70m',
            'description': 'ECåŽŸå§‹70mé£Žé€Ÿç›´æŽ¥é¢„æµ‹åŠŸçŽ‡',
            'type': 'direct', 
            'wind_col': 'ec_wind_speed_70m'
        },
        
        # M2ç³»åˆ—ï¼šä¸¤æ­¥æ³•MLæ ¡æ­£ï¼ˆä¿ç•™4ä¸ªï¼‰
        {
            'name': 'G-M2-10m',
            'description': 'GFS 10mé£Žé€Ÿä¸¤æ­¥æ³•MLæ ¡æ­£',
            'type': 'two_step',
            'wind_source': 'gfs',
            'wind_height': '10m'
        },
        {
            'name': 'G-M2-70m',
            'description': 'GFS 70mé£Žé€Ÿä¸¤æ­¥æ³•MLæ ¡æ­£',
            'type': 'two_step',
            'wind_source': 'gfs', 
            'wind_height': '70m'
        },
        {
            'name': 'E-M2-10m',
            'description': 'EC 10mé£Žé€Ÿä¸¤æ­¥æ³•MLæ ¡æ­£',
            'type': 'two_step',
            'wind_source': 'ec',
            'wind_height': '10m'
        },
        {
            'name': 'E-M2-70m',
            'description': 'EC 70mé£Žé€Ÿä¸¤æ­¥æ³•MLæ ¡æ­£', 
            'type': 'two_step',
            'wind_source': 'ec',
            'wind_height': '70m'
        },
        
        # ä¿ç•™Fusion-M1ï¼ˆ1ä¸ªï¼‰
        {
            'name': 'Fusion-M1',
            'description': 'å››é£Žé€Ÿæ ¡æ­£åŽé™æ€èžåˆ',
            'type': 'fusion',
            'wind_configs': [
                {'source': 'ec', 'height': '10m'},
                {'source': 'ec', 'height': '70m'},
                {'source': 'gfs', 'height': '10m'},
                {'source': 'gfs', 'height': '70m'}
            ],
            'fusion_strategy': 'corrected',
            'weights': [0.25, 0.25, 0.25, 0.25]
        },
        
        # ========== æ–°å¢žè¯•éªŒï¼ˆç®€åŒ–å‘½åï¼‰==========
        
        # æ–°å¢ž1: ECåŒé«˜åº¦åˆ†åˆ«æ ¡æ­£åŽèžåˆ
        {
            'name': 'E-M4-Dual',
            'description': 'ECä¸¤é«˜åº¦åˆ†åˆ«æ ¡æ­£åŽå‡æƒèžåˆ',
            'type': 'dual_height_corrected_fusion',
            'source': 'ec',
            'heights': ['10m', '70m'],
            'fusion_weights': [0.5, 0.5]  # å‡æƒ
        },
        
        # æ–°å¢ž2: GFSåŒé«˜åº¦åˆ†åˆ«æ ¡æ­£åŽèžåˆ  
        {
            'name': 'G-M4-Dual',
            'description': 'GFSä¸¤é«˜åº¦åˆ†åˆ«æ ¡æ­£åŽå‡æƒèžåˆ',
            'type': 'dual_height_corrected_fusion',
            'source': 'gfs', 
            'heights': ['10m', '70m'],
            'fusion_weights': [0.5, 0.5]  # å‡æƒ
        },
        
        # æ–°å¢ž3: è·¨æº10mæ ¡æ­£èžåˆ
        {
            'name': 'X-M2-10m',
            'description': 'GFSå’ŒECçš„10måˆ†åˆ«æ ¡æ­£åŽå‡æƒèžåˆ',
            'type': 'cross_source_corrected_fusion',
            'height': '10m',
            'sources': ['gfs', 'ec'],
            'fusion_weights': [0.5, 0.5]  # å‡æƒ
        },
        
        # æ–°å¢ž4: è·¨æº70mæ ¡æ­£èžåˆ
        {
            'name': 'X-M2-70m', 
            'description': 'GFSå’ŒECçš„70måˆ†åˆ«æ ¡æ­£åŽå‡æƒèžåˆ',
            'type': 'cross_source_corrected_fusion',
            'height': '70m',
            'sources': ['gfs', 'ec'],
            'fusion_weights': [0.5, 0.5]  # å‡æƒ
        },
        
        # æ–°å¢ž5: è·¨æº10må¹³å‡æ ¡æ­£ï¼ˆä½ çš„åˆ›æ–°æ–¹æ³•ï¼‰â­
        {
            'name': 'X-M3-10m',
            'description': 'GFSå’ŒECçš„10må¹³å‡åŽæ ¡æ­£å†é¢„æµ‹åŠŸçŽ‡ â­åˆ›æ–°æ–¹æ³•',
            'type': 'cross_source_average_corrected',
            'height': '10m',
            'sources': ['gfs', 'ec']
        },
        
        # æ–°å¢ž6: è·¨æº70må¹³å‡æ ¡æ­£ â­
        {
            'name': 'X-M3-70m',
            'description': 'GFSå’ŒECçš„70må¹³å‡åŽæ ¡æ­£å†é¢„æµ‹åŠŸçŽ‡ â­åˆ›æ–°æ–¹æ³•', 
            'type': 'cross_source_average_corrected',
            'height': '70m',
            'sources': ['gfs', 'ec']
        }
    ]
    
    print(f"ðŸ“Š è¯•éªŒæ€»æ•°: {len(experiments)}")
    print(f"åŒ…æ‹¬:")
    print(f"   M1ç³»åˆ— (4ä¸ª): G/E-M1-10m/70m")
    print(f"   M2ç³»åˆ— (4ä¸ª): G/E-M2-10m/70m")  
    print(f"   Fusionç³»åˆ— (1ä¸ª): Fusion-M1")
    print(f"   M4ç³»åˆ— (2ä¸ª): G/E-M4-Dual")
    print(f"   X-M2ç³»åˆ— (2ä¸ª): X-M2-10m/70m")
    print(f"   X-M3ç³»åˆ— (2ä¸ª): X-M3-10m/70m â­ä½ çš„åˆ›æ–°æ–¹æ³•")
    print(f"")
    print(f"ðŸŽ¯ ç®€åŒ–å‘½åè§„åˆ™:")
    print(f"   G-/E-: GFS/ECæ•°æ®æº")
    print(f"   X-: è·¨æº(Cross)èžåˆ")
    print(f"   M1: ç›´æŽ¥é¢„æµ‹, M2: ä¸¤æ­¥æ ¡æ­£, M3: å¹³å‡æ ¡æ­£, M4: åŒé«˜åº¦èžåˆ")
    print(f"   Dual: åŒé«˜åº¦, 10m/70m: å•ä¸€é«˜åº¦")
    
    # å­˜å‚¨æ‰€æœ‰ç»“æžœ
    all_results = []
    
    for i, exp_config in enumerate(experiments, 1):
        print(f"\nè¿›åº¦: {i}/{len(experiments)}")
        
        try:
            # è¿è¡Œå•ä¸ªè¯•éªŒ
            save_dir = os.path.join(base_save_dir, exp_config['name'])
            metrics = run_enhanced_experiment(data_path, save_dir, indices_path, exp_config)
            
            # è®°å½•ç»“æžœ
            result = {
                'experiment': exp_config['name'],
                'description': exp_config['description'],
                'type': exp_config['type'],
                'RMSE': metrics.get('RMSE'),
                'Correlation': metrics.get('Correlation')
            }
            
            if 'error' in metrics:
                result['error'] = metrics['error']
            
            all_results.append(result)
            
        except Exception as e:
            print(f"âŒ {exp_config['name']} è¯•éªŒå¤±è´¥: {str(e)}")
            result = {
                'experiment': exp_config['name'],
                'description': exp_config['description'],
                'type': exp_config['type'],
                'RMSE': None,
                'Correlation': None,
                'error': str(e)
            }
            all_results.append(result)
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    create_enhanced_summary(all_results, base_save_dir)
    
    print(f"\n{'='*80}")
    print(f"ðŸŽ‰ ç®€åŒ–å‘½åç‰ˆå¢žå¼ºè¯•éªŒç³»ç»Ÿå®Œæˆ!")
    print(f"ðŸ“ ç»“æžœä¿å­˜åœ¨: {base_save_dir}")
    print(f"ðŸ“Š æ±‡æ€»æŠ¥å‘Š: {base_save_dir}/enhanced_summary.csv")
    print(f"{'='*80}")
    
    return all_results

def create_enhanced_summary(all_results, base_save_dir):
    """åˆ›å»ºå¢žå¼ºç‰ˆæ±‡æ€»æŠ¥å‘Š"""
    
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(all_results)
    
    # æŒ‰RMSEæŽ’åºï¼ˆåªåŒ…å«æœ‰æ•ˆç»“æžœï¼‰
    df_valid = df[df['RMSE'].notna()].copy()
    df_valid = df_valid.sort_values('RMSE')
    
    # ä¿å­˜è¯¦ç»†ç»“æžœ
    os.makedirs(base_save_dir, exist_ok=True)
    df.to_csv(os.path.join(base_save_dir, 'enhanced_summary.csv'), index=False)
    
    # åˆ›å»ºæŽ’åæŠ¥å‘Š
    print(f"\nðŸ“Š ç®€åŒ–å‘½åç‰ˆè¯•éªŒç»“æžœæŽ’å (æŒ‰RMSEæŽ’åº):")
    print(f"{'æŽ’å':<4} {'è¯•éªŒåç§°':<15} {'ç±»åž‹':<25} {'RMSE':<10} {'ç›¸å…³ç³»æ•°':<10}")
    print(f"-" * 85)
    
    for i, (_, row) in enumerate(df_valid.iterrows(), 1):
        print(f"{i:<4} {row['experiment']:<15} {row['type']:<25} {row['RMSE']:<10.4f} {row['Correlation']:<10.4f}")
    
    # æŒ‰è¯•éªŒç±»åž‹åˆ†æž
    print(f"\nðŸ“ˆ æŒ‰è¯•éªŒç±»åž‹åˆ†æž:")
    
    type_mapping = {
        'direct': 'M1-ç›´æŽ¥é¢„æµ‹',
        'two_step': 'M2-ä¸¤æ­¥æ ¡æ­£',
        'fusion': 'Fusion-å››é£Žé€Ÿèžåˆ',
        'dual_height_corrected_fusion': 'M4-åŒé«˜åº¦æ ¡æ­£èžåˆ',
        'cross_source_corrected_fusion': 'X-M2-è·¨æºæ ¡æ­£èžåˆ', 
        'cross_source_average_corrected': 'X-M3-è·¨æºå¹³å‡æ ¡æ­£â­'
    }
    
    type_analysis = {}
    for exp_type in type_mapping.keys():
        type_data = df_valid[df_valid['type'] == exp_type]
        if len(type_data) > 0:
            type_analysis[exp_type] = {
                'count': len(type_data),
                'best_rmse': type_data['RMSE'].min(),
                'best_experiment': type_data.loc[type_data['RMSE'].idxmin(), 'experiment'],
                'avg_rmse': type_data['RMSE'].mean(),
                'avg_correlation': type_data['Correlation'].mean()
            }
            
            print(f"  {type_mapping[exp_type]}:")
            print(f"    è¯•éªŒæ•°é‡: {type_analysis[exp_type]['count']}")
            print(f"    æœ€ä½³RMSE: {type_analysis[exp_type]['best_rmse']:.4f} ({type_analysis[exp_type]['best_experiment']})")
            print(f"    å¹³å‡RMSE: {type_analysis[exp_type]['avg_rmse']:.4f}")
    
    # ä½ çš„åˆ›æ–°æ–¹æ³•ç‰¹åˆ«åˆ†æž
    innovation_experiments = df_valid[df_valid['type'] == 'cross_source_average_corrected']
    if len(innovation_experiments) > 0:
        print(f"\nâ­ ä½ çš„åˆ›æ–°æ–¹æ³• (X-M3ç³»åˆ—) ç‰¹åˆ«åˆ†æž:")
        for _, row in innovation_experiments.iterrows():
            rank = list(df_valid['experiment']).index(row['experiment']) + 1
            print(f"  {row['experiment']}: æŽ’åç¬¬{rank}å, RMSE={row['RMSE']:.4f}")
            
        best_innovation = innovation_experiments.loc[innovation_experiments['RMSE'].idxmin()]
        overall_best = df_valid.iloc[0]
        
        if best_innovation['experiment'] == overall_best['experiment']:
            print(f"  ðŸ† ä½ çš„åˆ›æ–°æ–¹æ³•æ˜¯å…¨å±€æœ€ä½³ï¼")
        else:
            improvement = (overall_best['RMSE'] - best_innovation['RMSE']) / overall_best['RMSE'] * 100
            print(f"  ðŸ“Š ä¸Žå…¨å±€æœ€ä½³å·®è·: {abs(improvement):.2f}%")
    
    # ç®€åŒ–ç‰ˆæ•°æ®æºå¯¹æ¯”
    print(f"\nðŸ” æ•°æ®æºå¯¹æ¯”:")
    
    gfs_experiments = df_valid[df_valid['experiment'].str.contains('G-')]
    ec_experiments = df_valid[df_valid['experiment'].str.contains('E-')]
    cross_experiments = df_valid[df_valid['experiment'].str.contains('X-')]
    
    if len(gfs_experiments) > 0:
        print(f"  GFSç³»åˆ—: å¹³å‡RMSE={gfs_experiments['RMSE'].mean():.4f}")
    if len(ec_experiments) > 0:
        print(f"  ECç³»åˆ—: å¹³å‡RMSE={ec_experiments['RMSE'].mean():.4f}")
    if len(cross_experiments) > 0:
        print(f"  è·¨æºç³»åˆ—: å¹³å‡RMSE={cross_experiments['RMSE'].mean():.4f}")
    
    # ä¿å­˜åˆ†æžæŠ¥å‘Š
    with open(os.path.join(base_save_dir, 'simplified_analysis_summary.txt'), 'w', encoding='utf-8') as f:
        f.write("ç®€åŒ–å‘½åç‰ˆè¯•éªŒç³»ç»Ÿåˆ†æžæŠ¥å‘Š\n")
        f.write("="*50 + "\n\n")
        
        f.write("1. æ€»ä½“æŽ’å (æŒ‰RMSE):\n")
        for i, (_, row) in enumerate(df_valid.iterrows(), 1):
            f.write(f"{i}. {row['experiment']}: RMSE={row['RMSE']:.4f}, Corr={row['Correlation']:.4f}\n")
        
        f.write(f"\n2. æŒ‰ç±»åž‹åˆ†æž:\n")
        for exp_type, stats in type_analysis.items():
            f.write(f"{type_mapping.get(exp_type, exp_type)}: æœ€ä½³RMSE={stats['best_rmse']:.4f} ({stats['best_experiment']})\n")
        
        f.write(f"\n3. åˆ›æ–°æ–¹æ³•åˆ†æž:\n")
        if len(innovation_experiments) > 0:
            for _, row in innovation_experiments.iterrows():
                rank = list(df_valid['experiment']).index(row['experiment']) + 1
                f.write(f"- {row['experiment']}: æŽ’åç¬¬{rank}å, RMSE={row['RMSE']:.4f}\n")
        
        f.write(f"\n4. ä¸»è¦å‘çŽ°:\n")
        if len(df_valid) > 0:
            best_overall = df_valid.iloc[0]
            f.write(f"- å…¨å±€æœ€ä½³: {best_overall['experiment']} (RMSE: {best_overall['RMSE']:.4f})\n")
            f.write(f"- æœ€ä½³ç­–ç•¥: {best_overall['description']}\n")
            
            if len(innovation_experiments) > 0:
                best_innovation = innovation_experiments.loc[innovation_experiments['RMSE'].idxmin()]
                f.write(f"- åˆ›æ–°æ–¹æ³•æœ€ä½³: {best_innovation['experiment']} (RMSE: {best_innovation['RMSE']:.4f})\n")
    
    # åˆ†æžæœ€ä½³ç­–ç•¥
    if len(df_valid) > 0:
        best_result = df_valid.iloc[0]
        print(f"\nðŸ† æœ€ä½³è¯•éªŒ: {best_result['experiment']}")
        print(f"   RMSE: {best_result['RMSE']:.4f}")
        print(f"   ç›¸å…³ç³»æ•°: {best_result['Correlation']:.4f}")
        print(f"   ç­–ç•¥: {best_result['description']}")
        print(f"   ç±»åž‹: {type_mapping.get(best_result['type'], best_result['type'])}")
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯åˆ›æ–°æ–¹æ³•
        if best_result['type'] == 'cross_source_average_corrected':
            print(f"   ðŸŽ‰ æœ€ä½³è¯•éªŒæ˜¯ä½ çš„åˆ›æ–°æ–¹æ³•ï¼")

if __name__ == "__main__":
    # é…ç½®è·¯å¾„
    DATA_PATH = "/Users/xiaxin/work/WindForecast_Project/01_Data/processed/imputed_data/changma_imputed_complete.csv"
    BASE_SAVE_DIR = "/Users/xiaxin/work/WindForecast_Project/03_Results/simplified_enhanced_experiments"
    INDICES_PATH = "/Users/xiaxin/work/WindForecast_Project/03_Results/third_part_experiments/train_test_split.json"
    
    # è¿è¡Œç®€åŒ–å‘½åç‰ˆå¢žå¼ºè¯•éªŒç³»ç»Ÿ
    results = run_enhanced_experiments(DATA_PATH, BASE_SAVE_DIR, INDICES_PATH)
    
    print(f"\nðŸ’¡ ç®€åŒ–å‘½åç‰ˆå¢žå¼ºè¯•éªŒç³»ç»Ÿè¿è¡Œå®Œæˆ!")
    print(f"\nðŸŽ¯ ç®€æ´å‘½åç³»ç»Ÿ:")
    print(f"   åŽŸæœ‰è¯•éªŒ: G/E-M1/M2-10m/70m, Fusion-M1")
    print(f"   æ–°å¢žè¯•éªŒ: G/E-M4-Dual, X-M2-10m/70m, X-M3-10m/70m")
    print(f"   åˆ›æ–°æ–¹æ³•: X-M3-10m/70m (è·¨æºå¹³å‡æ ¡æ­£)")
    print(f"\nðŸ“Š çŽ°åœ¨å¯ä»¥ç”¨ç®€æ´çš„åç§°:")
    print(f"   - å¼•ç”¨ä½ çš„åˆ›æ–°: X-M3-10m")
    print(f"   - å¯¹æ¯”åŸºçº¿æ–¹æ³•: G-M2-70m vs X-M3-10m")
    print(f"   - åˆ†æžèžåˆç­–ç•¥: Fusion-M1 vs X-M2-10m vs X-M3-10m")
    print(f"   - è®ºæ–‡ä¸­æ›´ç®€æ´ç¾Žè§‚!")