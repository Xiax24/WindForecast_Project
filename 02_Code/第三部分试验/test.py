#!/usr/bin/env python3
"""
å®Œæ•´çš„14ä¸ªä¸¤æ­¥æ³•MLæ ¡æ­£è¯•éªŒç³»ç»Ÿ
M1ç³»åˆ—: ç›´æ¥é¢„æµ‹ (NWPé£é€Ÿ â†’ åŠŸç‡)
M2ç³»åˆ—: ä¸¤æ­¥æ³•MLæ ¡æ­£ (NWPå˜é‡ â†’ æ ¡æ­£é£é€Ÿ â†’ åŠŸç‡)  
M3ç³»åˆ—: å¤šé£é€Ÿèåˆ (å¤šä¸ªæ ¡æ­£é£é€Ÿ â†’ èåˆ â†’ åŠŸç‡)
Fusionç³»åˆ—: è·¨æ¨¡å¼èåˆ
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.metrics import mean_squared_error
import os
import json
import warnings
warnings.filterwarnings('ignore')

RANDOM_STATE = 42

class WindCorrectionModel:
    """é£é€Ÿæ ¡æ­£æ¨¡å‹"""
    
    def __init__(self, target_height='10m', source='gfs'):
        self.target_height = target_height
        self.source = source
        self.model = None
        self.feature_names = None
        
    def prepare_correction_features(self, data):
        """å‡†å¤‡é£é€Ÿæ ¡æ­£çš„ç‰¹å¾"""
        
        features = pd.DataFrame()
        
        # ä¸»è¦é¢„æŠ¥é£é€Ÿ
        main_wind_col = f'{self.source}_wind_speed_{self.target_height}'
        features['forecast_wind'] = data[main_wind_col]
        features['forecast_wind_2'] = data[main_wind_col] ** 2
        
        # å…¶ä»–é«˜åº¦çš„é£é€Ÿ
        other_height = '70m' if self.target_height == '10m' else '10m'
        other_wind_col = f'{self.source}_wind_speed_{other_height}'
        if other_wind_col in data.columns:
            features['other_height_wind'] = data[other_wind_col]
            features['wind_shear'] = np.log(data[other_wind_col] / (data[main_wind_col] + 0.1))
        
        # æ¸©åº¦ç‰¹å¾
        if f'{self.source}_temperature_10m' in data.columns:
            features['temperature'] = data[f'{self.source}_temperature_10m']
        
        # æ—¶é—´ç‰¹å¾
        features['hour'] = data['datetime'].dt.hour
        features['month'] = data['datetime'].dt.month
        features['is_daytime'] = ((data['datetime'].dt.hour >= 6) & 
                                 (data['datetime'].dt.hour < 18)).astype(int)
        
        # æ»åç‰¹å¾
        features['wind_lag_1h'] = data[main_wind_col].shift(1)
        features['wind_lag_24h'] = data[main_wind_col].shift(24)
        
        # æ»šåŠ¨ç»Ÿè®¡
        features['wind_24h_mean'] = data[main_wind_col].rolling(window=24, min_periods=1).mean()
        
        # å¡«å……NaN
        features = features.fillna(method='bfill').fillna(method='ffill')
        
        self.feature_names = features.columns.tolist()
        return features
    
    def train(self, data, train_indices):
        """è®­ç»ƒé£é€Ÿæ ¡æ­£æ¨¡å‹"""
        
        features = self.prepare_correction_features(data)
        target_col = f'obs_wind_speed_{self.target_height}'
        target = data[target_col].values
        
        # åˆ’åˆ†è®­ç»ƒéªŒè¯é›†
        val_size = int(len(train_indices) * 0.2)
        train_only_indices = train_indices[:-val_size]
        val_indices = train_indices[-val_size:]
        
        X_train = features.iloc[train_only_indices]
        y_train = target[train_only_indices]
        X_val = features.iloc[val_indices]
        y_val = target[val_indices]
        
        # è®­ç»ƒLightGBM
        params = {
            'objective': 'regression',
            'metric': 'rmse',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.1,
            'feature_fraction': 0.9,
            'verbose': -1,
            'random_state': RANDOM_STATE
        }
        
        train_data = lgb.Dataset(X_train, label=y_train)
        valid_data = lgb.Dataset(X_val, label=y_val, reference=train_data)
        
        self.model = lgb.train(
            params,
            train_data,
            valid_sets=[valid_data],
            num_boost_round=100,
            callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(0)]
        )
        
        # è¯„ä¼°æ ¡æ­£æ•ˆæœ
        y_pred = self.model.predict(features.iloc[train_indices], num_iteration=self.model.best_iteration)
        y_true = target[train_indices]
        
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        corr = np.corrcoef(y_true, y_pred)[0, 1]
        
        return {'rmse': rmse, 'correlation': corr}
    
    def predict(self, data):
        """é¢„æµ‹æ ¡æ­£åçš„é£é€Ÿ"""
        features = self.prepare_correction_features(data)
        return self.model.predict(features, num_iteration=self.model.best_iteration)

class PowerPredictionModel:
    """åŠŸç‡é¢„æµ‹æ¨¡å‹"""
    
    def __init__(self):
        self.model = None
        self.feature_names = None
    
    def prepare_power_features(self, wind_data, original_data):
        """å‡†å¤‡åŠŸç‡é¢„æµ‹ç‰¹å¾"""
        
        features = pd.DataFrame()
        
        # é£é€Ÿç‰¹å¾
        if isinstance(wind_data, dict):
            # å¤šé£é€Ÿæƒ…å†µ
            for key, wind_values in wind_data.items():
                features[f'wind_{key}'] = wind_values
                features[f'wind_{key}_2'] = wind_values ** 2
                features[f'wind_{key}_3'] = wind_values ** 3
        else:
            # å•é£é€Ÿæƒ…å†µ
            features['wind'] = wind_data
            features['wind_2'] = wind_data ** 2
            features['wind_3'] = wind_data ** 3
        
        # æ—¶é—´ç‰¹å¾
        features['hour'] = original_data['datetime'].dt.hour
        features['month'] = original_data['datetime'].dt.month
        features['is_daytime'] = ((original_data['datetime'].dt.hour >= 6) & 
                                 (original_data['datetime'].dt.hour < 18)).astype(int)
        
        # æ»åç‰¹å¾
        main_wind = list(wind_data.values())[0] if isinstance(wind_data, dict) else wind_data
        features['wind_lag_1h'] = pd.Series(main_wind).shift(1)
        features['wind_lag_24h'] = pd.Series(main_wind).shift(24)
        
        # å¡«å……NaN
        features = features.fillna(method='bfill').fillna(method='ffill')
        
        self.feature_names = features.columns.tolist()
        return features
    
    def train(self, wind_data, original_data, train_indices, test_indices):
        """è®­ç»ƒåŠŸç‡é¢„æµ‹æ¨¡å‹"""
        
        features = self.prepare_power_features(wind_data, original_data)
        target = original_data['power'].values
        
        X_train = features.iloc[train_indices]
        X_test = features.iloc[test_indices]
        y_train = target[train_indices]
        y_test = target[test_indices]
        
        # è®­ç»ƒLightGBM
        params = {
            'objective': 'regression',
            'metric': 'rmse',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.1,
            'feature_fraction': 0.9,
            'verbose': -1,
            'random_state': RANDOM_STATE
        }
        
        train_data = lgb.Dataset(X_train, label=y_train)
        valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)
        
        self.model = lgb.train(
            params,
            train_data,
            valid_sets=[valid_data],
            num_boost_round=100,
            callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(0)]
        )
        
        # è¯„ä¼°åŠŸç‡é¢„æµ‹æ•ˆæœ
        y_pred = self.model.predict(X_test, num_iteration=self.model.best_iteration)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        corr = np.corrcoef(y_test, y_pred)[0, 1]
        
        return {
            'rmse': rmse,
            'correlation': corr,
            'predictions': y_pred,
            'actual': y_test,
            'features_test': X_test
        }

def prepare_simple_features(data, wind_col):
    """ä¸ºM1ç³»åˆ—å‡†å¤‡ç®€å•ç‰¹å¾ï¼ˆç›´æ¥é¢„æµ‹ï¼‰"""
    features = pd.DataFrame()
    
    features['wind_speed'] = data[wind_col]
    features['wind_speed_2'] = data[wind_col] ** 2
    features['wind_speed_3'] = data[wind_col] ** 3
    
    features['hour'] = data['datetime'].dt.hour
    features['month'] = data['datetime'].dt.month
    features['is_daytime'] = ((data['datetime'].dt.hour >= 6) & 
                             (data['datetime'].dt.hour < 18)).astype(int)
    
    features['wind_lag_1h'] = data[wind_col].shift(1)
    features['wind_lag_24h'] = data[wind_col].shift(24)
    
    features = features.fillna(method='bfill').fillna(method='ffill')
    
    return features

def train_simple_lightgbm(X_train, y_train, X_test, y_test):
    """è®­ç»ƒç®€å•LightGBMæ¨¡å‹ï¼ˆM1ç³»åˆ—ç”¨ï¼‰"""
    params = {
        'objective': 'regression',
        'metric': 'rmse',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.1,
        'verbose': -1,
        'random_state': RANDOM_STATE
    }
    
    train_data = lgb.Dataset(X_train, label=y_train)
    valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)
    
    model = lgb.train(
        params,
        train_data,
        valid_sets=[valid_data],
        num_boost_round=100,
        callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(0)]
    )
    
    return model

def create_three_way_split(data, indices_path, val_ratio=0.25):
    """åˆ›å»ºä¸¥æ ¼çš„ä¸‰åˆ†å‰²ï¼šè®­ç»ƒé›† â†’ è®­ç»ƒå­é›† + éªŒè¯é›†ï¼Œæµ‹è¯•é›†ä¿æŒä¸å˜"""
    
    # åŠ è½½åŸæœ‰çš„è®­ç»ƒæµ‹è¯•é›†åˆ’åˆ†
    with open(indices_path, 'r') as f:
        indices = json.load(f)
    
    original_train_indices = indices['train_indices']
    test_indices = indices['test_indices']
    
    # åœ¨åŸè®­ç»ƒé›†å†…éƒ¨å†åˆ†å‰²å‡ºéªŒè¯é›†
    train_size = len(original_train_indices)
    val_size = int(train_size * val_ratio)
    
    # æ—¶é—´åºåˆ—åˆ†å‰²ï¼šå–åŸè®­ç»ƒé›†çš„å25%ä½œä¸ºéªŒè¯é›†
    new_train_indices = original_train_indices[:-val_size]
    val_indices = original_train_indices[-val_size:]
    
    print(f"  ä¸‰åˆ†å‰²ç»“æœ:")
    print(f"    æ–°è®­ç»ƒé›†: {len(new_train_indices)} æ ·æœ¬")
    print(f"    éªŒè¯é›†:   {len(val_indices)} æ ·æœ¬") 
    print(f"    æµ‹è¯•é›†:   {len(test_indices)} æ ·æœ¬")
    
    return new_train_indices, val_indices, test_indices

def optimize_fusion_weights_on_validation(corrected_winds_dict, data, train_indices, val_indices):
    """åœ¨éªŒè¯é›†ä¸Šä¼˜åŒ–èåˆæƒé‡ï¼Œé¿å…æ•°æ®æ³„éœ²"""
    
    print("  ğŸ” åœ¨éªŒè¯é›†ä¸Šä¼˜åŒ–èåˆæƒé‡...")
    
    # å€™é€‰æƒé‡ç»„åˆ
    weight_candidates = [
        [0.25, 0.25, 0.25, 0.25],  # å‡ç­‰æƒé‡
        [0.30, 0.20, 0.30, 0.20],  # åå‘10m
        [0.20, 0.30, 0.20, 0.30],  # åå‘70m
        [0.40, 0.10, 0.40, 0.10],  # å¼ºåå‘10m
        [0.35, 0.15, 0.35, 0.15],  # ä¸­ç­‰åå‘10m
        [0.30, 0.15, 0.30, 0.25],  # æ··åˆç­–ç•¥1
        [0.25, 0.15, 0.35, 0.25],  # æ··åˆç­–ç•¥2
        [0.20, 0.15, 0.35, 0.30],  # GFSåå‘
        [0.35, 0.25, 0.25, 0.15],  # ECåå‘
    ]
    
    best_rmse = float('inf')
    best_weights = None
    validation_results = []
    
    keys = list(corrected_winds_dict.keys())
    
    for i, weights in enumerate(weight_candidates):
        try:
            # è®¡ç®—èåˆé£é€Ÿï¼ˆå®Œæ•´æ•°æ®é›†ï¼‰
            fused_wind = np.array([
                sum(weights[j] * corrected_winds_dict[keys[j]][idx] for j in range(len(keys)))
                for idx in range(len(data))
            ])
            
            # è®­ç»ƒåŠŸç‡é¢„æµ‹æ¨¡å‹ï¼ˆåªåœ¨è®­ç»ƒé›†ä¸Šï¼‰
            power_predictor = PowerPredictionModel()
            
            # å°†éªŒè¯é›†ç´¢å¼•æ˜ å°„ä¸ºç›¸å¯¹äºè®­ç»ƒé›†çš„ç´¢å¼•
            all_train_val_indices = train_indices + val_indices
            relative_train_indices = list(range(len(train_indices)))
            relative_val_indices = list(range(len(train_indices), len(train_indices) + len(val_indices)))
            
            # å‡†å¤‡è®­ç»ƒ+éªŒè¯çš„æ•°æ®
            train_val_fused = fused_wind[all_train_val_indices]
            train_val_data = data.iloc[all_train_val_indices].reset_index(drop=True)
            
            power_results = power_predictor.train(
                train_val_fused, train_val_data,
                relative_train_indices, 
                relative_val_indices
            )
            
            val_rmse = power_results['rmse']
            validation_results.append({
                'weights': weights,
                'val_rmse': val_rmse
            })
            
            if val_rmse < best_rmse:
                best_rmse = val_rmse
                best_weights = weights
                
        except Exception as e:
            print(f"    æƒé‡ç»„åˆ {weights} å¤±è´¥: {str(e)}")
            validation_results.append({
                'weights': weights,
                'val_rmse': float('inf'),
                'error': str(e)
            })
    
    print(f"    æœ€ä¼˜æƒé‡: {best_weights}")
    print(f"    éªŒè¯é›†æœ€ä½³RMSE: {best_rmse:.4f}")
    
    # æ˜¾ç¤ºå‰5ä¸ªæƒé‡çš„è¡¨ç°
    validation_results.sort(key=lambda x: x['val_rmse'])
    for i, result in enumerate(validation_results[:5]):
        if result['val_rmse'] != float('inf'):
            weights_str = [f"{w:.2f}" for w in result['weights']]
            print(f"      {i+1}. [{', '.join(weights_str)}] â†’ RMSE: {result['val_rmse']:.4f}")
    
    return best_weights, validation_results

def calculate_shap_weights(hour):
    """åŸºäºSHAPåˆ†æçš„æ˜¼å¤œæƒé‡ï¼ˆç”¨äºä¸¤é£é€Ÿèåˆï¼‰"""
    is_daytime = (6 <= hour < 18)
    if is_daytime:
        return [0.55, 0.45]  # [10mæƒé‡, 70mæƒé‡]
    else:
        return [0.61, 0.39]

def run_no_leakage_fusion_experiment(data_path, save_dir, indices_path, exp_config):
    """è¿è¡Œæ— æ•°æ®æ³„éœ²çš„èåˆè¯•éªŒ"""
    
    print(f"  ğŸ”’ æ— æ³„éœ²èåˆè¯•éªŒ: {exp_config['name']}")
    
    os.makedirs(save_dir, exist_ok=True)
    
    # åŠ è½½æ•°æ®
    data = pd.read_csv(data_path)
    data['datetime'] = pd.to_datetime(data['datetime'])
    
    # åŸºç¡€æ•°æ®æ¸…ç†
    data = data.dropna(subset=['power'])
    data = data[data['power'] >= 0]
    
    # æ¸…ç†æ‰€æœ‰éœ€è¦çš„é£é€Ÿæ•°æ®
    wind_configs = exp_config['wind_configs']
    all_required_cols = ['power']
    for config in wind_configs:
        source = config['source']
        height = config['height']
        all_required_cols.extend([f'{source}_wind_speed_{height}', f'obs_wind_speed_{height}'])
    
    data = data.dropna(subset=all_required_cols)
    for col in all_required_cols:
        if 'wind_speed' in col:
            data = data[(data[col] >= 0) & (data[col] <= 50)]
    
    data = data.sort_values('datetime').reset_index(drop=True)
    
    processing_log = []
    processing_log.append(f"æ— æ³„éœ²èåˆè¯•éªŒ: {exp_config['name']}")
    processing_log.append(f"æ•°æ®å¤§å°: {len(data)}")
    
    # åˆ›å»ºä¸¥æ ¼çš„ä¸‰åˆ†å‰²
    print("  âœ‚ï¸ åˆ›å»ºä¸‰åˆ†å‰²...")
    train_indices, val_indices, test_indices = create_three_way_split(data, indices_path)
    
    # ç¬¬ä¸€æ­¥ï¼šåœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒå„ä¸ªé£é€Ÿæ ¡æ­£æ¨¡å‹
    print("  ğŸ¯ ç¬¬ä¸€æ­¥ï¼šè®­ç»ƒé£é€Ÿæ ¡æ­£æ¨¡å‹ï¼ˆä»…è®­ç»ƒé›†ï¼‰...")
    
    corrected_winds = {}
    correction_stats = {}
    
    for config in wind_configs:
        source = config['source']
        height = config['height']
        key = f"{source}_{height}"
        
        wind_corrector = WindCorrectionModel(target_height=height, source=source)
        correction_stat = wind_corrector.train(data, train_indices)  # åªç”¨è®­ç»ƒé›†
        correction_stats[key] = correction_stat
        
        # å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œæ ¡æ­£
        corrected_winds[key] = wind_corrector.predict(data)
        
        processing_log.append(f"{key}æ ¡æ­£æ€§èƒ½(ä»…è®­ç»ƒé›†): RMSE={correction_stat['rmse']:.4f}")
    
    # ç¬¬äºŒæ­¥ï¼šåœ¨éªŒè¯é›†ä¸Šä¼˜åŒ–æƒé‡
    print("  ğŸ” ç¬¬äºŒæ­¥ï¼šéªŒè¯é›†æƒé‡ä¼˜åŒ–...")
    
    optimal_weights, weight_search_results = optimize_fusion_weights_on_validation(
        corrected_winds, data, train_indices, val_indices
    )
    
    processing_log.append(f"æƒé‡ä¼˜åŒ–: æµ‹è¯•äº†{len(weight_search_results)}ç»„æƒé‡")
    processing_log.append(f"æœ€ä¼˜æƒé‡: EC-10m({optimal_weights[0]:.3f}), EC-70m({optimal_weights[1]:.3f})")
    processing_log.append(f"         GFS-10m({optimal_weights[2]:.3f}), GFS-70m({optimal_weights[3]:.3f})")
    
    # ç¬¬ä¸‰æ­¥ï¼šç”¨æœ€ä¼˜æƒé‡åœ¨è®­ç»ƒ+éªŒè¯é›†ä¸Šé‡æ–°è®­ç»ƒï¼Œåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
    print("  âš¡ ç¬¬ä¸‰æ­¥ï¼šæœ€ç»ˆæ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•é›†è¯„ä¼°...")
    
    keys = list(corrected_winds.keys())
    
    # ç”¨æœ€ä¼˜æƒé‡è®¡ç®—èåˆé£é€Ÿ
    fused_wind = np.array([
        sum(optimal_weights[i] * corrected_winds[keys[i]][idx] for i in range(len(keys)))
        for idx in range(len(data))
    ])
    
    # ä½¿ç”¨è®­ç»ƒ+éªŒè¯é›†è®­ç»ƒæœ€ç»ˆåŠŸç‡é¢„æµ‹æ¨¡å‹
    combined_train_indices = train_indices + val_indices
    
    power_predictor = PowerPredictionModel()
    power_results = power_predictor.train(
        fused_wind, data, 
        combined_train_indices, 
        test_indices
    )
    
    rmse = power_results['rmse']
    corr = power_results['correlation']
    y_pred = power_results['predictions']
    y_test = power_results['actual']
    
    processing_log.append(f"æœ€ç»ˆæµ‹è¯•æ€§èƒ½: RMSE={rmse:.4f}, ç›¸å…³ç³»æ•°={corr:.4f}")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    detailed_results = pd.DataFrame({
        'datetime': data.iloc[test_indices]['datetime'].values,
        'actual_power': y_test,
        'predicted_power': y_pred,
        'fused_corrected_wind': fused_wind[test_indices],
        'error': y_pred - y_test,
        'abs_error': np.abs(y_pred - y_test)
    })
    
    # æ·»åŠ å„ä¸ªæ ¡æ­£åçš„é£é€Ÿå’Œæƒé‡
    for i, key in enumerate(keys):
        detailed_results[f'corrected_{key}'] = corrected_winds[key][test_indices]
        detailed_results[f'weight_{key}'] = optimal_weights[i]
    
    detailed_results.to_csv(os.path.join(save_dir, f'{exp_config["name"]}_detailed_results.csv'), index=False)
    
    # ä¿å­˜å¤„ç†æ—¥å¿—
    process_log = {
        'experiment_name': exp_config['name'],
        'experiment_config': exp_config,
        'data_split': {
            'train_size': len(train_indices),
            'val_size': len(val_indices),
            'test_size': len(test_indices)
        },
        'processing_log': processing_log,
        'weight_optimization': weight_search_results,
        'optimal_weights': {
            'ec_10m': optimal_weights[0],
            'ec_70m': optimal_weights[1], 
            'gfs_10m': optimal_weights[2],
            'gfs_70m': optimal_weights[3]
        },
        'correction_stats': correction_stats,
        'final_performance': {'rmse': rmse, 'correlation': corr}
    }
    
    with open(os.path.join(save_dir, f'{exp_config["name"]}_process_log.json'), 'w') as f:
        json.dump(process_log, f, indent=2, default=str)
    
    # ä¿å­˜æŒ‡æ ‡
    metrics = {'RMSE': rmse, 'Correlation': corr}
    with open(os.path.join(save_dir, f'{exp_config["name"]}_metrics.json'), 'w') as f:
        json.dump(metrics, f, indent=2)
    
    print(f"  âœ… æ— æ³„éœ²è¯•éªŒå®Œæˆ! RMSE: {rmse:.4f}, ç›¸å…³ç³»æ•°: {corr:.4f}")
    
    return metrics

def calculate_performance_based_weights():
    """åŸºäºå®é™…è¯•éªŒç»“æœçš„æ€§èƒ½æƒé‡åˆ†é…"""
    
    # åŸºäºå®é™…M1å’ŒM2ç³»åˆ—è¯•éªŒç»“æœ (RMSEè¶Šå°è¶Šå¥½ï¼Œæƒé‡è¶Šé«˜)
    performance_data = {
        'ec_10m': 33.1672,   # E-M1-10mæ€§èƒ½
        'ec_70m': 33.3369,   # E-M1-70mæ€§èƒ½  
        'gfs_10m': 33.7579,  # G-M1-10mæ€§èƒ½
        'gfs_70m': 34.2257   # G-M1-70mæ€§èƒ½
    }
    
    # å¯¹äºæ ¡æ­£æ¨¡å‹ï¼Œä½¿ç”¨ä¸¤æ­¥æ³•çš„æ€§èƒ½
    corrected_performance = {
        'ec_10m_corrected': 33.1708,   # E-M2-10mæ€§èƒ½
        'ec_70m_corrected': 33.8399,   # E-M2-70mæ€§èƒ½
        'gfs_10m_corrected': 32.9289,  # G-M2-10mæ€§èƒ½ 
        'gfs_70m_corrected': 32.6539   # G-M2-70mæ€§èƒ½ (æœ€å¥½!)
    }
    
    # è®¡ç®—æ€§èƒ½æƒé‡ (RMSEçš„å€’æ•°ï¼Œæ€§èƒ½è¶Šå¥½æƒé‡è¶Šé«˜)
    performance_scores = {}
    for key, rmse in corrected_performance.items():
        performance_scores[key] = 1.0 / rmse
    
    # å½’ä¸€åŒ–æƒé‡
    total_score = sum(performance_scores.values())
    normalized_weights = {key: score/total_score for key, score in performance_scores.items()}
    
    # æŒ‰é¡ºåºè¿”å›ï¼šEC-10m, EC-70m, GFS-10m, GFS-70m
    weights = [
        normalized_weights['ec_10m_corrected'],
        normalized_weights['ec_70m_corrected'], 
        normalized_weights['gfs_10m_corrected'],
        normalized_weights['gfs_70m_corrected']
    ]
    
    return weights

def calculate_adaptive_performance_weights(hour):
    """åŸºäºè¯•éªŒç»“æœçš„æ—¶é—´è‡ªé€‚åº”æƒé‡"""
    
    # åŸºç¡€æ€§èƒ½æƒé‡
    base_weights = calculate_performance_based_weights()
    
    is_daytime = (6 <= hour < 18)
    
    if is_daytime:
        # ç™½å¤©ï¼šæ ¹æ®SHAPåˆ†æï¼Œç¨å¾®å¢åŠ 10mæƒé‡
        adjustment_factors = [1.1, 0.9, 1.1, 0.9]  # å¢åŠ 10mï¼Œå‡å°‘70m
    else:
        # å¤œé—´ï¼šæ›´åŠ åå‘10m
        adjustment_factors = [1.2, 0.8, 1.2, 0.8]
    
    # åº”ç”¨è°ƒæ•´å› å­
    adjusted_weights = [base_weights[i] * adjustment_factors[i] for i in range(4)]
    
    # é‡æ–°å½’ä¸€åŒ–
    total = sum(adjusted_weights)
    final_weights = [w/total for w in adjusted_weights]
    
    return final_weights

def calculate_simple_optimal_weights():
    """åŸºäºè¯•éªŒç»“æœçš„ç®€åŒ–æœ€ä¼˜æƒé‡"""
    
    # ç›´æ¥åŸºäºå„æ¨¡å‹çš„RMSEè¡¨ç°åˆ†é…æƒé‡
    # G-M2-70mè¡¨ç°æœ€å¥½(32.6539)ï¼Œåº”è¯¥ç»™æœ€é«˜æƒé‡
    # G-M2-10mæ¬¡ä¹‹(32.9289) 
    # E-M2-10mç¬¬ä¸‰(33.1708)
    # E-M2-70mæœ€å·®(33.8399)
    
    # ç®€åŒ–ç­–ç•¥ï¼šç»™è¡¨ç°å¥½çš„æ›´é«˜æƒé‡
    weights = [
        0.25,  # EC-10m (ä¸­ç­‰è¡¨ç°)
        0.15,  # EC-70m (è¾ƒå·®è¡¨ç°) 
        0.30,  # GFS-10m (è¾ƒå¥½è¡¨ç°)
        0.30   # GFS-70m (æœ€å¥½è¡¨ç°)
    ]
    
    return weights

def load_train_test_split(indices_path):
    """åŠ è½½è®­ç»ƒæµ‹è¯•é›†åˆ’åˆ†"""
    with open(indices_path, 'r') as f:
        indices = json.load(f)
    return indices['train_indices'], indices['test_indices']

def run_experiment(data_path, save_dir, indices_path, exp_config):
    """è¿è¡Œå•ä¸ªè¯•éªŒ"""
    
    print(f"\n{'='*60}")
    print(f"ğŸ”¬ è¯•éªŒ: {exp_config['name']}")
    print(f"ğŸ“ {exp_config['description']}")
    print(f"{'='*60}")
    
    os.makedirs(save_dir, exist_ok=True)
    
    # åŠ è½½æ•°æ®
    print("  ğŸ“‚ åŠ è½½æ•°æ®...")
    data = pd.read_csv(data_path)
    data['datetime'] = pd.to_datetime(data['datetime'])
    
    # åŸºç¡€æ•°æ®æ¸…ç†
    data = data.dropna(subset=['power'])
    data = data[data['power'] >= 0]
    data = data.sort_values('datetime').reset_index(drop=True)
    
    # è·å–è®­ç»ƒæµ‹è¯•é›†åˆ’åˆ†
    train_indices, test_indices = load_train_test_split(indices_path)
    
    processing_log = []
    processing_log.append(f"è¯•éªŒç±»å‹: {exp_config['type']}")
    processing_log.append(f"æ•°æ®å¤§å°: {len(data)}")
    
    try:
        if exp_config['type'] == 'no_leakage_fusion':
            # æ— æ•°æ®æ³„éœ²çš„èåˆè¯•éªŒ
            return run_no_leakage_fusion_experiment(data_path, save_dir, indices_path, exp_config)
        
        elif exp_config['type'] == 'direct':
            # M1ç³»åˆ—ï¼šç›´æ¥é¢„æµ‹
            wind_col = exp_config['wind_col']
            processing_log.append(f"ç›´æ¥é¢„æµ‹é£é€Ÿåˆ—: {wind_col}")
            
            # æ¸…ç†é£é€Ÿæ•°æ®
            data = data.dropna(subset=[wind_col])
            data = data[(data[wind_col] >= 0) & (data[wind_col] <= 50)]
            
            # é‡æ–°è·å–æœ‰æ•ˆç´¢å¼•
            valid_indices = data.index.tolist()
            train_indices = [i for i in train_indices if i in valid_indices]
            test_indices = [i for i in test_indices if i in valid_indices]
            
            # å‡†å¤‡ç‰¹å¾å’Œè®­ç»ƒæ¨¡å‹
            features = prepare_simple_features(data, wind_col)
            target = data['power'].values
            
            X_train = features.iloc[train_indices]
            X_test = features.iloc[test_indices]
            y_train = target[train_indices]
            y_test = target[test_indices]
            
            print("  ğŸš€ è®­ç»ƒç›´æ¥é¢„æµ‹æ¨¡å‹...")
            model = train_simple_lightgbm(X_train, y_train, X_test, y_test)
            
            y_pred = model.predict(X_test, num_iteration=model.best_iteration)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            corr = np.corrcoef(y_test, y_pred)[0, 1]
            
            processing_log.append(f"ç›´æ¥é¢„æµ‹æ€§èƒ½: RMSE={rmse:.4f}, ç›¸å…³ç³»æ•°={corr:.4f}")
            
            # ä¿å­˜ç»“æœ
            detailed_results = pd.DataFrame({
                'datetime': data.iloc[test_indices]['datetime'].values,
                'actual_power': y_test,
                'predicted_power': y_pred,
                'wind_speed': data.iloc[test_indices][wind_col].values,
                'error': y_pred - y_test,
                'abs_error': np.abs(y_pred - y_test)
            })
            
            # æ·»åŠ ç‰¹å¾
            for i, col in enumerate(features.columns):
                detailed_results[f'feature_{col}'] = X_test.iloc[:, i].values
            
        elif exp_config['type'] == 'two_step':
            # M2ç³»åˆ—ï¼šä¸¤æ­¥æ³•æ ¡æ­£
            wind_source = exp_config['wind_source']
            wind_height = exp_config['wind_height']
            
            processing_log.append(f"ä¸¤æ­¥æ³•æ ¡æ­£: {wind_source.upper()}-{wind_height}")
            
            # æ¸…ç†æ•°æ®
            required_cols = [f'{wind_source}_wind_speed_{wind_height}', f'obs_wind_speed_{wind_height}']
            data = data.dropna(subset=required_cols)
            for col in required_cols:
                data = data[(data[col] >= 0) & (data[col] <= 50)]
            
            # é‡æ–°è·å–æœ‰æ•ˆç´¢å¼•
            valid_indices = data.index.tolist()
            train_indices = [i for i in train_indices if i in valid_indices]
            test_indices = [i for i in test_indices if i in valid_indices]
            
            # ç¬¬ä¸€æ­¥ï¼šé£é€Ÿæ ¡æ­£
            print("  ğŸ¯ ç¬¬ä¸€æ­¥ï¼šé£é€Ÿæ ¡æ­£...")
            wind_corrector = WindCorrectionModel(target_height=wind_height, source=wind_source)
            correction_stats = wind_corrector.train(data, train_indices)
            
            corrected_wind = wind_corrector.predict(data)
            processing_log.append(f"é£é€Ÿæ ¡æ­£æ€§èƒ½: RMSE={correction_stats['rmse']:.4f}")
            
            # ç¬¬äºŒæ­¥ï¼šåŠŸç‡é¢„æµ‹
            print("  âš¡ ç¬¬äºŒæ­¥ï¼šåŠŸç‡é¢„æµ‹...")
            power_predictor = PowerPredictionModel()
            power_results = power_predictor.train(corrected_wind, data, train_indices, test_indices)
            
            processing_log.append(f"åŠŸç‡é¢„æµ‹æ€§èƒ½: RMSE={power_results['rmse']:.4f}")
            
            rmse = power_results['rmse']
            corr = power_results['correlation']
            y_pred = power_results['predictions']
            y_test = power_results['actual']
            
            # ä¿å­˜ç»“æœ
            detailed_results = pd.DataFrame({
                'datetime': data.iloc[test_indices]['datetime'].values,
                'actual_power': y_test,
                'predicted_power': y_pred,
                'corrected_wind': corrected_wind[test_indices],
                'original_wind': data.iloc[test_indices][f'{wind_source}_wind_speed_{wind_height}'].values,
                'observed_wind': data.iloc[test_indices][f'obs_wind_speed_{wind_height}'].values,
                'error': y_pred - y_test,
                'abs_error': np.abs(y_pred - y_test)
            })
            
        elif exp_config['type'] == 'fusion':
            # M3å’ŒFusionç³»åˆ—ï¼šå¤šé£é€Ÿèåˆ
            wind_configs = exp_config['wind_configs']
            fusion_strategy = exp_config['fusion_strategy']
            
            processing_log.append(f"èåˆç­–ç•¥: {fusion_strategy}")
            processing_log.append(f"é£é€Ÿé…ç½®: {wind_configs}")
            
            # æ¸…ç†æ‰€æœ‰éœ€è¦çš„é£é€Ÿæ•°æ®
            all_required_cols = ['power']
            for config in wind_configs:
                source = config['source']
                height = config['height']
                all_required_cols.extend([f'{source}_wind_speed_{height}'])
                if exp_config['type'] == 'fusion' and fusion_strategy != 'direct':
                    all_required_cols.append(f'obs_wind_speed_{height}')
            
            data = data.dropna(subset=all_required_cols)
            for col in all_required_cols:
                if 'wind_speed' in col:
                    data = data[(data[col] >= 0) & (data[col] <= 50)]
            
            # é‡æ–°è·å–æœ‰æ•ˆç´¢å¼•
            valid_indices = data.index.tolist()
            train_indices = [i for i in train_indices if i in valid_indices]
            test_indices = [i for i in test_indices if i in valid_indices]
            
            if fusion_strategy == 'direct':
                # ç›´æ¥èåˆåŸå§‹é£é€Ÿ
                print("  ğŸ”— ç›´æ¥èåˆåŸå§‹é£é€Ÿ...")
                
                # è·å–æƒé‡
                if exp_config.get('weights'):
                    # å›ºå®šæƒé‡
                    weights = exp_config['weights']
                    fused_wind = np.zeros(len(data))
                    for i, config in enumerate(wind_configs):
                        source = config['source']
                        height = config['height']
                        wind_col = f'{source}_wind_speed_{height}'
                        fused_wind += weights[i] * data[wind_col].values
                    
                    processing_log.append(f"å›ºå®šæƒé‡: {weights}")
                    
                elif exp_config.get('adaptive_weights'):
                    # æ˜¼å¤œåŠ¨æ€æƒé‡
                    fused_wind = []
                    for idx, row in data.iterrows():
                        weights = calculate_shap_weights(row['datetime'].hour)
                        wind_values = [row[f"{config['source']}_wind_speed_{config['height']}"] 
                                     for config in wind_configs]
                        fused_value = sum(weights[i] * wind_values[i] for i in range(len(weights)))
                        fused_wind.append(fused_value)
                    fused_wind = np.array(fused_wind)
                    
                    processing_log.append("æ˜¼å¤œåŠ¨æ€æƒé‡èåˆ")
                
                # ä½¿ç”¨èåˆé£é€Ÿè®­ç»ƒåŠŸç‡é¢„æµ‹æ¨¡å‹
                power_predictor = PowerPredictionModel()
                power_results = power_predictor.train(fused_wind, data, train_indices, test_indices)
                
                rmse = power_results['rmse']
                corr = power_results['correlation']
                y_pred = power_results['predictions']
                y_test = power_results['actual']
                
                # ä¿å­˜ç»“æœ
                detailed_results = pd.DataFrame({
                    'datetime': data.iloc[test_indices]['datetime'].values,
                    'actual_power': y_test,
                    'predicted_power': y_pred,
                    'fused_wind': fused_wind[test_indices],
                    'error': y_pred - y_test,
                    'abs_error': np.abs(y_pred - y_test)
                })
                
                # æ·»åŠ åŸå§‹é£é€Ÿ
                for config in wind_configs:
                    source = config['source']
                    height = config['height']
                    wind_col = f'{source}_wind_speed_{height}'
                    detailed_results[f'original_{source}_{height}'] = data.iloc[test_indices][wind_col].values
                
            else:
                # æ ¡æ­£åèåˆ
                print("  ğŸ¯ å¤šé£é€Ÿæ ¡æ­£...")
                
                corrected_winds = {}
                correction_stats_all = {}
                
                # åˆ†åˆ«æ ¡æ­£æ¯ä¸ªé£é€Ÿ
                for config in wind_configs:
                    source = config['source']
                    height = config['height']
                    key = f"{source}_{height}"
                    
                    wind_corrector = WindCorrectionModel(target_height=height, source=source)
                    correction_stats = wind_corrector.train(data, train_indices)
                    correction_stats_all[key] = correction_stats
                    
                    corrected_winds[key] = wind_corrector.predict(data)
                    
                    processing_log.append(f"{key}æ ¡æ­£æ€§èƒ½: RMSE={correction_stats['rmse']:.4f}")
                
                # èåˆæ ¡æ­£åçš„é£é€Ÿ
                print("  ğŸ”— èåˆæ ¡æ­£åé£é€Ÿ...")
                
                if exp_config.get('weights'):
                    weights = exp_config['weights']
                    fused_wind = np.zeros(len(data))
                    for i, key in enumerate(corrected_winds.keys()):
                        fused_wind += weights[i] * corrected_winds[key]
                    
                elif exp_config.get('adaptive_weights'):
                    fused_wind = []
                    keys = list(corrected_winds.keys())
                    for idx, row in data.iterrows():
                        weights = calculate_shap_weights(row['datetime'].hour)
                        fused_value = sum(weights[i] * corrected_winds[keys[i]][idx] 
                                        for i in range(len(weights)))
                        fused_wind.append(fused_value)
                    fused_wind = np.array(fused_wind)
                
                elif fusion_strategy == 'performance_based':
                    # åŸºäºå®é™…è¯•éªŒç»“æœçš„æœ€ä¼˜æƒé‡èåˆ
                    fused_wind = []
                    keys = list(corrected_winds.keys())
                    
                    # è·å–åŸºäºæ€§èƒ½çš„æƒé‡
                    optimal_weights = calculate_simple_optimal_weights()
                    
                    processing_log.append("åŸºäºè¯•éªŒç»“æœçš„æ€§èƒ½æƒé‡èåˆ")
                    processing_log.append(f"æƒé‡åˆ†é…: EC-10m({optimal_weights[0]:.3f}), EC-70m({optimal_weights[1]:.3f})")
                    processing_log.append(f"         GFS-10m({optimal_weights[2]:.3f}), GFS-70m({optimal_weights[3]:.3f})")
                    processing_log.append("æƒé‡ä¾æ®: G-M2-70m(32.65)æœ€å¥½, G-M2-10m(32.93)æ¬¡ä¹‹")
                    
                    # ç®€å•é™æ€èåˆ - ä¸å†ä½¿ç”¨å¤æ‚çš„æ—¶é—´åŠ¨æ€
                    for idx in range(len(data)):
                        fused_value = sum(optimal_weights[i] * corrected_winds[keys[i]][idx] 
                                        for i in range(len(keys)))
                        fused_wind.append(fused_value)
                    
                    fused_wind = np.array(fused_wind)
                
                elif fusion_strategy == 'corrected':
                    # é»˜è®¤å›ºå®šæƒé‡èåˆ
                    weights = exp_config.get('weights', [0.4, 0.2, 0.3, 0.1])
                    fused_wind = np.zeros(len(data))
                    for i, key in enumerate(corrected_winds.keys()):
                        fused_wind += weights[i] * corrected_winds[key]
                
                # åŠŸç‡é¢„æµ‹
                print("  âš¡ åŠŸç‡é¢„æµ‹...")
                power_predictor = PowerPredictionModel()
                power_results = power_predictor.train(fused_wind, data, train_indices, test_indices)
                
                rmse = power_results['rmse']
                corr = power_results['correlation']
                y_pred = power_results['predictions']
                y_test = power_results['actual']
                
                # ä¿å­˜ç»“æœ
                detailed_results = pd.DataFrame({
                    'datetime': data.iloc[test_indices]['datetime'].values,
                    'actual_power': y_test,
                    'predicted_power': y_pred,
                    'fused_corrected_wind': fused_wind[test_indices],
                    'error': y_pred - y_test,
                    'abs_error': np.abs(y_pred - y_test)
                })
                
                # æ·»åŠ å„ä¸ªæ ¡æ­£åçš„é£é€Ÿ
                for key, wind_values in corrected_winds.items():
                    detailed_results[f'corrected_{key}'] = wind_values[test_indices]
        
        print(f"  âœ… å®Œæˆ! RMSE: {rmse:.4f}, ç›¸å…³ç³»æ•°: {corr:.4f}")
        
        # ä¿å­˜æ‰€æœ‰ç»“æœæ–‡ä»¶
        detailed_results.to_csv(os.path.join(save_dir, f'{exp_config["name"]}_detailed_results.csv'), index=False)
        
        # ä¿å­˜å¤„ç†æ—¥å¿—
        process_log = {
            'experiment_name': exp_config['name'],
            'experiment_config': exp_config,
            'processing_log': processing_log,
            'final_performance': {'rmse': rmse, 'correlation': corr}
        }
        
        with open(os.path.join(save_dir, f'{exp_config["name"]}_process_log.json'), 'w') as f:
            json.dump(process_log, f, indent=2, default=str)
        
        # ä¿å­˜æŒ‡æ ‡
        metrics = {'RMSE': rmse, 'Correlation': corr}
        with open(os.path.join(save_dir, f'{exp_config["name"]}_metrics.json'), 'w') as f:
            json.dump(metrics, f, indent=2)
        
        return metrics
        
    except Exception as e:
        print(f"  âŒ å¤±è´¥: {str(e)}")
        return {'RMSE': None, 'Correlation': None, 'error': str(e)}

def run_all_14_experiments(data_path, base_save_dir, indices_path):
    """è¿è¡Œå®Œæ•´çš„14ä¸ªè¯•éªŒ"""
    
    print("=" * 80)
    print("ğŸš€ å¼€å§‹è¿è¡Œå®Œæ•´çš„14ä¸ªä¸¤æ­¥æ³•MLè¯•éªŒ")
    print("=" * 80)
    
    # å®šä¹‰æ‰€æœ‰14ä¸ªè¯•éªŒé…ç½®
    experiments = [
        # M1ç³»åˆ—ï¼šç›´æ¥é¢„æµ‹
        {
            'name': 'G-M1-10m',
            'description': 'GFSåŸå§‹10mé£é€Ÿç›´æ¥é¢„æµ‹åŠŸç‡',
            'type': 'direct',
            'wind_col': 'gfs_wind_speed_10m'
        },
        {
            'name': 'G-M1-70m', 
            'description': 'GFSåŸå§‹70mé£é€Ÿç›´æ¥é¢„æµ‹åŠŸç‡',
            'type': 'direct',
            'wind_col': 'gfs_wind_speed_70m'
        },
        {
            'name': 'E-M1-10m',
            'description': 'ECåŸå§‹10mé£é€Ÿç›´æ¥é¢„æµ‹åŠŸç‡', 
            'type': 'direct',
            'wind_col': 'ec_wind_speed_10m'
        },
        {
            'name': 'E-M1-70m',
            'description': 'ECåŸå§‹70mé£é€Ÿç›´æ¥é¢„æµ‹åŠŸç‡',
            'type': 'direct', 
            'wind_col': 'ec_wind_speed_70m'
        },
        
        # M2ç³»åˆ—ï¼šä¸¤æ­¥æ³•MLæ ¡æ­£
        {
            'name': 'G-M2-10m',
            'description': 'GFS 10mé£é€Ÿä¸¤æ­¥æ³•MLæ ¡æ­£',
            'type': 'two_step',
            'wind_source': 'gfs',
            'wind_height': '10m'
        },
        {
            'name': 'G-M2-70m',
            'description': 'GFS 70mé£é€Ÿä¸¤æ­¥æ³•MLæ ¡æ­£',
            'type': 'two_step',
            'wind_source': 'gfs', 
            'wind_height': '70m'
        },
        {
            'name': 'E-M2-10m',
            'description': 'EC 10mé£é€Ÿä¸¤æ­¥æ³•MLæ ¡æ­£',
            'type': 'two_step',
            'wind_source': 'ec',
            'wind_height': '10m'
        },
        {
            'name': 'E-M2-70m',
            'description': 'EC 70mé£é€Ÿä¸¤æ­¥æ³•MLæ ¡æ­£', 
            'type': 'two_step',
            'wind_source': 'ec',
            'wind_height': '70m'
        },
        
        # M3ç³»åˆ—ï¼šå¤šé£é€Ÿèåˆ
        {
            'name': 'G-M3-Fixed',
            'description': 'GFSå›ºå®šæƒé‡èåˆ(åŸºäºSHAP)',
            'type': 'fusion',
            'wind_configs': [
                {'source': 'gfs', 'height': '10m'},
                {'source': 'gfs', 'height': '70m'}
            ],
            'fusion_strategy': 'direct',
            'weights': [0.5, 0.5]
        },
        {
            'name': 'G-M3-TimeAdaptive',
            'description': 'GFSæ˜¼å¤œåŠ¨æ€æƒé‡èåˆ(åŸºäºSHAP)',
            'type': 'fusion',
            'wind_configs': [
                {'source': 'gfs', 'height': '10m'},
                {'source': 'gfs', 'height': '70m'}
            ],
            'fusion_strategy': 'direct',
            'adaptive_weights': True
        },
        {
            'name': 'E-M3-Fixed',
            'description': 'ECå›ºå®šæƒé‡èåˆ(åŸºäºSHAP)', 
            'type': 'fusion',
            'wind_configs': [
                {'source': 'ec', 'height': '10m'},
                {'source': 'ec', 'height': '70m'}
            ],
            'fusion_strategy': 'direct',
            'weights': [0.5, 0.5]
        },
        {
            'name': 'E-M3-TimeAdaptive',
            'description': 'ECæ˜¼å¤œåŠ¨æ€æƒé‡èåˆ(åŸºäºSHAP)',
            'type': 'fusion',
            'wind_configs': [
                {'source': 'ec', 'height': '10m'},
                {'source': 'ec', 'height': '70m'}
            ],
            'fusion_strategy': 'direct', 
            'adaptive_weights': True
        },
        
        # Fusionç³»åˆ—ï¼šè·¨æ¨¡å¼èåˆ
        {
            'name': 'Fusion-M1',
            'description': 'è”åˆæ ¡æ­£åé™æ€èåˆ',
            'type': 'fusion',
            'wind_configs': [
                {'source': 'ec', 'height': '10m'},
                {'source': 'ec', 'height': '70m'},
                {'source': 'gfs', 'height': '10m'},
                {'source': 'gfs', 'height': '70m'}
            ],
            'fusion_strategy': 'corrected',
            'weights': [0.25, 0.25, 0.25, 0.25]  # ECä¸»å¯¼ï¼Œ10mé‡è¦
        },
        {
            'name': 'Fusion-M2',
            'description': 'MLæ ¡æ­£åæ— æ•°æ®æ³„éœ²çš„æƒé‡ä¼˜åŒ–èåˆ',
            'type': 'no_leakage_fusion',
            'wind_configs': [
                {'source': 'ec', 'height': '10m'},
                {'source': 'ec', 'height': '70m'},
                {'source': 'gfs', 'height': '10m'},
                {'source': 'gfs', 'height': '70m'}
            ]
        }
    ]
    
    # å­˜å‚¨æ‰€æœ‰ç»“æœ
    all_results = []
    
    for i, exp_config in enumerate(experiments, 1):
        print(f"\nè¿›åº¦: {i}/14")
        
        try:
            # è¿è¡Œå•ä¸ªè¯•éªŒ
            save_dir = os.path.join(base_save_dir, exp_config['name'])
            metrics = run_experiment(data_path, save_dir, indices_path, exp_config)
            
            # è®°å½•ç»“æœ
            result = {
                'experiment': exp_config['name'],
                'description': exp_config['description'],
                'type': exp_config['type'],
                'RMSE': metrics.get('RMSE'),
                'Correlation': metrics.get('Correlation')
            }
            
            if 'error' in metrics:
                result['error'] = metrics['error']
            
            all_results.append(result)
            
        except Exception as e:
            print(f"âŒ {exp_config['name']} è¯•éªŒå¤±è´¥: {str(e)}")
            result = {
                'experiment': exp_config['name'],
                'description': exp_config['description'],
                'type': exp_config['type'],
                'RMSE': None,
                'Correlation': None,
                'error': str(e)
            }
            all_results.append(result)
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    create_comprehensive_summary(all_results, base_save_dir)
    
    print(f"\n{'='*80}")
    print(f"ğŸ‰ æ‰€æœ‰14ä¸ªè¯•éªŒå®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {base_save_dir}")
    print(f"ğŸ“Š æ±‡æ€»æŠ¥å‘Š: {base_save_dir}/comprehensive_summary.csv")
    print(f"{'='*80}")
    
    return all_results

def create_comprehensive_summary(all_results, base_save_dir):
    """åˆ›å»ºç»¼åˆæ±‡æ€»æŠ¥å‘Š"""
    
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(all_results)
    
    # æŒ‰RMSEæ’åºï¼ˆåªåŒ…å«æœ‰æ•ˆç»“æœï¼‰
    df_valid = df[df['RMSE'].notna()].copy()
    df_valid = df_valid.sort_values('RMSE')
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    df.to_csv(os.path.join(base_save_dir, 'comprehensive_summary.csv'), index=False)
    
    # åˆ›å»ºæ’åæŠ¥å‘Š
    print(f"\nğŸ“Š å®Œæ•´è¯•éªŒç»“æœæ’å (æŒ‰RMSEæ’åº):")
    print(f"{'æ’å':<4} {'è¯•éªŒåç§°':<20} {'ç±»å‹':<12} {'RMSE':<10} {'ç›¸å…³ç³»æ•°':<10} {'æè¿°'}")
    print(f"-" * 95)
    
    for i, (_, row) in enumerate(df_valid.iterrows(), 1):
        print(f"{i:<4} {row['experiment']:<20} {row['type']:<12} {row['RMSE']:<10.4f} {row['Correlation']:<10.4f} {row['description']}")
    
    # æŒ‰ç±»å‹åˆ†æ
    print(f"\nğŸ“ˆ æŒ‰è¯•éªŒç±»å‹åˆ†æ:")
    
    type_analysis = {}
    for exp_type in ['direct', 'two_step', 'fusion']:
        type_data = df_valid[df_valid['type'] == exp_type]
        if len(type_data) > 0:
            type_analysis[exp_type] = {
                'count': len(type_data),
                'best_rmse': type_data['RMSE'].min(),
                'best_experiment': type_data.loc[type_data['RMSE'].idxmin(), 'experiment'],
                'avg_rmse': type_data['RMSE'].mean(),
                'avg_correlation': type_data['Correlation'].mean()
            }
            
            print(f"  {exp_type.upper()}ç±»å‹:")
            print(f"    è¯•éªŒæ•°é‡: {type_analysis[exp_type]['count']}")
            print(f"    æœ€ä½³RMSE: {type_analysis[exp_type]['best_rmse']:.4f} ({type_analysis[exp_type]['best_experiment']})")
            print(f"    å¹³å‡RMSE: {type_analysis[exp_type]['avg_rmse']:.4f}")
            print(f"    å¹³å‡ç›¸å…³ç³»æ•°: {type_analysis[exp_type]['avg_correlation']:.4f}")
    
    # æ•°æ®æºå¯¹æ¯”
    print(f"\nğŸ” æ•°æ®æºå¯¹æ¯”:")
    
    # GFS vs ECå¯¹æ¯”
    gfs_experiments = df_valid[df_valid['experiment'].str.contains('G-')]
    ec_experiments = df_valid[df_valid['experiment'].str.contains('E-')]
    
    if len(gfs_experiments) > 0 and len(ec_experiments) > 0:
        print(f"  GFSç³»åˆ— (å¹³å‡RMSE: {gfs_experiments['RMSE'].mean():.4f})")
        print(f"  ECç³»åˆ—  (å¹³å‡RMSE: {ec_experiments['RMSE'].mean():.4f})")
        
        if gfs_experiments['RMSE'].mean() < ec_experiments['RMSE'].mean():
            print(f"  â†’ GFSæ•´ä½“è¡¨ç°æ›´å¥½")
        else:
            print(f"  â†’ ECæ•´ä½“è¡¨ç°æ›´å¥½")
    
    # 10m vs 70må¯¹æ¯”
    m10_experiments = df_valid[df_valid['experiment'].str.contains('10m')]
    m70_experiments = df_valid[df_valid['experiment'].str.contains('70m')]
    
    if len(m10_experiments) > 0 and len(m70_experiments) > 0:
        print(f"  10mé£é€Ÿ (å¹³å‡RMSE: {m10_experiments['RMSE'].mean():.4f})")
        print(f"  70mé£é€Ÿ (å¹³å‡RMSE: {m70_experiments['RMSE'].mean():.4f})")
        
        if m10_experiments['RMSE'].mean() < m70_experiments['RMSE'].mean():
            print(f"  â†’ 10mé£é€Ÿæ•´ä½“è¡¨ç°æ›´å¥½")
        else:
            print(f"  â†’ 70mé£é€Ÿæ•´ä½“è¡¨ç°æ›´å¥½")
    
    # ä¿å­˜åˆ†ææŠ¥å‘Š
    with open(os.path.join(base_save_dir, 'analysis_summary.txt'), 'w') as f:
        f.write("14ä¸ªè¯•éªŒç»¼åˆåˆ†ææŠ¥å‘Š\n")
        f.write("="*50 + "\n\n")
        
        f.write("1. æ€»ä½“æ’å (æŒ‰RMSE):\n")
        for i, (_, row) in enumerate(df_valid.iterrows(), 1):
            f.write(f"{i}. {row['experiment']}: RMSE={row['RMSE']:.4f}, Corr={row['Correlation']:.4f}\n")
        
        f.write(f"\n2. æŒ‰ç±»å‹åˆ†æ:\n")
        for exp_type, stats in type_analysis.items():
            f.write(f"{exp_type.upper()}: æœ€ä½³RMSE={stats['best_rmse']:.4f} ({stats['best_experiment']})\n")
        
        f.write(f"\n3. ä¸»è¦å‘ç°:\n")
        if len(df_valid) > 0:
            best_overall = df_valid.iloc[0]
            f.write(f"- æœ€ä½³è¯•éªŒ: {best_overall['experiment']} (RMSE: {best_overall['RMSE']:.4f})\n")
            f.write(f"- æœ€ä½³ç­–ç•¥: {best_overall['description']}\n")
            
            # MLæ ¡æ­£æ•ˆæœåˆ†æ
            direct_avg = df_valid[df_valid['type'] == 'direct']['RMSE'].mean() if len(df_valid[df_valid['type'] == 'direct']) > 0 else None
            two_step_avg = df_valid[df_valid['type'] == 'two_step']['RMSE'].mean() if len(df_valid[df_valid['type'] == 'two_step']) > 0 else None
            
            if direct_avg and two_step_avg:
                improvement = (direct_avg - two_step_avg) / direct_avg * 100
                f.write(f"- MLæ ¡æ­£æ•ˆæœ: å¹³å‡æ”¹å–„ {improvement:.2f}%\n")
    
    # åˆ†ææœ€ä½³ç­–ç•¥
    if len(df_valid) > 0:
        best_result = df_valid.iloc[0]
        print(f"\nğŸ† æœ€ä½³è¯•éªŒ: {best_result['experiment']}")
        print(f"   RMSE: {best_result['RMSE']:.4f}")
        print(f"   ç›¸å…³ç³»æ•°: {best_result['Correlation']:.4f}")
        print(f"   ç­–ç•¥: {best_result['description']}")
        print(f"   ç±»å‹: {best_result['type']}")


def run_weight_comparison_experiments(data_path, base_save_dir, indices_path):
    """è¿è¡Œæƒé‡å¯¹æ¯”è¯•éªŒ"""
    
    print("=" * 80)
    print("ğŸ”¬ æƒé‡å¯¹æ¯”è¯•éªŒï¼šæµ‹è¯•ä¸åŒèåˆæƒé‡ç­–ç•¥")
    print("=" * 80)
    
    # å®šä¹‰ä¸åŒçš„æƒé‡ç­–ç•¥
    weight_strategies = [
        {
            'name': 'Fusion-Equal',
            'description': 'å››æ¨¡å‹ç­‰æƒé‡èåˆ (å„25%)',
            'type': 'fusion',
            'wind_configs': [
                {'source': 'ec', 'height': '10m'},
                {'source': 'ec', 'height': '70m'},
                {'source': 'gfs', 'height': '10m'},
                {'source': 'gfs', 'height': '70m'}
            ],
            'fusion_strategy': 'corrected',
            'weights': [0.25, 0.25, 0.25, 0.25]  # ç­‰æƒé‡
        },
        {
            'name': 'Fusion-Original',
            'description': 'åŸå§‹æƒé‡ (ECä¸»å¯¼)',
            'type': 'fusion',
            'wind_configs': [
                {'source': 'ec', 'height': '10m'},
                {'source': 'ec', 'height': '70m'},
                {'source': 'gfs', 'height': '10m'},
                {'source': 'gfs', 'height': '70m'}
            ],
            'fusion_strategy': 'corrected',
            'weights': [0.4, 0.2, 0.3, 0.1]  # åŸå§‹æƒé‡
        },
        {
            'name': 'Fusion-Performance',
            'description': 'åŸºäºå•æ¨¡å‹æ€§èƒ½çš„æƒé‡',
            'type': 'fusion',
            'wind_configs': [
                {'source': 'ec', 'height': '10m'},
                {'source': 'ec', 'height': '70m'},
                {'source': 'gfs', 'height': '10m'},
                {'source': 'gfs', 'height': '70m'}
            ],
            'fusion_strategy': 'corrected',
            # åŸºäºè¯•éªŒç»“æœï¼šG-M2-70m(32.65) > G-M2-10m(32.93) > E-M2-10m(33.17) > E-M2-70m(33.84)
            'weights': [0.25, 0.15, 0.30, 0.30]  # GFS-70mæœ€å¥½ç»™æœ€é«˜æƒé‡
        },
        {
            'name': 'Fusion-10m-Focus',
            'description': 'åå‘10mé«˜åº¦ (10må 70%)',
            'type': 'fusion',
            'wind_configs': [
                {'source': 'ec', 'height': '10m'},
                {'source': 'ec', 'height': '70m'},
                {'source': 'gfs', 'height': '10m'},
                {'source': 'gfs', 'height': '70m'}
            ],
            'fusion_strategy': 'corrected',
            'weights': [0.35, 0.15, 0.35, 0.15]  # 10må 70%
        },
        {
            'name': 'Fusion-EC-Focus',
            'description': 'ECä¸»å¯¼ç­–ç•¥ (ECå 70%)',
            'type': 'fusion',
            'wind_configs': [
                {'source': 'ec', 'height': '10m'},
                {'source': 'ec', 'height': '70m'},
                {'source': 'gfs', 'height': '10m'},
                {'source': 'gfs', 'height': '70m'}
            ],
            'fusion_strategy': 'corrected',
            'weights': [0.45, 0.25, 0.20, 0.10]  # ECå 70%
        },
        {
            'name': 'Fusion-GFS-Focus',
            'description': 'GFSä¸»å¯¼ç­–ç•¥ (GFSå 70%)',
            'type': 'fusion',
            'wind_configs': [
                {'source': 'ec', 'height': '10m'},
                {'source': 'ec', 'height': '70m'},
                {'source': 'gfs', 'height': '10m'},
                {'source': 'gfs', 'height': '70m'}
            ],
            'fusion_strategy': 'corrected',
            'weights': [0.15, 0.15, 0.35, 0.35]  # GFSå 70%
        }
    ]
    
    # å­˜å‚¨æ‰€æœ‰ç»“æœ
    comparison_results = []
    
    for i, exp_config in enumerate(weight_strategies, 1):
        print(f"\næƒé‡ç­–ç•¥ {i}/6: {exp_config['name']}")
        print(f"æƒé‡: {exp_config['weights']}")
        print(f"è¯´æ˜: {exp_config['description']}")
        
        try:
            # è¿è¡Œè¯•éªŒ
            save_dir = os.path.join(base_save_dir, 'weight_comparison', exp_config['name'])
            metrics = run_experiment(data_path, save_dir, indices_path, exp_config)
            
            # è®°å½•ç»“æœ
            result = {
                'strategy': exp_config['name'],
                'description': exp_config['description'],
                'weights': exp_config['weights'],
                'ec_10m_weight': exp_config['weights'][0],
                'ec_70m_weight': exp_config['weights'][1],
                'gfs_10m_weight': exp_config['weights'][2],
                'gfs_70m_weight': exp_config['weights'][3],
                'ec_total_weight': exp_config['weights'][0] + exp_config['weights'][1],
                'gfs_total_weight': exp_config['weights'][2] + exp_config['weights'][3],
                'm10_total_weight': exp_config['weights'][0] + exp_config['weights'][2],
                'm70_total_weight': exp_config['weights'][1] + exp_config['weights'][3],
                'RMSE': metrics.get('RMSE'),
                'Correlation': metrics.get('Correlation')
            }
            
            if 'error' in metrics:
                result['error'] = metrics['error']
            
            comparison_results.append(result)
            
            print(f"  ç»“æœ: RMSE={result['RMSE']:.4f}, ç›¸å…³ç³»æ•°={result['Correlation']:.4f}")
            
        except Exception as e:
            print(f"  âŒ å¤±è´¥: {str(e)}")
            result = {
                'strategy': exp_config['name'],
                'description': exp_config['description'],
                'weights': exp_config['weights'],
                'RMSE': None,
                'Correlation': None,
                'error': str(e)
            }
            comparison_results.append(result)
    
    # åˆ†æå’Œæ±‡æ€»ç»“æœ
    analyze_weight_comparison_results(comparison_results, base_save_dir)
    
    return comparison_results

def analyze_weight_comparison_results(results, base_save_dir):
    """åˆ†ææƒé‡å¯¹æ¯”ç»“æœ"""
    
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(results)
    
    # ä¿å­˜å®Œæ•´ç»“æœ
    os.makedirs(os.path.join(base_save_dir, 'weight_comparison'), exist_ok=True)
    df.to_csv(os.path.join(base_save_dir, 'weight_comparison', 'weight_comparison_results.csv'), index=False)
    
    # ç­›é€‰æœ‰æ•ˆç»“æœå¹¶æ’åº
    df_valid = df[df['RMSE'].notna()].copy()
    df_valid = df_valid.sort_values('RMSE')
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š æƒé‡ç­–ç•¥å¯¹æ¯”ç»“æœ (æŒ‰RMSEæ’åº)")
    print(f"{'='*80}")
    print(f"{'æ’å':<4} {'ç­–ç•¥åç§°':<20} {'RMSE':<10} {'ç›¸å…³ç³»æ•°':<8} {'æƒé‡åˆ†é…':<25} {'è¯´æ˜'}")
    print(f"-" * 100)
    
    for i, (_, row) in enumerate(df_valid.iterrows(), 1):
        weights_str = f"[{row['ec_10m_weight']:.2f},{row['ec_70m_weight']:.2f},{row['gfs_10m_weight']:.2f},{row['gfs_70m_weight']:.2f}]"
        print(f"{i:<4} {row['strategy']:<20} {row['RMSE']:<10.4f} {row['Correlation']:<8.4f} {weights_str:<25} {row['description']}")
    
    # åˆ†æä¸åŒæƒé‡ç­–ç•¥çš„æ•ˆæœ
    print(f"\nğŸ” æƒé‡ç­–ç•¥åˆ†æ:")
    
    if len(df_valid) > 0:
        best_strategy = df_valid.iloc[0]
        worst_strategy = df_valid.iloc[-1]
        
        print(f"  ğŸ† æœ€ä½³ç­–ç•¥: {best_strategy['strategy']}")
        print(f"     æƒé‡: EC-10m({best_strategy['ec_10m_weight']:.2f}), EC-70m({best_strategy['ec_70m_weight']:.2f})")
        print(f"          GFS-10m({best_strategy['gfs_10m_weight']:.2f}), GFS-70m({best_strategy['gfs_70m_weight']:.2f})")
        print(f"     RMSE: {best_strategy['RMSE']:.4f}")
        
        print(f"  ğŸ“‰ æœ€å·®ç­–ç•¥: {worst_strategy['strategy']}")
        print(f"     RMSE: {worst_strategy['RMSE']:.4f}")
        
        improvement = (worst_strategy['RMSE'] - best_strategy['RMSE']) / worst_strategy['RMSE'] * 100
        print(f"  ğŸ“ˆ æœ€ä¼˜vsæœ€å·®æ”¹å–„: {improvement:.2f}%")
        
        # ç­‰æƒé‡ç­–ç•¥çš„è¡¨ç°
        equal_weight = df_valid[df_valid['strategy'] == 'Fusion-Equal']
        if len(equal_weight) > 0:
            equal_result = equal_weight.iloc[0]
            equal_rank = list(df_valid['strategy']).index('Fusion-Equal') + 1
            print(f"  âš–ï¸ ç­‰æƒé‡ç­–ç•¥è¡¨ç°:")
            print(f"     æ’å: ç¬¬{equal_rank}å (å…±{len(df_valid)}ä¸ª)")
            print(f"     RMSE: {equal_result['RMSE']:.4f}")
            
            if equal_result['RMSE'] == best_strategy['RMSE']:
                print(f"     ğŸ¯ ç­‰æƒé‡ç­–ç•¥å°±æ˜¯æœ€ä¼˜ç­–ç•¥!")
            else:
                gap = (equal_result['RMSE'] - best_strategy['RMSE']) / best_strategy['RMSE'] * 100
                print(f"     ğŸ“Š ä¸æœ€ä¼˜ç­–ç•¥å·®è·: {gap:.2f}%")
    
    # EC vs GFS æƒé‡æ•ˆæœåˆ†æ
    print(f"\nğŸ”¬ EC vs GFS æƒé‡æ•ˆæœåˆ†æ:")
    
    for _, row in df_valid.iterrows():
        ec_weight = row['ec_total_weight'] 
        gfs_weight = row['gfs_total_weight']
        print(f"  {row['strategy']:<20} EC:{ec_weight:.2f} GFS:{gfs_weight:.2f} â†’ RMSE:{row['RMSE']:.4f}")
    
    # 10m vs 70m æƒé‡æ•ˆæœåˆ†æ  
    print(f"\nğŸŒªï¸ 10m vs 70m æƒé‡æ•ˆæœåˆ†æ:")
    
    for _, row in df_valid.iterrows():
        m10_weight = row['m10_total_weight']
        m70_weight = row['m70_total_weight'] 
        print(f"  {row['strategy']:<20} 10m:{m10_weight:.2f} 70m:{m70_weight:.2f} â†’ RMSE:{row['RMSE']:.4f}")
    
    # ä¿å­˜åˆ†ææŠ¥å‘Š
    with open(os.path.join(base_save_dir, 'weight_comparison', 'analysis_report.txt'), 'w', encoding='utf-8') as f:
        f.write("æƒé‡ç­–ç•¥å¯¹æ¯”åˆ†ææŠ¥å‘Š\n")
        f.write("="*50 + "\n\n")
        
        f.write("1. ç­–ç•¥æ’å:\n")
        for i, (_, row) in enumerate(df_valid.iterrows(), 1):
            f.write(f"{i}. {row['strategy']}: RMSE={row['RMSE']:.4f}, æƒé‡={row['weights']}\n")
        
        f.write(f"\n2. ä¸»è¦å‘ç°:\n")
        if len(df_valid) > 0:
            best = df_valid.iloc[0]
            f.write(f"- æœ€ä¼˜ç­–ç•¥: {best['strategy']} (RMSE: {best['RMSE']:.4f})\n")
            f.write(f"- æœ€ä¼˜æƒé‡: {best['weights']}\n")
            
            equal_weight = df_valid[df_valid['strategy'] == 'Fusion-Equal']
            if len(equal_weight) > 0:
                equal_rmse = equal_weight.iloc[0]['RMSE']
                f.write(f"- ç­‰æƒé‡è¡¨ç°: RMSE={equal_rmse:.4f}\n")
                
                if equal_rmse == best['RMSE']:
                    f.write(f"- ç»“è®º: ç­‰æƒé‡ç­–ç•¥å·²ç»æ˜¯æœ€ä¼˜çš„!\n")
                else:
                    gap = (equal_rmse - best['RMSE']) / best['RMSE'] * 100
                    f.write(f"- æƒé‡ä¼˜åŒ–å¸¦æ¥çš„æ”¹å–„: {gap:.2f}%\n")
# åœ¨åŸæœ‰çš„ test.py æ–‡ä»¶çš„ main éƒ¨åˆ†æ·»åŠ è¿™ä¸ªè°ƒç”¨
def run_weight_comparison_main():
    """æƒé‡å¯¹æ¯”è¯•éªŒçš„ä¸»å‡½æ•°"""
    
    # é…ç½®è·¯å¾„
    DATA_PATH = "/Users/xiaxin/work/WindForecast_Project/01_Data/processed/imputed_data/changma_imputed_complete.csv"
    BASE_SAVE_DIR = "/Users/xiaxin/work/WindForecast_Project/03_Results/weight_comparison_experiments"
    INDICES_PATH = "/Users/xiaxin/work/WindForecast_Project/03_Results/third_part_experiments/train_test_split.json"
    
    # è¿è¡Œæƒé‡å¯¹æ¯”è¯•éªŒ
    results = run_weight_comparison_experiments(DATA_PATH, BASE_SAVE_DIR, INDICES_PATH)
    
    print(f"\nğŸ’¡ æƒé‡å¯¹æ¯”è¯•éªŒå®Œæˆ!")
    print(f"ğŸ“Š ç°åœ¨ä½ çŸ¥é“ç­‰æƒé‡å’Œå…¶ä»–ç­–ç•¥çš„å¯¹æ¯”æ•ˆæœäº†!")



if __name__ == "__main__":
    # é…ç½®è·¯å¾„
    DATA_PATH = "/Users/xiaxin/work/WindForecast_Project/01_Data/processed/imputed_data/changma_imputed_complete.csv"
    BASE_SAVE_DIR = "/Users/xiaxin/work/WindForecast_Project/03_Results/complete_14_experiments"
    INDICES_PATH = "/Users/xiaxin/work/WindForecast_Project/03_Results/third_part_experiments/train_test_split.json"
    
    # è¿è¡Œæ‰€æœ‰14ä¸ªè¯•éªŒ
    results = run_all_14_experiments(DATA_PATH, BASE_SAVE_DIR, INDICES_PATH)
    # run_weight_comparison_main()
    print(f"\nğŸ’¡ å®Œæ•´çš„14ä¸ªè¯•éªŒç³»ç»Ÿè¿è¡Œå®Œæˆ!")
    print(f"\nğŸ”¬ è¯•éªŒåŒ…æ‹¬:")
    print(f"   M1ç³»åˆ— (4ä¸ª): ç›´æ¥é¢„æµ‹")
    print(f"   M2ç³»åˆ— (4ä¸ª): ä¸¤æ­¥æ³•MLæ ¡æ­£")  
    print(f"   M3ç³»åˆ— (4ä¸ª): å¤šé£é€Ÿèåˆ")
    print(f"   Fusionç³»åˆ— (2ä¸ª): è·¨æ¨¡å¼èåˆ (å…¶ä¸­Fusion-M2ä¸ºæ— æ•°æ®æ³„éœ²ç‰ˆæœ¬)")
    print(f"\nğŸ“Š ç°åœ¨å¯ä»¥å…¨é¢å¯¹æ¯”ä¸åŒç­–ç•¥çš„æ•ˆæœ!")
    print(f"   - å“ªç§æ–¹æ³•æœ€å¥½: ç›´æ¥é¢„æµ‹ vs MLæ ¡æ­£ vs èåˆ")
    print(f"   - å“ªä¸ªæ•°æ®æºæœ€å¥½: GFS vs EC")
    print(f"   - å“ªä¸ªé«˜åº¦æœ€å¥½: 10m vs 70m")
    print(f"   - å“ªç§èåˆç­–ç•¥æœ€å¥½: å›ºå®šæƒé‡ vs åŠ¨æ€æƒé‡ vs æ— æ³„éœ²æƒé‡ä¼˜åŒ–")