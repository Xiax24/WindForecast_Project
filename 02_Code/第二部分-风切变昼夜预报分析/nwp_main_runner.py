#!/usr/bin/env python3
"""
ÂÆûÁî®ÁâàÊï∞ÂÄºÈ¢ÑÊä•ËØÑ‰º∞Âô®
ÈáçÁÇπÂÖ≥Ê≥®ÔºöÁõ∏ÂÖ≥Á≥ªÊï∞„ÄÅÂÅèÂ∑Æ„ÄÅRMSE + Ê†∑Êú¨Êï∞ÊòæÁ§∫
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error
import os
import json
import warnings
warnings.filterwarnings('ignore')

# ËÆæÁΩÆËã±ÊñáÊòæÁ§∫
plt.rcParams['font.family'] = ['Arial', 'DejaVu Sans', 'Liberation Sans']
plt.rcParams['axes.unicode_minus'] = False

def practical_nwp_evaluation(data_path, save_path):
    """ÂÆûÁî®ÁâàÊï∞ÂÄºÈ¢ÑÊä•ËØÑ‰º∞ - ÈáçÁÇπÂÖ≥Ê≥®Áõ∏ÂÖ≥Á≥ªÊï∞„ÄÅÂÅèÂ∑Æ„ÄÅRMSE"""
    print("=" * 80)
    print("üì° ÂÆûÁî®ÁâàÊï∞ÂÄºÈ¢ÑÊä•ËØÑ‰º∞ÂàÜÊûê")
    print("ÈáçÁÇπÊåáÊ†áÔºöÁõ∏ÂÖ≥Á≥ªÊï∞„ÄÅÂÅèÂ∑Æ„ÄÅRMSE + Ê†∑Êú¨Êï∞")
    print("=" * 80)
    
    os.makedirs(save_path, exist_ok=True)
    
    # ÈÖçÁΩÆ
    shear_thresholds = {'weak_upper': 0.1, 'moderate_upper': 0.3}
    min_samples = 50
    min_valid_samples = 20
    
    key_variables = {
        'wind_speed_10m': {
            'obs': 'obs_wind_speed_10m', 'ec': 'ec_wind_speed_10m', 'gfs': 'gfs_wind_speed_10m', 
            'name': '10m Wind Speed', 'unit': 'm/s'
        },
        'wind_speed_70m': {
            'obs': 'obs_wind_speed_70m', 'ec': 'ec_wind_speed_70m', 'gfs': 'gfs_wind_speed_70m', 
            'name': '70m Wind Speed', 'unit': 'm/s'
        },
        'temperature_10m': {
            'obs': 'obs_temperature_10m', 'ec': 'ec_temperature_10m', 'gfs': 'gfs_temperature_10m', 
            'name': '10m Temperature', 'unit': '¬∞C'
        }
    }
    
    try:
        # 1. Êï∞ÊçÆÂä†ËΩΩÂíåÈ¢ÑÂ§ÑÁêÜÔºà‰∏é‰πãÂâçÁõ∏ÂêåÔºâ
        print("\nüîÑ Ê≠•È™§1: Âä†ËΩΩÊï∞ÊçÆ")
        data = pd.read_csv(data_path)
        data['datetime'] = pd.to_datetime(data['datetime'])
        print(f"ÂéüÂßãÊï∞ÊçÆÂΩ¢Áä∂: {data.shape}")
        
        # Êï∞ÊçÆÊ∏ÖÁêÜ
        for var_name, var_info in key_variables.items():
            for col_type in ['obs', 'ec', 'gfs']:
                col = var_info[col_type]
                if col in data.columns:
                    if 'wind_speed' in col:
                        data[col] = data[col].where((data[col] >= 0) & (data[col] <= 50))
                    elif 'temperature' in col:
                        data[col] = data[col].where((data[col] >= -50) & (data[col] <= 60))
        
        # È£éÂàáÂèòËÆ°ÁÆóÂíåÂàÜÁ±ª
        print("\nüîÑ Ê≠•È™§2: È£éÂàáÂèòËÆ°ÁÆóÂíåÂàÜÁ±ª")
        v1 = data['obs_wind_speed_10m']
        v2 = data['obs_wind_speed_70m']
        
        valid_wind_mask = (v1 > 0.5) & (v2 > 0.5) & (~v1.isna()) & (~v2.isna())
        data = data[valid_wind_mask].copy()
        
        data['wind_shear_alpha'] = np.log(data['obs_wind_speed_70m'] / data['obs_wind_speed_10m']) / np.log(70 / 10)
        
        alpha = data['wind_shear_alpha']
        valid_alpha = (~np.isnan(alpha)) & (~np.isinf(alpha)) & (alpha > -1) & (alpha < 2)
        data = data[valid_alpha].copy()
        
        # ÂàÜÁ±ª
        alpha = data['wind_shear_alpha']
        conditions = [
            alpha < shear_thresholds['weak_upper'],
            (alpha >= shear_thresholds['weak_upper']) & (alpha < shear_thresholds['moderate_upper']),
            alpha >= shear_thresholds['moderate_upper']
        ]
        choices = ['weak', 'moderate', 'strong']
        data['shear_group'] = np.select(conditions, choices, default='unknown')
        
        data['hour'] = data['datetime'].dt.hour
        data['is_daytime'] = ((data['hour'] >= 6) & (data['hour'] < 18))
        data['shear_diurnal_class'] = data['shear_group'].astype(str) + '_' + \
                                     data['is_daytime'].map({True: 'day', False: 'night'})
        
        class_counts = data['shear_diurnal_class'].value_counts()
        print(f"Wind shear classification distribution:")
        for class_name, count in class_counts.items():
            if 'unknown' not in class_name:
                percentage = count / len(data) * 100
                print(f"  {class_name}: {count} samples ({percentage:.1f}%)")
        
        # 3. ËÆ°ÁÆóÂÆûÁî®ËØÑ‰º∞ÊåáÊ†á
        print("\nüîÑ Ê≠•È™§3: ËÆ°ÁÆóÂÆûÁî®ËØÑ‰º∞ÊåáÊ†á")
        
        def calculate_practical_metrics(obs, forecast):
            """ËÆ°ÁÆóÂÆûÁî®ÊåáÊ†áÔºöÁõ∏ÂÖ≥Á≥ªÊï∞„ÄÅÂÅèÂ∑Æ„ÄÅRMSE"""
            obs = np.array(obs)
            forecast = np.array(forecast)
            valid_mask = ~(np.isnan(obs) | np.isnan(forecast) | np.isinf(obs) | np.isinf(forecast))
            obs_clean = obs[valid_mask]
            forecast_clean = forecast[valid_mask]
            
            if len(obs_clean) < min_valid_samples:
                return {'CORR': np.nan, 'BIAS': np.nan, 'RMSE': np.nan, 'MAE': np.nan, 'COUNT': len(obs_clean)}
            
            try:
                # Áõ∏ÂÖ≥Á≥ªÊï∞
                if len(obs_clean) > 1 and np.std(obs_clean) > 1e-10 and np.std(forecast_clean) > 1e-10:
                    corr = np.corrcoef(obs_clean, forecast_clean)[0, 1]
                else:
                    corr = np.nan
                
                # ÂÅèÂ∑Æ
                bias = np.mean(forecast_clean - obs_clean)
                
                # RMSE
                rmse = np.sqrt(mean_squared_error(obs_clean, forecast_clean))
                
                # MAE
                mae = mean_absolute_error(obs_clean, forecast_clean)
                
                return {'CORR': corr, 'BIAS': bias, 'RMSE': rmse, 'MAE': mae, 'COUNT': len(obs_clean)}
            except Exception as e:
                print(f"    ËÆ°ÁÆóÊåáÊ†áÈîôËØØ: {e}")
                return {'CORR': np.nan, 'BIAS': np.nan, 'RMSE': np.nan, 'MAE': np.nan, 'COUNT': len(obs_clean)}
        
        evaluation_results = {}
        unique_classes = [cls for cls in data['shear_diurnal_class'].unique() if 'unknown' not in cls]
        
        print(f"Starting evaluation of {len(unique_classes)} classifications...")
        
        for class_name in unique_classes:
            class_data = data[data['shear_diurnal_class'] == class_name]
            
            if len(class_data) < min_samples:
                print(f"Skip {class_name}: insufficient samples ({len(class_data)} < {min_samples})")
                continue
                
            print(f"\nEvaluating {class_name}: {len(class_data)} samples")
            evaluation_results[class_name] = {}
            
            for var_name, var_info in key_variables.items():
                obs_col = var_info['obs']
                ec_col = var_info['ec']
                gfs_col = var_info['gfs']
                
                if all(col in class_data.columns for col in [obs_col, ec_col, gfs_col]):
                    var_valid = (~class_data[obs_col].isna()) & (~class_data[ec_col].isna()) & (~class_data[gfs_col].isna())
                    valid_count = var_valid.sum()
                    
                    if valid_count >= min_valid_samples:
                        ec_metrics = calculate_practical_metrics(class_data[obs_col], class_data[ec_col])
                        gfs_metrics = calculate_practical_metrics(class_data[obs_col], class_data[gfs_col])
                        
                        evaluation_results[class_name][var_name] = {
                            'EC': ec_metrics,
                            'GFS': gfs_metrics
                        }
                        
                        # ÊòæÁ§∫ÂÖ≥ÈîÆÊåáÊ†á
                        print(f"  {var_info['name']} (N={valid_count}):")
                        print(f"    EC:  CORR={ec_metrics['CORR']:.3f}, BIAS={ec_metrics['BIAS']:+.3f}, RMSE={ec_metrics['RMSE']:.3f}")
                        print(f"    GFS: CORR={gfs_metrics['CORR']:.3f}, BIAS={gfs_metrics['BIAS']:+.3f}, RMSE={gfs_metrics['RMSE']:.3f}")
                    else:
                        print(f"  {var_info['name']}: insufficient valid samples ({valid_count} < {min_valid_samples})")
        
        # 4. ÂàõÂª∫ÂÆûÁî®ÁöÑÂèØËßÜÂåñÂõæË°®
        print("\nüîÑ Ê≠•È™§4: ÂàõÂª∫ÂÆûÁî®ÂèØËßÜÂåñÂõæË°®")
        
        # ËÆæÁΩÆÊï¥‰ΩìÊ†∑Âºè
        plt.style.use('default')
        plt.rcParams['axes.facecolor'] = '#F8F9FA'
        plt.rcParams['figure.facecolor'] = 'white'
        plt.rcParams['axes.edgecolor'] = '#6C757D'
        plt.rcParams['axes.linewidth'] = 0.8
        plt.rcParams['grid.color'] = '#DEE2E6'
        plt.rcParams['grid.alpha'] = 0.7
        
        for var_name, var_info in key_variables.items():
            print(f"  Creating {var_info['name']} practical analysis chart...")
            
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle(f'{var_info["name"]} Forecast Performance Analysis', fontsize=16, fontweight='bold')
            
            # Êî∂ÈõÜÊï∞ÊçÆ
            classes = []
            ec_corr = []
            gfs_corr = []
            ec_bias = []
            gfs_bias = []
            ec_rmse = []
            gfs_rmse = []
            sample_counts = []
            
            for cls in evaluation_results.keys():
                if var_name in evaluation_results[cls]:
                    ec_metrics = evaluation_results[cls][var_name]['EC']
                    gfs_metrics = evaluation_results[cls][var_name]['GFS']
                    
                    # Âè™Ë¶ÅÁõ∏ÂÖ≥Á≥ªÊï∞‰∏çÊòØNaNÂ∞±ÂåÖÂê´
                    if not (np.isnan(ec_metrics['CORR']) or np.isnan(gfs_metrics['CORR'])):
                        classes.append(cls.replace('_', '\n'))
                        ec_corr.append(ec_metrics['CORR'])
                        gfs_corr.append(gfs_metrics['CORR'])
                        ec_bias.append(ec_metrics['BIAS'])
                        gfs_bias.append(gfs_metrics['BIAS'])
                        ec_rmse.append(ec_metrics['RMSE'])
                        gfs_rmse.append(gfs_metrics['RMSE'])
                        sample_counts.append(ec_metrics['COUNT'])
            
            if classes:
                x = np.arange(len(classes))
                width = 0.35
                
                # 1. Áõ∏ÂÖ≥Á≥ªÊï∞ÂØπÊØî
                bars1 = axes[0, 0].bar(x - width/2, ec_corr, width, label='EC', color="#5F46FF", alpha=0.8)
                bars2 = axes[0, 0].bar(x + width/2, gfs_corr, width, label='GFS', color="#E38989", alpha=0.8)
                axes[0, 0].set_xlabel('Classification')
                axes[0, 0].set_ylabel('Correlation Coefficient')
                axes[0, 0].set_title('Correlation Coefficient Comparison')
                axes[0, 0].set_xticks(x)
                axes[0, 0].set_xticklabels(classes, rotation=45, ha='right')
                axes[0, 0].legend()
                axes[0, 0].grid(True, alpha=0.3)
                axes[0, 0].set_ylim(0, 1)
                
                # Ê∑ªÂä†Êï∞ÂÄºÊ†áÁ≠æÂíåÊ†∑Êú¨Êï∞
                for i, (bar1, bar2, count) in enumerate(zip(bars1, bars2, sample_counts)):
                    # Áõ∏ÂÖ≥Á≥ªÊï∞Ê†áÁ≠æ
                    axes[0, 0].text(bar1.get_x() + bar1.get_width()/2., bar1.get_height() + 0.02,
                                   f'{ec_corr[i]:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')
                    axes[0, 0].text(bar2.get_x() + bar2.get_width()/2., bar2.get_height() + 0.02,
                                   f'{gfs_corr[i]:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')
                    # Ê†∑Êú¨Êï∞Ê†áÁ≠æ
                    axes[0, 0].text(i, 0.05, f'N={count}', ha='center', va='bottom', 
                                   fontsize=9, fontweight='bold', color='white',
                                   bbox=dict(boxstyle='round,pad=0.3', facecolor="#0165F1FF", alpha=0.9))
                
                # 2. ÂÅèÂ∑ÆÂØπÊØî
                bars1 = axes[0, 1].bar(x - width/2, ec_bias, width, label='EC', color="#30C1FF", alpha=0.8)
                bars2 = axes[0, 1].bar(x + width/2, gfs_bias, width, label='GFS', color="#CE6D7F", alpha=0.8)
                axes[0, 1].set_xlabel('Classification')
                axes[0, 1].set_ylabel(f'Bias ({var_info["unit"]})')
                axes[0, 1].set_title('Forecast Bias Comparison (Positive = Overestimate)')
                axes[0, 1].set_xticks(x)
                axes[0, 1].set_xticklabels(classes, rotation=45, ha='right')
                axes[0, 1].legend()
                axes[0, 1].grid(True, alpha=0.3)
                axes[0, 1].axhline(y=0, color='black', linestyle='-', alpha=0.5)
                
                # Ê∑ªÂä†ÂÅèÂ∑ÆÊï∞ÂÄºÊ†áÁ≠æ
                for bar, value in zip(bars1, ec_bias):
                    y_pos = value + (max(ec_bias + gfs_bias) - min(ec_bias + gfs_bias)) * 0.02 if value >= 0 else value - (max(ec_bias + gfs_bias) - min(ec_bias + gfs_bias)) * 0.02
                    axes[0, 1].text(bar.get_x() + bar.get_width()/2., y_pos,
                                   f'{value:+.2f}', ha='center', va='bottom' if value >= 0 else 'top', 
                                   fontsize=8, fontweight='bold')
                for bar, value in zip(bars2, gfs_bias):
                    y_pos = value + (max(ec_bias + gfs_bias) - min(ec_bias + gfs_bias)) * 0.02 if value >= 0 else value - (max(ec_bias + gfs_bias) - min(ec_bias + gfs_bias)) * 0.02
                    axes[0, 1].text(bar.get_x() + bar.get_width()/2., y_pos,
                                   f'{value:+.2f}', ha='center', va='bottom' if value >= 0 else 'top', 
                                   fontsize=8, fontweight='bold')
                
                # 3. RMSEÂØπÊØî
                bars1 = axes[1, 0].bar(x - width/2, ec_rmse, width, label='EC', color="#F1F148B8", alpha=0.8)
                bars2 = axes[1, 0].bar(x + width/2, gfs_rmse, width, label='GFS', color="#BC89E3", alpha=0.8)
                axes[1, 0].set_xlabel('Classification')
                axes[1, 0].set_ylabel(f'RMSE ({var_info["unit"]})')
                axes[1, 0].set_title('Root Mean Square Error Comparison')
                axes[1, 0].set_xticks(x)
                axes[1, 0].set_xticklabels(classes, rotation=45, ha='right')
                axes[1, 0].legend()
                axes[1, 0].grid(True, alpha=0.3)
                
                # Ê∑ªÂä†RMSEÊï∞ÂÄºÊ†áÁ≠æ
                for bar, value in zip(bars1, ec_rmse):
                    axes[1, 0].text(bar.get_x() + bar.get_width()/2., bar.get_height() + max(ec_rmse + gfs_rmse) * 0.01,
                                   f'{value:.2f}', ha='center', va='bottom', fontsize=8, fontweight='bold')
                for bar, value in zip(bars2, gfs_rmse):
                    axes[1, 0].text(bar.get_x() + bar.get_width()/2., bar.get_height() + max(ec_rmse + gfs_rmse) * 0.01,
                                   f'{value:.2f}', ha='center', va='bottom', fontsize=8, fontweight='bold')
                
                # 4. ÁªºÂêàÊÄßËÉΩÊï£ÁÇπÂõæ (Áõ∏ÂÖ≥Á≥ªÊï∞ vs RMSE)
                axes[1, 1].scatter(ec_corr, ec_rmse, s=120, alpha=0.8, color='#46C7FF', label='EC', edgecolors='white', linewidth=1)
                axes[1, 1].scatter(gfs_corr, gfs_rmse, s=120, alpha=0.8, color='#E389D9', label='GFS', edgecolors='white', linewidth=1)
                
                # Ê∑ªÂä†ÂàÜÁ±ªÊ†áÁ≠æ
                for i, cls in enumerate(classes):
                    axes[1, 1].annotate(f'EC_{cls.replace(chr(10), "_")}', (ec_corr[i], ec_rmse[i]), 
                                       xytext=(5, 5), textcoords='offset points', fontsize=7, color="#46C7FF")
                    axes[1, 1].annotate(f'GFS_{cls.replace(chr(10), "_")}', (gfs_corr[i], gfs_rmse[i]), 
                                       xytext=(-5, -5), textcoords='offset points', fontsize=7, color="#E389D9")
                
                axes[1, 1].set_xlabel('Correlation Coefficient')
                axes[1, 1].set_ylabel(f'RMSE ({var_info["unit"]})')
                axes[1, 1].set_title('Forecast Quality Distribution\n(Bottom-right = High Corr & Low RMSE = Good Forecast)')
                axes[1, 1].legend()
                axes[1, 1].grid(True, alpha=0.3)
                axes[1, 1].set_xlim(0, 1)
                
                # Ê∑ªÂä†ÁêÜÊÉ≥Âå∫ÂüüÊ†áÊ≥®
                axes[1, 1].axhspan(0, min(ec_rmse + gfs_rmse), xmin=0.7, xmax=1.0, alpha=0.15, color='#C1FF72')
                axes[1, 1].text(0.85, min(ec_rmse + gfs_rmse) * 0.5, 'Ideal Region\nHigh Corr\nLow RMSE', 
                               ha='center', va='center', fontsize=10, 
                               bbox=dict(boxstyle='round', facecolor='#C1FF72', alpha=0.8, edgecolor='#7FB069'))
            else:
                fig.text(0.5, 0.5, f'{var_info["name"]}: No valid evaluation results', 
                        ha='center', va='center', fontsize=20)
            
            plt.tight_layout()
            plt.savefig(f"{save_path}/practical_{var_name}_analysis.png", dpi=300, bbox_inches='tight')
            plt.show()
        
        # 5. ÁîüÊàêÂÆûÁî®Ê±áÊÄªÊä•Âëä
        print("\nüîÑ Ê≠•È™§5: ÁîüÊàêÂÆûÁî®Ê±áÊÄªÊä•Âëä")
        
        summary_data = []
        for cls in evaluation_results:
            for var in evaluation_results[cls]:
                ec_metrics = evaluation_results[cls][var]['EC']
                gfs_metrics = evaluation_results[cls][var]['GFS']
                
                summary_data.append({
                    'Classification': cls,
                    'Variable': var,
                    'Variable_Name': key_variables[var]['name'],
                    'Sample_Size': ec_metrics['COUNT'],
                    'EC_CORR': ec_metrics['CORR'],
                    'GFS_CORR': gfs_metrics['CORR'],
                    'EC_BIAS': ec_metrics['BIAS'],
                    'GFS_BIAS': gfs_metrics['BIAS'],
                    'EC_RMSE': ec_metrics['RMSE'],
                    'GFS_RMSE': gfs_metrics['RMSE'],
                    'EC_MAE': ec_metrics['MAE'],
                    'GFS_MAE': gfs_metrics['MAE'],
                    'CORR_Diff_EC_minus_GFS': ec_metrics['CORR'] - gfs_metrics['CORR'],
                    'RMSE_Diff_GFS_minus_EC': gfs_metrics['RMSE'] - ec_metrics['RMSE'],  # Ê≠£ÂÄºË°®Á§∫ECÊõ¥Â•Ω
                    'Better_CORR': 'EC' if ec_metrics['CORR'] > gfs_metrics['CORR'] else 'GFS',
                    'Better_RMSE': 'EC' if ec_metrics['RMSE'] < gfs_metrics['RMSE'] else 'GFS'
                })
        
        summary_df = pd.DataFrame(summary_data)
        summary_df.to_csv(f"{save_path}/practical_nwp_evaluation.csv", index=False, encoding='utf-8-sig')
        
        print("\n" + "=" * 80)
        print("üéâ Practical NWP Evaluation Analysis Completed!")
        print("=" * 80)
        
        # ËæìÂá∫ÂÆûÁî®ÁªüËÆ°ÁªìÊûú
        print("\nüìä Practical Statistical Results:")
        for var_name, var_info in key_variables.items():
            var_data = summary_df[summary_df['Variable'] == var_name]
            if len(var_data) > 0:
                print(f"\n{var_info['name']}:")
                print(f"  Average sample size: {var_data['Sample_Size'].mean():.0f}")
                print(f"  EC average correlation: {var_data['EC_CORR'].mean():.3f}")
                print(f"  GFS average correlation: {var_data['GFS_CORR'].mean():.3f}")
                print(f"  EC average bias: {var_data['EC_BIAS'].mean():+.3f} {var_info['unit']}")
                print(f"  GFS average bias: {var_data['GFS_BIAS'].mean():+.3f} {var_info['unit']}")
                print(f"  EC average RMSE: {var_data['EC_RMSE'].mean():.3f} {var_info['unit']}")
                print(f"  GFS average RMSE: {var_data['GFS_RMSE'].mean():.3f} {var_info['unit']}")
                
                # ËÆ°ÁÆó‰ºòÂäøÁªüËÆ°
                ec_corr_wins = (var_data['Better_CORR'] == 'EC').sum()
                ec_rmse_wins = (var_data['Better_RMSE'] == 'EC').sum()
                total_comparisons = len(var_data)
                
                print(f"  EC better correlation: {ec_corr_wins}/{total_comparisons} ({ec_corr_wins/total_comparisons*100:.1f}%)")
                print(f"  EC lower error: {ec_rmse_wins}/{total_comparisons} ({ec_rmse_wins/total_comparisons*100:.1f}%)")
        
        print(f"\nüìÅ Output files:")
        print(f"  - practical_[variable]_analysis.png: Variable-specific analysis charts")
        print(f"  - practical_nwp_evaluation.csv: Practical evaluation data table")
        
        return True
        
    except Exception as e:
        print(f"‚ùå ËØÑ‰º∞ËøáÁ®ãÂá∫Èîô: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    # ÈÖçÁΩÆË∑ØÂæÑ
    DATA_PATH = "/Users/xiaxin/work/WindForecast_Project/01_Data/processed/imputed_data/changma_imputed_complete.csv"
    SAVE_PATH = "/Users/xiaxin/work/WindForecast_Project/03_Results/practical_nwp_evaluation_results"
    
    success = practical_nwp_evaluation(DATA_PATH, SAVE_PATH)
    
    if success:
        print("\nüéØ Practical version evaluation completed!")
        print("\nüí° Key improvements:")
        print("1. ‚úÖ Focus on correlation, bias, RMSE")
        print("2. ‚úÖ Sample size displayed for each classification")
        print("3. ‚úÖ Specific values labeled on charts")
        print("4. ‚úÖ All text in English")
        print("5. ‚úÖ Professional color scheme")
        print("\nüìà Practical value:")
        print("‚Ä¢ Correlation coefficient ‚Üí Forecast skill level")
        print("‚Ä¢ Bias ‚Üí Systematic error, can be corrected")
        print("‚Ä¢ RMSE ‚Üí Overall forecast accuracy")
        print("‚Ä¢ Sample size ‚Üí Statistical significance")
    else:
        print("\n‚ö†Ô∏è Evaluation failed")